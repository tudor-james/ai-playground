{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81544e7-f1c5-44cf-9faf-d7f2bc852117",
   "metadata": {},
   "source": [
    "# The hitchhiker's guide to Jupyter (part 5/n)\n",
    "\n",
    "## Let's create a Generative AI chatbot using RAG to talk to my book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea7779-0905-41f2-bb52-506fe08be871",
   "metadata": {},
   "source": [
    "I'm going to implement local chatbot on my laptop to talk to my book, [\"Designed4Devops\"](https://designed4devops.com). This will allow a user to be able to ask questions of the book and summarise its contents. My book is self-published and copywrite so it shouldn't appear in models' training data. To achieve this I'm going to RAG or _Retrieval Augmented Generation_. \n",
    "\n",
    "## RAG\n",
    "\n",
    "RAG is a technique that allows you to add data to a LLM after the model was trained, without retraining or finetuning it. Training models requires access to large and often numerous high-end GPUs. This can be expensive. It also has the downside that if you want to update the data, you need to retrain the model again.\n",
    "\n",
    "RAG overcomes this by taking the data (e.g., PDF, CSV, HTML) and vectorising it. Remember that models work by matrix multiplations of numbers not text. We use a model to embed the text as numbers in a vectore store. This allows the LLM to query the data with symantec searching. The model then returns results based on the context of the query given.\n",
    "\n",
    "Let's set up the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238abf1f-e8ff-4913-9d4a-cf53f5a32b15",
   "metadata": {},
   "source": [
    "### First, we'll install the dependencies and set up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a275d0f8-7cb0-45c8-9fa7-3af48132bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastembed 0.2.7 requires huggingface-hub<0.21,>=0.20, but you have huggingface-hub 0.23.0 which is incompatible.\n",
      "fastembed 0.2.7 requires tokenizers<0.16,>=0.15, but you have tokenizers 0.19.1 which is incompatible.\n",
      "langchain-core 0.1.52 requires packaging<24.0,>=23.2, but you have packaging 24.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall -Uq torch datasets accelerate peft bitsandbytes transformers trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8c7aeb-f605-43aa-9bdf-4fccc798d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import datasets\n",
    "import accelerate\n",
    "import peft\n",
    "import bitsandbytes\n",
    "import trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76fff367-5df0-4c0f-9ec0-59013aa3eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ebad1-ceb1-454b-936f-9bf54fadc68d",
   "metadata": {},
   "source": [
    "This sets up the tokeniser. This breaks the text up into tokens (chunks) which can be individual words or fragments of words.\n",
    "\n",
    "I'm going to use Mistral 7B as it offers a good performance at a low overhead of processing and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3a866d7-77f4-416d-98ee-291df4d2546c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449ad64b66d2433e979d919ca2bbe66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SafetensorError",
     "evalue": "Error while deserializing header: HeaderTooLarge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSafetensorError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/Mixtral-8x7B-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello my name is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3531\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3523\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3524\u001b[0m     (\n\u001b[1;32m   3525\u001b[0m         model,\n\u001b[1;32m   3526\u001b[0m         missing_keys,\n\u001b[1;32m   3527\u001b[0m         unexpected_keys,\n\u001b[1;32m   3528\u001b[0m         mismatched_keys,\n\u001b[1;32m   3529\u001b[0m         offload_index,\n\u001b[1;32m   3530\u001b[0m         error_msgs,\n\u001b[0;32m-> 3531\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3538\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3539\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3542\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3543\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3547\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3549\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3550\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3938\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shard_file \u001b[38;5;129;01min\u001b[39;00m disk_only_shard_files:\n\u001b[1;32m   3937\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 3938\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_quantized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3940\u001b[0m \u001b[38;5;66;03m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[39;00m\n\u001b[1;32m   3941\u001b[0m \u001b[38;5;66;03m# matching the weights in the model.\u001b[39;00m\n\u001b[1;32m   3942\u001b[0m mismatched_keys \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3943\u001b[0m     state_dict,\n\u001b[1;32m   3944\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3948\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3949\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:506\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file, is_quantized)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;124;03mReads a PyTorch checkpoint file, returning properly formatted errors if they arise.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_safetensors_available():\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# Check format of the archive\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msafe_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    507\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mmetadata()\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlx\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mSafetensorError\u001b[0m: Error while deserializing header: HeaderTooLarge"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"../models/Mixtral-8x7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "text = \"Hello my name is\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed401b8-2646-4384-9946-35048b2c3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model_name='../models/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bff158-c603-4bd4-ba4b-5b2d61a8325b",
   "metadata": {},
   "source": [
    "#### Quantization of the Model\n",
    "\n",
    "I'm going to quantize the model to 4 bits. This lowers the precision of the data types (int4 vs fp16 or fp32), which reduces the overheads even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ac06130-f66b-4341-9ee9-6197cd2effa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b72d5f88-8577-47f8-922a-740690132e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "faa1b72b-f025-4aec-b992-24b36bcdeab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc44133-d625-4336-88ab-ad02644a0705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "'''#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea67554-a91f-4008-bdcc-fcc24e2d6c8d",
   "metadata": {},
   "source": [
    "#### Let's test it..\n",
    "\n",
    "This query asks the model a question. We haven't loaded any of our data into it yet, this is all information held within the model from its training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e1adf3-fdb0-4553-92a8-7208a5921c86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m'''inputs_not_chat = tokenizer.encode_plus(\"[INST] What is Designed4Devops? [/INST]\", return_tensors=\"pt\")['input_ids'].to('cuda')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mgenerated_ids = model.generate(inputs_not_chat, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03mdecoded = tokenizer.batch_decode(generated_ids)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mprint(decoded)'''\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mllm\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is designed4devops?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "'''inputs_not_chat = tokenizer.encode_plus(\"[INST] What is Designed4Devops? [/INST]\", return_tensors=\"pt\")['input_ids'].to('cuda')\n",
    "\n",
    "generated_ids = model.generate(inputs_not_chat, \n",
    "                               max_new_tokens=1000, \n",
    "                               do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded)'''\n",
    "llm.invoke(\"What is designed4devops?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3907e9-d871-4f3e-b605-142c42d859cf",
   "metadata": {},
   "source": [
    "___The model has a bit in it, presumably from the website!___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0baba-0611-4acc-b0f6-8d436bb6fac5",
   "metadata": {},
   "source": [
    "#### Create the vector database\n",
    "\n",
    "I'm going to use ChromaDB, which is a lightweight local vector store, to hold the embeddings of the books text that will come from the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64eb884e-6087-4ddf-b7c1-be7b26fb27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.19.1 requires huggingface-hub>=0.21.2, but you have huggingface-hub 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall -Uq langchain chromadb openai tiktoken sentence-transformers pypdf fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a052fb6d-8a53-4894-b1d4-e3de5173d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "# from langchain.document_loaders import CSVLoader\n",
    "# from langchain.vectorstores import FAISS\n",
    "# import nest_asyncio\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "deb335d0-445e-4a47-8082-9ea021fd1ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa7218d7c424a9cafb370a157f8e108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "# Load the book\n",
    "loader = PyPDFLoader(\"/tf/docker-shared-data/rag-data/d4do_paperback.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 150,\n",
    "    chunk_overlap  = 50,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "chunks[0]\n",
    "\n",
    "store = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embeddings,\n",
    "    ids = [f\"{item.metadata['source']}-{index}\" for index, item in enumerate(chunks)],\n",
    "    collection_name=\"D4DO-Embeddings\",\n",
    "    persist_directory='db',\n",
    ")\n",
    "store.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed6733c-07b0-4868-9a43-77193e0fb9c2",
   "metadata": {},
   "source": [
    "#### Test the vector store\n",
    "\n",
    "This tests that the data exists within the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee5ed610-a64b-470a-a391-259bc771dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D4DO is how we produce products within an ITSM framework. D4DO structures a pipeline\n"
     ]
    }
   ],
   "source": [
    "result = store.similarity_search(\n",
    "    query=\"What is D4DO?\",\n",
    "    k=10\n",
    ")\n",
    "[doc.page_content for doc in result]\n",
    "'''\n",
    "query = \"What is D4DO?\"\n",
    "docs = store.similarity_search(query)\n",
    "print(docs[0].page_content)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b617a88c-1c08-4fc0-a180-3edc72d77924",
   "metadata": {},
   "source": [
    "#### Create the LLM chain\n",
    "\n",
    "To create a symantically aware search, we need to store the context of the question, and engineer a prompt that focuses the model on answering questions using the data from our vector store instead of making it up (hallucinating). Prompt engineering is a way to coach the model into giving the sort of answers that you want return and filter those that you don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd719b4a-e57c-4631-a523-eb91fc8536b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=300,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "template = \"\"\"You are a bot that answers user questions about designed4devops using only the context provided. Don't use expletives or bad language.\n",
    "If you can't answer the appoligise and say you don't know. Don't make up answers. Please limit your answer to 200 words or less. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {input}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template, input_variables=[\"context\", \"input\"]\n",
    ")\n",
    "\n",
    "retriever = store.as_retriever(search_kwargs={\n",
    "      'k': 10\n",
    "})\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8fb3a5-f435-4a19-956e-e4a6d2cb2dc0",
   "metadata": {},
   "source": [
    "#### Create RAG Chain\n",
    "\n",
    "This chains the prompt with the question to _hopefully_ get a strong answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ffbf2-ffd4-463d-9cb4-6e9e60923afa",
   "metadata": {},
   "source": [
    "## The Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f27d5e3f-9a5b-4f8b-8e54-acf50c98fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\n",
    "  \"input\": \"How can I start a digital transformation programme on my portfolio of digital products using designed4devops?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8689ad7-848a-47b8-a35b-6c863218f62e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The input to RunnablePassthrough.assign() must be a dict.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can I start a digital transformation programme on my portfolio of digital products using designed4devops?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py:4525\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   4520\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4521\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4522\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4523\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4524\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 4525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4526\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4527\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4528\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/passthrough.py:469\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    466\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    468\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py:1626\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1623\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m   1624\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1625\u001b[0m         Output,\n\u001b[0;32m-> 1626\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1634\u001b[0m     )\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1636\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/passthrough.py:450\u001b[0m, in \u001b[0;36mRunnableAssign._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke\u001b[39m(\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    449\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mdict\u001b[39m\n\u001b[1;32m    452\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapper\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    460\u001b[0m         ),\n\u001b[1;32m    461\u001b[0m     }\n",
      "\u001b[0;31mAssertionError\u001b[0m: The input to RunnablePassthrough.assign() must be a dict."
     ]
    }
   ],
   "source": [
    "query = \"How can I start a digital transformation programme on my portfolio of digital products using designed4devops?\"\n",
    "\n",
    "chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837018c0-6f46-4c46-a5b8-6fad503a9d4f",
   "metadata": {},
   "source": [
    "Not bad:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746b3f3-abce-4e92-8c65-2eca70d5de08",
   "metadata": {},
   "source": [
    "### QUESTION:\\nHow can I start a digital transformation programme on my portfolio of digital products using designed4devops? \\n\\n[/INST]\\n \\nTo start a digital transformation program on your portfolio of digital products using designed4devOps, you should follow these steps:\\n\\n1. Understand the concept of digital transformation and its benefits. This will help you understand why you need to transform your digital products and what the expected outcomes are.\\n2. Identify the areas where your digital products need improvement. This could include improving product stability, security, agility, innovation, and reducing your organization's contribution to climate change.\\n3. Develop a structured approach to digital transformation. Designed4devOps provides a framework for designing and delivering digital transformation within an organization. You can use this framework to develop a structured approach to digital transformation that is repeatable, measurable, and testable.\\n4. Integrate digital transformation into broader business frameworks. Designed4devOps emphasizes the importance of integrating digital transformation into broader business frameworks such as security and service management. This will ensure that your digital transformation efforts align with your overall business goals.\\n5. Implement the changes. Once you have developed a structured approach to digital transformation and integrated it into broader business frameworks, you can begin implementing the changes. This may involve reorganizing your teams, updating processes and procedures, and investing in new technologies.\\n6. Monitor and measure progress. To ensure that your digital transformation program is successful, you need to monitor and measure progress regularly. This will help you identify areas where you need to make adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9bd0c-e02c-4156-936f-335fab15ab74",
   "metadata": {},
   "source": [
    "Let's ask a very specific question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b9803f1-f8a6-40e2-b043-da28ea2b79f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='213 Epilogue \\nHopefully, we can draw enough parallels between the improvements made in the Lean physical product \\nproduction world and apply them to our digital pipelines. We can increase the efficiency of releasing \\nnovemes into our products by changing how we approach the introduction of changes. \\nWe aim to decrease the size of novemes to get close to single-piece flow to allow us to increase our \\nrelease frequency and decrease our release complexity. We achieve this by having developers check code \\nin more frequently and automate the testing of releases to ensure that they won’t cause problems and \\ncapture issues quickly. \\nTo make this easier for our developers, we look at the whole lifecycle of our product from the outset in \\nany change we make to it. We structure everyone involved in introducing novemes into sequential, \\nfunctional cells that self-organize. Each cell treats its downstream cell as its primary customer to ensure a \\nsmooth handover of work from one to the next and allow the introduction of automation. When we add \\nautomation, we set up guide rails that will enable us to delegate responsibility upstream or shift left to \\nreduce the wait time of work downstream. \\nTo govern this end-to-end process, we empower our product manager to have overall authority for the \\nproduct and its delivery pipeline. This person will make appropriate measurements at every step of the \\nprocess and within the product to create short feedback loops that allow us to keep improving our product \\nand its pipeline and embed a cultural appreciation of kaizen within the teams. \\nFaddy Toys Inc \\nSo how did we do in Faddy Toys? The marketing API was ready for the holiday period. \\nStakeholders de-scoped some features and added others, but it was there, and it was robust. \\nIt gave valuable insight to innovate in marketing new toy lines, which increased sales over \\nprevious years. The organization saw the change as a success. \\nThe kaizen effort continues and has a broader remit to improve existing services and \\nmanage new product delivery. The digital product management team now has an audible \\nvoice at the board level and is seen as equal to the rest of the company. IT now has support \\nto separate monolithic architectures to facilitate and optimize change. Devops is the default \\nmode of operation for any of these changes. The pipelines continue to evolve.', metadata={'page': 230, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Do \\n \\n \\n81 to bugs in code or software. Documenting these globally will help other teams avoid the same issue, which \\nmeans that overall lead time for different products can improve. \\nDuring the iteration, it is common to have short daily meetings, sometimes called stand-ups . The idea \\nbehind this is that a team in a physical location would stand up, perhaps stand up, gather at a whiteboard, \\nand discuss any existing blockers. These are also commonly done with online meeting tools such as Skype, \\nTeams, or Slack as long as the voice is available and we can share screens. It is especially beneficial if other \\nteam members can resolve blockers. Sometimes it helps if the product is in a sensitive delivery period, \\nsuch as approaching milestones or fixing security bugs. \\nThese meetings should be short (15 minutes is typical) to avoid being a distraction in their own right. \\nThe point is to flag the item up, not solve it. To solve it, the relevant team members should collaborate \\nfurther. If the problem is external, then the point is to flag the need to escalate afterward. Someone should \\nalso police the rabbit hole  to prevent the team from becoming too distracted by technical issues. If the \\nconversation drifts off-topic, they call out, “Rabbit hole!” \\nAgile Management \\nAgile management is a way to break down deliveries into smaller pieces that we can prioritize. The \\norder of delivery can change, as can the items of work on the backlog. It allows the framework to embrace \\nchange. Agile principles value the early delivery of working software through collaboration, which is why \\nit is suited to devops and helps increase flow. There is an Agile Manifesto , which is vital to understand. \\nIt also has Twelve Principles  centered around trust, collaboration, and communication. \\nAgile’s method is to box the backlog items we work on into small chunks (usually from one to four \\nweeks). These are generally known as iterations  and have different names in different methodologies, such \\nas sprints in Scrum. When planning your iterations, it is crucial to balance four things: \\n\\uf0b7 Work in progress \\n\\uf0b7 The ability for people to get on with their job and not change priorities too frequently (context \\nswitching - see Identifying Waste ) \\n\\uf0b7 The need to change requirements, even late into the cycle Note \\nRabbit Hole.  \\nA rabbit hole  is a distraction: like the disorienting, meandering journey experienced by \\nAlice in Alice’s Adventures in Wonderland .', metadata={'page': 98, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Observe \\n \\n \\n39 their schedule. Limit the breakouts to a couple of hours, or you will burn people out and walk into the laws \\nof diminishing returns. People will drift off and start working on emails or their next book in the \\nbackground. \\nMake lots of notes, especially names, titles, and roles. You are starting your cycle of improvement now. \\nYou will not get everything right the first time, and you will learn as you go. You will need follow-up calls \\nto speak to the stakeholders you missed. It is all part of the process. Try to diagram the flows of information \\nand relationships. Think of the notice board in detective shows—with the photos of key people with pins \\nand all the string between them. \\nThese meetings will be the start of your collaborative journey. Many people in the room will have often \\ncomplained about the same issues for years. It will probably be the first time many have discussed solving \\nthem together . \\nImportant  \\nNot all novemes will have the same lead time in a cell. How you average it out is up to you \\nand what makes sense in your value stream. Keep it consistent for each cell and across all \\nyour value stream maps. These measurements can become important indicators across your \\ndevops transformation to show that you are progressing. \\n \\nLead Time \\nIn the lead time  image, you can see outliers, deviations, and variations within the data. \\nConsider these at the start to ensure that you have a measurement practice that is flexible \\nenough to accommodate your whole organization. Getting this correct at the beginning will \\nhelp you consistently show progress over time and not waste time explaining differences in \\ndifferent data sets. \\n \\nWe usually break things down into manageable chunks in technical architecture and engineering. We \\nwill start with a high-level view and break it into pieces for a more detailed understanding. Start with the', metadata={'page': 56, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Do \\n \\n \\n75 above a specific size, this becomes the exception rather than the norm with numerous products and value \\nstreams. \\nOften there will be a shared function for operations, security, procurement, and finance. If this is the \\ncase, you need to automate the interfaces with the cells dependent on the people outside your direct \\nproduct team. What does that mean? You need to avoid the situation where the flow of your noveme stops \\nwith a ticket in someone else’s queue. We discuss that in more detail in Part III. \\nAn example is a shared ops team accepting tickets to create environments for competing workloads \\nand priorities. It could be a ticket with procurement and finance to get some more servers to increase \\ncapacity or security by running a vulnerability scan. We should automate these processes as a priority; \\narguably, they are the most important ones, as you have no control over them. \\nProcure enough capacity to give you headroom or buy resources in a public cloud with your budget. \\nHave APIs that developers can call to build standard environment definitions that ops have designed and \\nsigned off. Have APIs for the security tools so that developers can initiate the vulnerability scan themselves \\nthat security has developed and approved. We want all the activities within the pipeline to get a noveme \\nto release, delegated to the product team themselves to have no external lead times. It provides control \\nover the end-to-end pipeline of your novemes and creates the opportunity to increase overall flow. \\nYou should aim to have all the cells operated within your product team within your pipeline, even if \\npeople own and control them externally. If you empower developers to build their environments, you can \\nbreak the dependency on the shared ops team outside the pipeline. But communications between people \\nwithin and outside of the pipeline are still required. \\nIn the physical world, the car assembly line depends on the car seat assembly line. Suppose a developer \\nrequires changes to the environment template, such as a change in middleware technology; \\ncommunication channels still need to exist. Depending on the infrastructure, you will often find \\ndependencies between pipelines, such as the application layer. These dependencies are adjacent, and \\ncommunication will be frequent but usually less frequent than within the pipeline’s cells. \\nQuite often, we communicate this information via a ticketing system. It is very impersonal and treats \\nthe other service as a black box. We must foster collaboration between these pipelines as we work on a \\ncommon goal. The operations team is a group of external stakeholders in your pipeline. If you want this \\ninterface to work, you must communicate more effectively here. \\nRelationships between the people in both pipelines need to be encouraged and nurtured. We must align \\nthe management layers towards a common goal of increasing the value of our products. Professional', metadata={'page': 92, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'})],\n",
       " 'question': 'My developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time?',\n",
       " 'text': \"\\n### [INST] \\nInstruction: Answer the question based on your knowledge from the files in the vector database only.\\nDon't use expletives or bad language.\\nIf you can't answer the appoligise and say you don't know.\\nDon't make up answers. Please limit your answer to 200 words or less. Here is context to help:\\n\\n[Document(page_content='213 Epilogue \\\\nHopefully, we can draw enough parallels between the improvements made in the Lean physical product \\\\nproduction world and apply them to our digital pipelines. We can increase the efficiency of releasing \\\\nnovemes into our products by changing how we approach the introduction of changes. \\\\nWe aim to decrease the size of novemes to get close to single-piece flow to allow us to increase our \\\\nrelease frequency and decrease our release complexity. We achieve this by having developers check code \\\\nin more frequently and automate the testing of releases to ensure that they won’t cause problems and \\\\ncapture issues quickly. \\\\nTo make this easier for our developers, we look at the whole lifecycle of our product from the outset in \\\\nany change we make to it. We structure everyone involved in introducing novemes into sequential, \\\\nfunctional cells that self-organize. Each cell treats its downstream cell as its primary customer to ensure a \\\\nsmooth handover of work from one to the next and allow the introduction of automation. When we add \\\\nautomation, we set up guide rails that will enable us to delegate responsibility upstream or shift left to \\\\nreduce the wait time of work downstream. \\\\nTo govern this end-to-end process, we empower our product manager to have overall authority for the \\\\nproduct and its delivery pipeline. This person will make appropriate measurements at every step of the \\\\nprocess and within the product to create short feedback loops that allow us to keep improving our product \\\\nand its pipeline and embed a cultural appreciation of kaizen within the teams. \\\\nFaddy Toys Inc \\\\nSo how did we do in Faddy Toys? The marketing API was ready for the holiday period. \\\\nStakeholders de-scoped some features and added others, but it was there, and it was robust. \\\\nIt gave valuable insight to innovate in marketing new toy lines, which increased sales over \\\\nprevious years. The organization saw the change as a success. \\\\nThe kaizen effort continues and has a broader remit to improve existing services and \\\\nmanage new product delivery. The digital product management team now has an audible \\\\nvoice at the board level and is seen as equal to the rest of the company. IT now has support \\\\nto separate monolithic architectures to facilitate and optimize change. Devops is the default \\\\nmode of operation for any of these changes. The pipelines continue to evolve.', metadata={'page': 230, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Do \\\\n \\\\n \\\\n81 to bugs in code or software. Documenting these globally will help other teams avoid the same issue, which \\\\nmeans that overall lead time for different products can improve. \\\\nDuring the iteration, it is common to have short daily meetings, sometimes called stand-ups . The idea \\\\nbehind this is that a team in a physical location would stand up, perhaps stand up, gather at a whiteboard, \\\\nand discuss any existing blockers. These are also commonly done with online meeting tools such as Skype, \\\\nTeams, or Slack as long as the voice is available and we can share screens. It is especially beneficial if other \\\\nteam members can resolve blockers. Sometimes it helps if the product is in a sensitive delivery period, \\\\nsuch as approaching milestones or fixing security bugs. \\\\nThese meetings should be short (15 minutes is typical) to avoid being a distraction in their own right. \\\\nThe point is to flag the item up, not solve it. To solve it, the relevant team members should collaborate \\\\nfurther. If the problem is external, then the point is to flag the need to escalate afterward. Someone should \\\\nalso police the rabbit hole  to prevent the team from becoming too distracted by technical issues. If the \\\\nconversation drifts off-topic, they call out, “Rabbit hole!” \\\\nAgile Management \\\\nAgile management is a way to break down deliveries into smaller pieces that we can prioritize. The \\\\norder of delivery can change, as can the items of work on the backlog. It allows the framework to embrace \\\\nchange. Agile principles value the early delivery of working software through collaboration, which is why \\\\nit is suited to devops and helps increase flow. There is an Agile Manifesto , which is vital to understand. \\\\nIt also has Twelve Principles  centered around trust, collaboration, and communication. \\\\nAgile’s method is to box the backlog items we work on into small chunks (usually from one to four \\\\nweeks). These are generally known as iterations  and have different names in different methodologies, such \\\\nas sprints in Scrum. When planning your iterations, it is crucial to balance four things: \\\\n\\\\uf0b7 Work in progress \\\\n\\\\uf0b7 The ability for people to get on with their job and not change priorities too frequently (context \\\\nswitching - see Identifying Waste ) \\\\n\\\\uf0b7 The need to change requirements, even late into the cycle Note \\\\nRabbit Hole.  \\\\nA rabbit hole  is a distraction: like the disorienting, meandering journey experienced by \\\\nAlice in Alice’s Adventures in Wonderland .', metadata={'page': 98, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Observe \\\\n \\\\n \\\\n39 their schedule. Limit the breakouts to a couple of hours, or you will burn people out and walk into the laws \\\\nof diminishing returns. People will drift off and start working on emails or their next book in the \\\\nbackground. \\\\nMake lots of notes, especially names, titles, and roles. You are starting your cycle of improvement now. \\\\nYou will not get everything right the first time, and you will learn as you go. You will need follow-up calls \\\\nto speak to the stakeholders you missed. It is all part of the process. Try to diagram the flows of information \\\\nand relationships. Think of the notice board in detective shows—with the photos of key people with pins \\\\nand all the string between them. \\\\nThese meetings will be the start of your collaborative journey. Many people in the room will have often \\\\ncomplained about the same issues for years. It will probably be the first time many have discussed solving \\\\nthem together . \\\\nImportant  \\\\nNot all novemes will have the same lead time in a cell. How you average it out is up to you \\\\nand what makes sense in your value stream. Keep it consistent for each cell and across all \\\\nyour value stream maps. These measurements can become important indicators across your \\\\ndevops transformation to show that you are progressing. \\\\n \\\\nLead Time \\\\nIn the lead time  image, you can see outliers, deviations, and variations within the data. \\\\nConsider these at the start to ensure that you have a measurement practice that is flexible \\\\nenough to accommodate your whole organization. Getting this correct at the beginning will \\\\nhelp you consistently show progress over time and not waste time explaining differences in \\\\ndifferent data sets. \\\\n \\\\nWe usually break things down into manageable chunks in technical architecture and engineering. We \\\\nwill start with a high-level view and break it into pieces for a more detailed understanding. Start with the', metadata={'page': 56, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Do \\\\n \\\\n \\\\n75 above a specific size, this becomes the exception rather than the norm with numerous products and value \\\\nstreams. \\\\nOften there will be a shared function for operations, security, procurement, and finance. If this is the \\\\ncase, you need to automate the interfaces with the cells dependent on the people outside your direct \\\\nproduct team. What does that mean? You need to avoid the situation where the flow of your noveme stops \\\\nwith a ticket in someone else’s queue. We discuss that in more detail in Part III. \\\\nAn example is a shared ops team accepting tickets to create environments for competing workloads \\\\nand priorities. It could be a ticket with procurement and finance to get some more servers to increase \\\\ncapacity or security by running a vulnerability scan. We should automate these processes as a priority; \\\\narguably, they are the most important ones, as you have no control over them. \\\\nProcure enough capacity to give you headroom or buy resources in a public cloud with your budget. \\\\nHave APIs that developers can call to build standard environment definitions that ops have designed and \\\\nsigned off. Have APIs for the security tools so that developers can initiate the vulnerability scan themselves \\\\nthat security has developed and approved. We want all the activities within the pipeline to get a noveme \\\\nto release, delegated to the product team themselves to have no external lead times. It provides control \\\\nover the end-to-end pipeline of your novemes and creates the opportunity to increase overall flow. \\\\nYou should aim to have all the cells operated within your product team within your pipeline, even if \\\\npeople own and control them externally. If you empower developers to build their environments, you can \\\\nbreak the dependency on the shared ops team outside the pipeline. But communications between people \\\\nwithin and outside of the pipeline are still required. \\\\nIn the physical world, the car assembly line depends on the car seat assembly line. Suppose a developer \\\\nrequires changes to the environment template, such as a change in middleware technology; \\\\ncommunication channels still need to exist. Depending on the infrastructure, you will often find \\\\ndependencies between pipelines, such as the application layer. These dependencies are adjacent, and \\\\ncommunication will be frequent but usually less frequent than within the pipeline’s cells. \\\\nQuite often, we communicate this information via a ticketing system. It is very impersonal and treats \\\\nthe other service as a black box. We must foster collaboration between these pipelines as we work on a \\\\ncommon goal. The operations team is a group of external stakeholders in your pipeline. If you want this \\\\ninterface to work, you must communicate more effectively here. \\\\nRelationships between the people in both pipelines need to be encouraged and nurtured. We must align \\\\nthe management layers towards a common goal of increasing the value of our products. Professional', metadata={'page': 92, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'})]\\n\\n### QUESTION:\\nMy developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time? \\n\\n[/INST]\\n \\nTo reduce lead time, you can consider implementing agile practices such as documenting bugs globally, using short daily meetings to flag items up and collaborate further, and breaking down deliverables into smaller, prioritized chunks. Additionally, you can focus on automating processes and reducing external dependencies to increase overall flow and reduce lead time. Encouraging collaboration between teams and fostering effective communication can also help to reduce lead time and improve overall productivity.\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"My developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time?\"\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf7ff7-01eb-4ce4-a29c-92903c7a3aaa",
   "metadata": {},
   "source": [
    "### QUESTION:\\nMy developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time? \\n\\n[/INST]\\n \\nTo reduce lead time, you can consider implementing agile practices such as documenting bugs globally, using short daily meetings to flag items up and collaborate further, and breaking down deliverables into smaller, prioritized chunks. Additionally, you can focus on automating processes and reducing external dependencies to increase overall flow and reduce lead time. Encouraging collaboration between teams and fostering effective communication can also help to reduce lead time and improve overall productivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df285ad5-69f1-4242-8489-9a8cb406dcf5",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This was quite simple to set up on a local laptop. It demonstrates that generative AI is achievable with modest resources and in short time periods. Before you jump in, be sure to check out my blog on [Generative AI and RAG Security](https://).\n",
    "\n",
    "I'll be taking this project further and blogging along the way. I'll be talking about the environment I used to build this demo, how I productionise the system, package it and host it, and adding a front end so that you can interact with the book yourselves!\n",
    "\n",
    "You can download this blog as a Jupyter notebook file [here](https://github.com/tudor-james/ai-playground/blob/main/mistral-rag-langchain-chromadb.ipynb). As ever, if you need help with AI projects you can get in touch with Methods or contact us via LinkedIn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82807a1-4569-4122-a78f-690de716d7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2abcab3-7453-4548-8d77-f9636cdee154",
   "metadata": {},
   "source": [
    "# Addendum - Let's add Voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f92482c2-1dd2-45f0-a298-607dc259a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting voila\n",
      "  Downloading voila-0.5.6-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: jupyter-client<9,>=7.4.4 in /usr/local/lib/python3.11/dist-packages (from voila) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from voila) (5.7.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from voila) (2.13.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from voila) (2.25.3)\n",
      "Collecting nbclient<0.8,>=0.4.0 (from voila)\n",
      "  Downloading nbclient-0.7.4-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: nbconvert<8,>=6.4.5 in /usr/local/lib/python3.11/dist-packages (from voila) (7.16.2)\n",
      "Requirement already satisfied: traitlets<6,>=5.0.3 in /usr/local/lib/python3.11/dist-packages (from voila) (5.14.1)\n",
      "Requirement already satisfied: websockets>=9.0 in /usr/local/lib/python3.11/dist-packages (from voila) (12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<9,>=7.4.4->voila) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<9,>=7.4.4->voila) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<9,>=7.4.4->voila) (6.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.11.0->voila) (4.2.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (4.3.0)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (23.1.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (3.1.4)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (0.9.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (0.5.2)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (5.9.2)\n",
      "Requirement already satisfied: overrides in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (7.7.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (24.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (0.20.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (0.18.0)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.0.0->voila) (1.7.0)\n",
      "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.3.0->voila) (2.14.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.3.0->voila) (0.9.22)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.3.0->voila) (4.21.1)\n",
      "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.3.0->voila) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert<8,>=6.4.5->voila) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert<8,>=6.4.5->voila) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert<8,>=6.4.5->voila) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert<8,>=6.4.5->voila) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert<8,>=6.4.5->voila) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert<8,>=6.4.5->voila) (3.0.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert<8,>=6.4.5->voila) (1.5.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert<8,>=6.4.5->voila) (2.18.0)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.11/dist-packages (from nbconvert<8,>=6.4.5->voila) (1.2.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.0.0->voila) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.0.0->voila) (1.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->nbconvert<8,>=6.4.5->voila) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->nbconvert<8,>=6.4.5->voila) (0.5.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.3.0->voila) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.3.0->voila) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.3.0->voila) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.3.0->voila) (0.18.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.0.0->voila) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.0.0->voila) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.0.0->voila) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.0.0->voila) (0.1.1)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.0.0->voila) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.3.0->voila) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.3.0->voila) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.3.0->voila) (2024.2.2)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.0.0->voila) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->jupyter-server<3,>=2.0.0->voila) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert<8,>=6.4.5->voila) (2.5)\n",
      "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.0->voila) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.0->voila) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.0->voila) (2.4)\n",
      "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.0->voila) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.0->voila) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.0.0->voila) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.0.0->voila) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.0->voila) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.0.0->voila) (2.8.19.20240106)\n",
      "Downloading voila-0.5.6-py3-none-any.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nbclient-0.7.4-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.1/73.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nbclient, voila\n",
      "  Attempting uninstall: nbclient\n",
      "    Found existing installation: nbclient 0.9.0\n",
      "    Uninstalling nbclient-0.9.0:\n",
      "      Successfully uninstalled nbclient-0.9.0\n",
      "Successfully installed nbclient-0.7.4 voila-0.5.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc73439e-e1de-47fe-9348-7d0c5875e566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
