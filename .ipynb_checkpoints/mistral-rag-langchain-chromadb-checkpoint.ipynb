{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81544e7-f1c5-44cf-9faf-d7f2bc852117",
   "metadata": {},
   "source": [
    "# Let's create a Generative AI chatbot using RAG to talk to my book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea7779-0905-41f2-bb52-506fe08be871",
   "metadata": {},
   "source": [
    "I'm going to implement local chatbot on my laptop to talk to my book, [\"Designed4Devops\"](https://designed4devops.com). This will allow a user to be able to ask questions of the book and summarise its contents. My book is self-published and copywrite so it shouldn't appear in models' training data. To achieve this I'm going to RAG or _Retrieval Augmented Generation_. \n",
    "\n",
    "## RAG\n",
    "\n",
    "RAG is a technique that allows you to add data to a LLM after the model was trained, without retraining or finetuning it. Training models requires access to large and often numerous high-end GPUs. This can be expensive. It also has the downside that if you want to update the data, you need to retrain the model again.\n",
    "\n",
    "RAG overcomes this by taking the data (e.g., PDF, CSV, HTML) and vectorising it. Remember that models work by matrix multiplations of numbers not text. We use a model to embed the text as numbers in a vectore store. This allows the LLM to query the data with symantec searching. The model then returns results based on the context of the query given.\n",
    "\n",
    "Let's set up the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238abf1f-e8ff-4913-9d4a-cf53f5a32b15",
   "metadata": {},
   "source": [
    "### First, we'll install the dependencies and set up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a275d0f8-7cb0-45c8-9fa7-3af48132bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-core 0.1.52 requires packaging<24.0,>=23.2, but you have packaging 24.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall -Uq torch datasets accelerate peft bitsandbytes transformers trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8c7aeb-f605-43aa-9bdf-4fccc798d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import datasets\n",
    "import accelerate\n",
    "import peft\n",
    "import bitsandbytes\n",
    "import trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76fff367-5df0-4c0f-9ec0-59013aa3eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ebad1-ceb1-454b-936f-9bf54fadc68d",
   "metadata": {},
   "source": [
    "This sets up the tokeniser. This breaks the text up into tokens (chunks) which can be individual words or fragments of words.\n",
    "\n",
    "I'm going to use Mistral 7B as it offers a good performance at a low overhead of processing and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7bb7e-1a11-4bfe-9b4d-29f60b0250b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='../models/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bff158-c603-4bd4-ba4b-5b2d61a8325b",
   "metadata": {},
   "source": [
    "#### Quantization of the Model\n",
    "\n",
    "I'm going to quantize the model to 4 bits. This lowers the precision of the data types (int4 vs fp16 or fp32), which reduces the overheads even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac06130-f66b-4341-9ee9-6197cd2effa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72d5f88-8577-47f8-922a-740690132e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa1b72b-f025-4aec-b992-24b36bcdeab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc44133-d625-4336-88ab-ad02644a0705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7ea17682d540659b4b35f112f41cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea67554-a91f-4008-bdcc-fcc24e2d6c8d",
   "metadata": {},
   "source": [
    "#### Let's test it..\n",
    "\n",
    "This query asks the model a question. We haven't loaded any of our data into it yet, this is all information held within the model from its training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3e1adf3-fdb0-4553-92a8-7208a5921c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> [INST] What is Designed4Devops? [/INST] Designed4DevOps is a community of software development operations professionals who work to improve automation, collaboration, and reliability in software development and deployment processes. The purpose of the community is to share best practices, knowledge, and experience in using tools and methodologies to simplify the management of software systems, reduce the risk of errors and failures, and increase the speed and efficiency of software delivery.</s>']\n"
     ]
    }
   ],
   "source": [
    "inputs_not_chat = tokenizer.encode_plus(\"[INST] What is Designed4Devops? [/INST]\", return_tensors=\"pt\")['input_ids'].to('cuda')\n",
    "\n",
    "generated_ids = model.generate(inputs_not_chat, \n",
    "                               max_new_tokens=1000, \n",
    "                               do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3907e9-d871-4f3e-b605-142c42d859cf",
   "metadata": {},
   "source": [
    "___This information is completely incorrect, it's an hallucination!___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0baba-0611-4acc-b0f6-8d436bb6fac5",
   "metadata": {},
   "source": [
    "#### Create the vector database\n",
    "\n",
    "I'm going to use ChromaDB, which is a lightweight local vector store, to hold the embeddings of the books text that will come from the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64eb884e-6087-4ddf-b7c1-be7b26fb27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -Uq langchain chromadb openai tiktoken sentence-transformers pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a052fb6d-8a53-4894-b1d4-e3de5173d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "# from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "import nest_asyncio\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deb335d0-445e-4a47-8082-9ea021fd1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load the book\n",
    "loader = PyPDFLoader(\"/tf/docker-shared-data/rag-data/d4do_paperback.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Chunk text\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunked_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# Load chunked documents into the Chroma index\n",
    "db = Chroma.from_documents(chunked_documents, embedding_function)\n",
    "\n",
    "# Connect query to Chroma index using a retriever\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 4}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed6733c-07b0-4868-9a43-77193e0fb9c2",
   "metadata": {},
   "source": [
    "#### Test the vector store\n",
    "\n",
    "This tests that the data exists within the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee5ed610-a64b-470a-a391-259bc771dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "designed4devops\n"
     ]
    }
   ],
   "source": [
    "query = \"What can designed4devops do for my organisation?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b617a88c-1c08-4fc0-a180-3edc72d77924",
   "metadata": {},
   "source": [
    "#### Create the LLM chain\n",
    "\n",
    "To create a symantically aware search, we need to store the context of the question, and engineer a prompt that focuses the model on answering questions using the data from our vector store instead of making it up (hallucinating). Prompt engineering is a way to coach the model into giving the sort of answers that you want return and filter those that you don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd719b4a-e57c-4631-a523-eb91fc8536b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=300,\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "### [INST] \n",
    "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
    "Don't use expletives or bad language.\n",
    "If you can't answer the appoligise and say you don't know.\n",
    "Don't make up answers. Please limit your answer to 200 words or less. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} \n",
    "\n",
    "[/INST]\n",
    " \"\"\"\n",
    "\n",
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8fb3a5-f435-4a19-956e-e4a6d2cb2dc0",
   "metadata": {},
   "source": [
    "#### Create RAG Chain\n",
    "\n",
    "This chains the prompt with the question to _hopefully_ get a strong answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7771491-5768-4f6e-b17a-1c8e8178a58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content=\"Part III - WHAT - A Model Value Stream- Phase 1 - Design \\n \\n \\n100 They will interview users, conduct workshops, and complete surveys using analytical methods and their \\nexperience to understand the requirements and their context better. They will turn the requirements into \\nuser stories. \\nA user story is a user-centric definition of what the target user tries to achieve with the requirement. It \\nwill be unambiguous and allow a developer to code the functionality without a back-and-forth exchange \\nof information that will slow down cadence. \\nA user story might look like, “I want to add details to a user ticket by editing the record when I have \\nselected it from the list of tickets available.” It should have enough information so the developer can \\nunderstand the user's intent, picture themselves in their position, and walk through their actions in their \\nmind. \\nBusiness analysis is critical to agile development in many ways. Its purpose is to remove ambiguity. \\nPeople can only do it with enough experience in the field of what they are doing. They usually have a \\nbackground in the industry vertical you are serving. It is a skilled role that involves using experience and \\nan analytical approach to design with an ability to communicate and empathize with the users. A good \\nbusiness analyst will have a toolbox of techniques to work with users to drive the requirements gathering \\nand create user stories from them. \\nBusiness analysis is the bridge between addressing the business, the organizational or social need to \\nsolve a problem or perform a task, and the system's design that addresses that need. \\nUser Researcher \\nUser research is the understanding of human behavior when interacting with products. A user \\nresearcher will observe users' behavior to drive the product's design. BAs will analyze the data gathered in \\nthis exercise to inform the UX (user experience) design and improve the product's usability. \\nUser researchers may sit and observe the users directly and use data from systems or eye-tracking \\nsoftware on a cohort of users who volunteer for testing. It provides feedback to the UX design to increase \\nthe product's usability, efficiency, accessibility, and reach.\", metadata={'page': 117, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Designed4: Selecting Novemes \\n \\n \\n93 Designed4: Selecting Novemes \\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\nfor further development. \\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\ndownstream one above all others. \\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\ncost required for the investment. The following are examples of information typically captured: \\n\\uf0b7 Feature request or bug fix \\n\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\n\\uf0b7 Required by whom? \\n\\uf0b7 Change to existing service or new service \\n\\uf0b7 Number of identical or similar requests \\nEstimation \\nMost organizations will want to track their costs in some form or another. In publicly listed \\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\n\\uf0b7 Upfront and ongoing costs for the noveme \\n\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\n\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\n\\uf0b7 The expected return on the investment in the noveme \\n\\uf0b7 The length of time required for the noveme to realize its benefits \\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid', metadata={'page': 110, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Preface \\n \\n \\nvi write the book as modular sets of topics that I could structure and restructure afterward. It also meant I \\ncould lint and test as I went—devops for writing. I can still see the evolution of the book. \\nI wrote the book in modules for you to read in modules. It is hierarchical so that you can dip in and out \\ndepending on your current focus. Digital transformation is a journey, and you will need to revisit sections \\ndepending on where you are currently focusing your energy and what you have learned so far.', metadata={'page': 15, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Part III - WHAT - A Model Value Stream- Phase 3 - Use \\n \\n \\n190 \\uf0b7 Usability - indexes for measuring the length of sessions, number of interactions per task \\no If the number of interactions per task increases over time, it could signify that it is \\nbecoming more complex - technical debt building. \\n\\uf0b7 Net promoter score - customers complete surveys to indicate how happy they are with a product \\nand the likelihood of recommending services. \\no Customers answer questions on a Likert scale from ‘very positive’ to ‘very negative,’ which \\nwe can score as numbers. \\no Metricize the numbers into something which offers insight. \\n\\uf0b7 Session length - derived from first and last interactions - useful if you are advertising on your site \\nor app as it approximates how long the eyes are on the adverts \\n\\uf0b7 Lifetime - first and last day of activity, install to uninstall \\n\\uf0b7 Churn rate - account deletions, uninstall rates \\nFor our novemes, we might want a specific set of metrics dedicated to understanding how successful \\nour change behaves. \\n\\uf0b7 Popularity - a comparison of the feature against the background of other features \\n\\uf0b7 Assistance - the rate of lookups for the feature in documentation compared to others \\n\\uf0b7 Usability - the ratio of successful click-paths through the feature compared to the baseline \\n(important for tracking accessibility issues) \\nMetrics must be derived to illustrate the product’s profitability if required. \\n\\uf0b7 Paying Users & Share — the number of unique paying users in each period and the ratio of paying \\nusers to non-paying \\n\\uf0b7 Paying User Conversion - the number of non-paying users that we have converted to paying by \\nperiod \\n\\uf0b7 Transactions — number of financial transactions in a period \\n\\uf0b7 Transactions by User (TBU) — the number of financial transactions per user \\n\\uf0b7 Gross — the total value of transactions in a period \\n\\uf0b7 Revenue — the total amount of sales minus any external payment processing fees per period \\n\\uf0b7 The average revenue per user (ARPU) - could be across all users to indicate profitability or across \\npaying users to predict trends in spend', metadata={'page': 207, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'})],\n",
       " 'question': 'Summarize the text in the vector database.',\n",
       " 'text': '\\n### [INST] \\nInstruction: Answer the question based on your knowledge from the files in the vector database only.\\nDon\\'t use expletives or bad language.\\nIf you can\\'t answer the appoligise and say you don\\'t know.\\nDon\\'t make up answers. Please limit your answer to 200 words or less. Here is context to help:\\n\\n[Document(page_content=\"Part III - WHAT - A Model Value Stream- Phase 1 - Design \\\\n \\\\n \\\\n100 They will interview users, conduct workshops, and complete surveys using analytical methods and their \\\\nexperience to understand the requirements and their context better. They will turn the requirements into \\\\nuser stories. \\\\nA user story is a user-centric definition of what the target user tries to achieve with the requirement. It \\\\nwill be unambiguous and allow a developer to code the functionality without a back-and-forth exchange \\\\nof information that will slow down cadence. \\\\nA user story might look like, “I want to add details to a user ticket by editing the record when I have \\\\nselected it from the list of tickets available.” It should have enough information so the developer can \\\\nunderstand the user\\'s intent, picture themselves in their position, and walk through their actions in their \\\\nmind. \\\\nBusiness analysis is critical to agile development in many ways. Its purpose is to remove ambiguity. \\\\nPeople can only do it with enough experience in the field of what they are doing. They usually have a \\\\nbackground in the industry vertical you are serving. It is a skilled role that involves using experience and \\\\nan analytical approach to design with an ability to communicate and empathize with the users. A good \\\\nbusiness analyst will have a toolbox of techniques to work with users to drive the requirements gathering \\\\nand create user stories from them. \\\\nBusiness analysis is the bridge between addressing the business, the organizational or social need to \\\\nsolve a problem or perform a task, and the system\\'s design that addresses that need. \\\\nUser Researcher \\\\nUser research is the understanding of human behavior when interacting with products. A user \\\\nresearcher will observe users\\' behavior to drive the product\\'s design. BAs will analyze the data gathered in \\\\nthis exercise to inform the UX (user experience) design and improve the product\\'s usability. \\\\nUser researchers may sit and observe the users directly and use data from systems or eye-tracking \\\\nsoftware on a cohort of users who volunteer for testing. It provides feedback to the UX design to increase \\\\nthe product\\'s usability, efficiency, accessibility, and reach.\", metadata={\\'page\\': 117, \\'source\\': \\'/tf/docker-shared-data/rag-data/d4do_paperback.pdf\\'}), Document(page_content=\\'Designed4: Selecting Novemes \\\\n \\\\n \\\\n93 Designed4: Selecting Novemes \\\\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\\\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\\\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\\\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\\\nfor further development. \\\\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\\\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\\\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\\\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\\\ndownstream one above all others. \\\\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\\\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\\\ncost required for the investment. The following are examples of information typically captured: \\\\n\\\\uf0b7 Feature request or bug fix \\\\n\\\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\\\n\\\\uf0b7 Required by whom? \\\\n\\\\uf0b7 Change to existing service or new service \\\\n\\\\uf0b7 Number of identical or similar requests \\\\nEstimation \\\\nMost organizations will want to track their costs in some form or another. In publicly listed \\\\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\\\n\\\\uf0b7 Upfront and ongoing costs for the noveme \\\\n\\\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\\\n\\\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\\\n\\\\uf0b7 The expected return on the investment in the noveme \\\\n\\\\uf0b7 The length of time required for the noveme to realize its benefits \\\\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\\\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\\\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid\\', metadata={\\'page\\': 110, \\'source\\': \\'/tf/docker-shared-data/rag-data/d4do_paperback.pdf\\'}), Document(page_content=\\'Preface \\\\n \\\\n \\\\nvi write the book as modular sets of topics that I could structure and restructure afterward. It also meant I \\\\ncould lint and test as I went—devops for writing. I can still see the evolution of the book. \\\\nI wrote the book in modules for you to read in modules. It is hierarchical so that you can dip in and out \\\\ndepending on your current focus. Digital transformation is a journey, and you will need to revisit sections \\\\ndepending on where you are currently focusing your energy and what you have learned so far.\\', metadata={\\'page\\': 15, \\'source\\': \\'/tf/docker-shared-data/rag-data/d4do_paperback.pdf\\'}), Document(page_content=\\'Part III - WHAT - A Model Value Stream- Phase 3 - Use \\\\n \\\\n \\\\n190 \\\\uf0b7 Usability - indexes for measuring the length of sessions, number of interactions per task \\\\no If the number of interactions per task increases over time, it could signify that it is \\\\nbecoming more complex - technical debt building. \\\\n\\\\uf0b7 Net promoter score - customers complete surveys to indicate how happy they are with a product \\\\nand the likelihood of recommending services. \\\\no Customers answer questions on a Likert scale from ‘very positive’ to ‘very negative,’ which \\\\nwe can score as numbers. \\\\no Metricize the numbers into something which offers insight. \\\\n\\\\uf0b7 Session length - derived from first and last interactions - useful if you are advertising on your site \\\\nor app as it approximates how long the eyes are on the adverts \\\\n\\\\uf0b7 Lifetime - first and last day of activity, install to uninstall \\\\n\\\\uf0b7 Churn rate - account deletions, uninstall rates \\\\nFor our novemes, we might want a specific set of metrics dedicated to understanding how successful \\\\nour change behaves. \\\\n\\\\uf0b7 Popularity - a comparison of the feature against the background of other features \\\\n\\\\uf0b7 Assistance - the rate of lookups for the feature in documentation compared to others \\\\n\\\\uf0b7 Usability - the ratio of successful click-paths through the feature compared to the baseline \\\\n(important for tracking accessibility issues) \\\\nMetrics must be derived to illustrate the product’s profitability if required. \\\\n\\\\uf0b7 Paying Users & Share — the number of unique paying users in each period and the ratio of paying \\\\nusers to non-paying \\\\n\\\\uf0b7 Paying User Conversion - the number of non-paying users that we have converted to paying by \\\\nperiod \\\\n\\\\uf0b7 Transactions — number of financial transactions in a period \\\\n\\\\uf0b7 Transactions by User (TBU) — the number of financial transactions per user \\\\n\\\\uf0b7 Gross — the total value of transactions in a period \\\\n\\\\uf0b7 Revenue — the total amount of sales minus any external payment processing fees per period \\\\n\\\\uf0b7 The average revenue per user (ARPU) - could be across all users to indicate profitability or across \\\\npaying users to predict trends in spend\\', metadata={\\'page\\': 207, \\'source\\': \\'/tf/docker-shared-data/rag-data/d4do_paperback.pdf\\'})]\\n\\n### QUESTION:\\nSummarize the text in the vector database. \\n\\n[/INST]\\n \\nThe text in the vector database describes a model value stream for designing a product. The process begins with user research, where the needs and goals of the target user are identified and defined. Business analysis is then used to remove ambiguity and ensure that the user\\'s intent is understood. This information is used to create user stories, which serve as a guide for developers to build the product. The text also discusses the importance of selecting the right noveles to work on and how the inputs and outputs of the value stream should align to ensure a smooth transition from one cell to another. Finally, the text mentions the importance of tracking costs and estimating the effort and cost required for each novela.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Summarize the text in the vector database.\" \n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "rag_chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ffbf2-ffd4-463d-9cb4-6e9e60923afa",
   "metadata": {},
   "source": [
    "## The Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3bf2727-cc6b-4853-ac8f-de9c4316c273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Background \\n \\niii \\n With designed4devops  and its framework, I aim to give you a structure to use DevOps to design and \\ndeliver Digital Transformation within your organization.', metadata={'page': 12, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='designed4devops \\nDigital Transformation the Lean and Easy way \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAJ James', metadata={'page': 2, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='About this book \\n \\nvii \\n About this book \\nThis book is for anyone considering or working in the digital transformation of organizations that \\ncreate digital products. It uses DevOps and the optimization of delivering change as its core but shows you \\nhow to approach it structurally and repeatedly. It also shows you how to design your product delivery and \\nintegrate it into broader business frameworks such as security and service management. \\ndesigned4devops  will guide your digital transformation to becoming a ‘Digital Speed’ producer of \\ndigital products. It will shape your re-organization with a structured approach that is repeatable, \\nmeasurable, and testable. It could save you hundreds of thousands of dollars a year, improve your \\nproducts’ stability and security, make you more agile in your markets, create a culture of innovation, make \\nyour organization a better workplace, and reduce our contributions to climate change! \\nWhile I try to explain all the relevant terms used in devops within this book, it is a broad topic, with \\nsome subjects having entire (excellent) books of their own which I have included these in a reference \\nsection at the end of the book.', metadata={'page': 16, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='designed4devops', metadata={'page': 0, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'})],\n",
       " 'question': 'How can I start a digital transformation programme on my portfolio of digital products using designed4devops?',\n",
       " 'text': \"\\n### [INST] \\nInstruction: Answer the question based on your knowledge from the files in the vector database only.\\nDon't use expletives or bad language.\\nIf you can't answer the appoligise and say you don't know.\\nDon't make up answers. Please limit your answer to 200 words or less. Here is context to help:\\n\\n[Document(page_content='Background \\\\n \\\\niii \\\\n With designed4devops  and its framework, I aim to give you a structure to use DevOps to design and \\\\ndeliver Digital Transformation within your organization.', metadata={'page': 12, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='designed4devops \\\\nDigital Transformation the Lean and Easy way \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\nAJ James', metadata={'page': 2, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='About this book \\\\n \\\\nvii \\\\n About this book \\\\nThis book is for anyone considering or working in the digital transformation of organizations that \\\\ncreate digital products. It uses DevOps and the optimization of delivering change as its core but shows you \\\\nhow to approach it structurally and repeatedly. It also shows you how to design your product delivery and \\\\nintegrate it into broader business frameworks such as security and service management. \\\\ndesigned4devops  will guide your digital transformation to becoming a ‘Digital Speed’ producer of \\\\ndigital products. It will shape your re-organization with a structured approach that is repeatable, \\\\nmeasurable, and testable. It could save you hundreds of thousands of dollars a year, improve your \\\\nproducts’ stability and security, make you more agile in your markets, create a culture of innovation, make \\\\nyour organization a better workplace, and reduce our contributions to climate change! \\\\nWhile I try to explain all the relevant terms used in devops within this book, it is a broad topic, with \\\\nsome subjects having entire (excellent) books of their own which I have included these in a reference \\\\nsection at the end of the book.', metadata={'page': 16, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='designed4devops', metadata={'page': 0, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'})]\\n\\n### QUESTION:\\nHow can I start a digital transformation programme on my portfolio of digital products using designed4devops? \\n\\n[/INST]\\n \\nTo start a digital transformation program on your portfolio of digital products using designed4devOps, you should follow these steps:\\n\\n1. Understand the concept of digital transformation and its benefits. This will help you understand why you need to transform your digital products and what the expected outcomes are.\\n2. Identify the areas where your digital products need improvement. This could include improving product stability, security, agility, innovation, and reducing your organization's contribution to climate change.\\n3. Develop a structured approach to digital transformation. Designed4devOps provides a framework for designing and delivering digital transformation within an organization. You can use this framework to develop a structured approach to digital transformation that is repeatable, measurable, and testable.\\n4. Integrate digital transformation into broader business frameworks. Designed4devOps emphasizes the importance of integrating digital transformation into broader business frameworks such as security and service management. This will ensure that your digital transformation efforts align with your overall business goals.\\n5. Implement the changes. Once you have developed a structured approach to digital transformation and integrated it into broader business frameworks, you can begin implementing the changes. This may involve reorganizing your teams, updating processes and procedures, and investing in new technologies.\\n6. Monitor and measure progress. To ensure that your digital transformation program is successful, you need to monitor and measure progress regularly. This will help you identify areas where you need to make adjustments\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How can I start a digital transformation programme on my portfolio of digital products using designed4devops?\"\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837018c0-6f46-4c46-a5b8-6fad503a9d4f",
   "metadata": {},
   "source": [
    "Not bad:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746b3f3-abce-4e92-8c65-2eca70d5de08",
   "metadata": {},
   "source": [
    "### QUESTION:\\nHow can I start a digital transformation programme on my portfolio of digital products using designed4devops? \\n\\n[/INST]\\n \\nTo start a digital transformation program on your portfolio of digital products using designed4devOps, you should follow these steps:\\n\\n1. Understand the concept of digital transformation and its benefits. This will help you understand why you need to transform your digital products and what the expected outcomes are.\\n2. Identify the areas where your digital products need improvement. This could include improving product stability, security, agility, innovation, and reducing your organization's contribution to climate change.\\n3. Develop a structured approach to digital transformation. Designed4devOps provides a framework for designing and delivering digital transformation within an organization. You can use this framework to develop a structured approach to digital transformation that is repeatable, measurable, and testable.\\n4. Integrate digital transformation into broader business frameworks. Designed4devOps emphasizes the importance of integrating digital transformation into broader business frameworks such as security and service management. This will ensure that your digital transformation efforts align with your overall business goals.\\n5. Implement the changes. Once you have developed a structured approach to digital transformation and integrated it into broader business frameworks, you can begin implementing the changes. This may involve reorganizing your teams, updating processes and procedures, and investing in new technologies.\\n6. Monitor and measure progress. To ensure that your digital transformation program is successful, you need to monitor and measure progress regularly. This will help you identify areas where you need to make adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9bd0c-e02c-4156-936f-335fab15ab74",
   "metadata": {},
   "source": [
    "Let's ask a very specific question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b9803f1-f8a6-40e2-b043-da28ea2b79f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='213 Epilogue \\nHopefully, we can draw enough parallels between the improvements made in the Lean physical product \\nproduction world and apply them to our digital pipelines. We can increase the efficiency of releasing \\nnovemes into our products by changing how we approach the introduction of changes. \\nWe aim to decrease the size of novemes to get close to single-piece flow to allow us to increase our \\nrelease frequency and decrease our release complexity. We achieve this by having developers check code \\nin more frequently and automate the testing of releases to ensure that they won’t cause problems and \\ncapture issues quickly. \\nTo make this easier for our developers, we look at the whole lifecycle of our product from the outset in \\nany change we make to it. We structure everyone involved in introducing novemes into sequential, \\nfunctional cells that self-organize. Each cell treats its downstream cell as its primary customer to ensure a \\nsmooth handover of work from one to the next and allow the introduction of automation. When we add \\nautomation, we set up guide rails that will enable us to delegate responsibility upstream or shift left to \\nreduce the wait time of work downstream. \\nTo govern this end-to-end process, we empower our product manager to have overall authority for the \\nproduct and its delivery pipeline. This person will make appropriate measurements at every step of the \\nprocess and within the product to create short feedback loops that allow us to keep improving our product \\nand its pipeline and embed a cultural appreciation of kaizen within the teams. \\nFaddy Toys Inc \\nSo how did we do in Faddy Toys? The marketing API was ready for the holiday period. \\nStakeholders de-scoped some features and added others, but it was there, and it was robust. \\nIt gave valuable insight to innovate in marketing new toy lines, which increased sales over \\nprevious years. The organization saw the change as a success. \\nThe kaizen effort continues and has a broader remit to improve existing services and \\nmanage new product delivery. The digital product management team now has an audible \\nvoice at the board level and is seen as equal to the rest of the company. IT now has support \\nto separate monolithic architectures to facilitate and optimize change. Devops is the default \\nmode of operation for any of these changes. The pipelines continue to evolve.', metadata={'page': 230, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Do \\n \\n \\n81 to bugs in code or software. Documenting these globally will help other teams avoid the same issue, which \\nmeans that overall lead time for different products can improve. \\nDuring the iteration, it is common to have short daily meetings, sometimes called stand-ups . The idea \\nbehind this is that a team in a physical location would stand up, perhaps stand up, gather at a whiteboard, \\nand discuss any existing blockers. These are also commonly done with online meeting tools such as Skype, \\nTeams, or Slack as long as the voice is available and we can share screens. It is especially beneficial if other \\nteam members can resolve blockers. Sometimes it helps if the product is in a sensitive delivery period, \\nsuch as approaching milestones or fixing security bugs. \\nThese meetings should be short (15 minutes is typical) to avoid being a distraction in their own right. \\nThe point is to flag the item up, not solve it. To solve it, the relevant team members should collaborate \\nfurther. If the problem is external, then the point is to flag the need to escalate afterward. Someone should \\nalso police the rabbit hole  to prevent the team from becoming too distracted by technical issues. If the \\nconversation drifts off-topic, they call out, “Rabbit hole!” \\nAgile Management \\nAgile management is a way to break down deliveries into smaller pieces that we can prioritize. The \\norder of delivery can change, as can the items of work on the backlog. It allows the framework to embrace \\nchange. Agile principles value the early delivery of working software through collaboration, which is why \\nit is suited to devops and helps increase flow. There is an Agile Manifesto , which is vital to understand. \\nIt also has Twelve Principles  centered around trust, collaboration, and communication. \\nAgile’s method is to box the backlog items we work on into small chunks (usually from one to four \\nweeks). These are generally known as iterations  and have different names in different methodologies, such \\nas sprints in Scrum. When planning your iterations, it is crucial to balance four things: \\n\\uf0b7 Work in progress \\n\\uf0b7 The ability for people to get on with their job and not change priorities too frequently (context \\nswitching - see Identifying Waste ) \\n\\uf0b7 The need to change requirements, even late into the cycle Note \\nRabbit Hole.  \\nA rabbit hole  is a distraction: like the disorienting, meandering journey experienced by \\nAlice in Alice’s Adventures in Wonderland .', metadata={'page': 98, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Observe \\n \\n \\n39 their schedule. Limit the breakouts to a couple of hours, or you will burn people out and walk into the laws \\nof diminishing returns. People will drift off and start working on emails or their next book in the \\nbackground. \\nMake lots of notes, especially names, titles, and roles. You are starting your cycle of improvement now. \\nYou will not get everything right the first time, and you will learn as you go. You will need follow-up calls \\nto speak to the stakeholders you missed. It is all part of the process. Try to diagram the flows of information \\nand relationships. Think of the notice board in detective shows—with the photos of key people with pins \\nand all the string between them. \\nThese meetings will be the start of your collaborative journey. Many people in the room will have often \\ncomplained about the same issues for years. It will probably be the first time many have discussed solving \\nthem together . \\nImportant  \\nNot all novemes will have the same lead time in a cell. How you average it out is up to you \\nand what makes sense in your value stream. Keep it consistent for each cell and across all \\nyour value stream maps. These measurements can become important indicators across your \\ndevops transformation to show that you are progressing. \\n \\nLead Time \\nIn the lead time  image, you can see outliers, deviations, and variations within the data. \\nConsider these at the start to ensure that you have a measurement practice that is flexible \\nenough to accommodate your whole organization. Getting this correct at the beginning will \\nhelp you consistently show progress over time and not waste time explaining differences in \\ndifferent data sets. \\n \\nWe usually break things down into manageable chunks in technical architecture and engineering. We \\nwill start with a high-level view and break it into pieces for a more detailed understanding. Start with the', metadata={'page': 56, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Do \\n \\n \\n75 above a specific size, this becomes the exception rather than the norm with numerous products and value \\nstreams. \\nOften there will be a shared function for operations, security, procurement, and finance. If this is the \\ncase, you need to automate the interfaces with the cells dependent on the people outside your direct \\nproduct team. What does that mean? You need to avoid the situation where the flow of your noveme stops \\nwith a ticket in someone else’s queue. We discuss that in more detail in Part III. \\nAn example is a shared ops team accepting tickets to create environments for competing workloads \\nand priorities. It could be a ticket with procurement and finance to get some more servers to increase \\ncapacity or security by running a vulnerability scan. We should automate these processes as a priority; \\narguably, they are the most important ones, as you have no control over them. \\nProcure enough capacity to give you headroom or buy resources in a public cloud with your budget. \\nHave APIs that developers can call to build standard environment definitions that ops have designed and \\nsigned off. Have APIs for the security tools so that developers can initiate the vulnerability scan themselves \\nthat security has developed and approved. We want all the activities within the pipeline to get a noveme \\nto release, delegated to the product team themselves to have no external lead times. It provides control \\nover the end-to-end pipeline of your novemes and creates the opportunity to increase overall flow. \\nYou should aim to have all the cells operated within your product team within your pipeline, even if \\npeople own and control them externally. If you empower developers to build their environments, you can \\nbreak the dependency on the shared ops team outside the pipeline. But communications between people \\nwithin and outside of the pipeline are still required. \\nIn the physical world, the car assembly line depends on the car seat assembly line. Suppose a developer \\nrequires changes to the environment template, such as a change in middleware technology; \\ncommunication channels still need to exist. Depending on the infrastructure, you will often find \\ndependencies between pipelines, such as the application layer. These dependencies are adjacent, and \\ncommunication will be frequent but usually less frequent than within the pipeline’s cells. \\nQuite often, we communicate this information via a ticketing system. It is very impersonal and treats \\nthe other service as a black box. We must foster collaboration between these pipelines as we work on a \\ncommon goal. The operations team is a group of external stakeholders in your pipeline. If you want this \\ninterface to work, you must communicate more effectively here. \\nRelationships between the people in both pipelines need to be encouraged and nurtured. We must align \\nthe management layers towards a common goal of increasing the value of our products. Professional', metadata={'page': 92, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'})],\n",
       " 'question': 'My developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time?',\n",
       " 'text': \"\\n### [INST] \\nInstruction: Answer the question based on your knowledge from the files in the vector database only.\\nDon't use expletives or bad language.\\nIf you can't answer the appoligise and say you don't know.\\nDon't make up answers. Please limit your answer to 200 words or less. Here is context to help:\\n\\n[Document(page_content='213 Epilogue \\\\nHopefully, we can draw enough parallels between the improvements made in the Lean physical product \\\\nproduction world and apply them to our digital pipelines. We can increase the efficiency of releasing \\\\nnovemes into our products by changing how we approach the introduction of changes. \\\\nWe aim to decrease the size of novemes to get close to single-piece flow to allow us to increase our \\\\nrelease frequency and decrease our release complexity. We achieve this by having developers check code \\\\nin more frequently and automate the testing of releases to ensure that they won’t cause problems and \\\\ncapture issues quickly. \\\\nTo make this easier for our developers, we look at the whole lifecycle of our product from the outset in \\\\nany change we make to it. We structure everyone involved in introducing novemes into sequential, \\\\nfunctional cells that self-organize. Each cell treats its downstream cell as its primary customer to ensure a \\\\nsmooth handover of work from one to the next and allow the introduction of automation. When we add \\\\nautomation, we set up guide rails that will enable us to delegate responsibility upstream or shift left to \\\\nreduce the wait time of work downstream. \\\\nTo govern this end-to-end process, we empower our product manager to have overall authority for the \\\\nproduct and its delivery pipeline. This person will make appropriate measurements at every step of the \\\\nprocess and within the product to create short feedback loops that allow us to keep improving our product \\\\nand its pipeline and embed a cultural appreciation of kaizen within the teams. \\\\nFaddy Toys Inc \\\\nSo how did we do in Faddy Toys? The marketing API was ready for the holiday period. \\\\nStakeholders de-scoped some features and added others, but it was there, and it was robust. \\\\nIt gave valuable insight to innovate in marketing new toy lines, which increased sales over \\\\nprevious years. The organization saw the change as a success. \\\\nThe kaizen effort continues and has a broader remit to improve existing services and \\\\nmanage new product delivery. The digital product management team now has an audible \\\\nvoice at the board level and is seen as equal to the rest of the company. IT now has support \\\\nto separate monolithic architectures to facilitate and optimize change. Devops is the default \\\\nmode of operation for any of these changes. The pipelines continue to evolve.', metadata={'page': 230, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Do \\\\n \\\\n \\\\n81 to bugs in code or software. Documenting these globally will help other teams avoid the same issue, which \\\\nmeans that overall lead time for different products can improve. \\\\nDuring the iteration, it is common to have short daily meetings, sometimes called stand-ups . The idea \\\\nbehind this is that a team in a physical location would stand up, perhaps stand up, gather at a whiteboard, \\\\nand discuss any existing blockers. These are also commonly done with online meeting tools such as Skype, \\\\nTeams, or Slack as long as the voice is available and we can share screens. It is especially beneficial if other \\\\nteam members can resolve blockers. Sometimes it helps if the product is in a sensitive delivery period, \\\\nsuch as approaching milestones or fixing security bugs. \\\\nThese meetings should be short (15 minutes is typical) to avoid being a distraction in their own right. \\\\nThe point is to flag the item up, not solve it. To solve it, the relevant team members should collaborate \\\\nfurther. If the problem is external, then the point is to flag the need to escalate afterward. Someone should \\\\nalso police the rabbit hole  to prevent the team from becoming too distracted by technical issues. If the \\\\nconversation drifts off-topic, they call out, “Rabbit hole!” \\\\nAgile Management \\\\nAgile management is a way to break down deliveries into smaller pieces that we can prioritize. The \\\\norder of delivery can change, as can the items of work on the backlog. It allows the framework to embrace \\\\nchange. Agile principles value the early delivery of working software through collaboration, which is why \\\\nit is suited to devops and helps increase flow. There is an Agile Manifesto , which is vital to understand. \\\\nIt also has Twelve Principles  centered around trust, collaboration, and communication. \\\\nAgile’s method is to box the backlog items we work on into small chunks (usually from one to four \\\\nweeks). These are generally known as iterations  and have different names in different methodologies, such \\\\nas sprints in Scrum. When planning your iterations, it is crucial to balance four things: \\\\n\\\\uf0b7 Work in progress \\\\n\\\\uf0b7 The ability for people to get on with their job and not change priorities too frequently (context \\\\nswitching - see Identifying Waste ) \\\\n\\\\uf0b7 The need to change requirements, even late into the cycle Note \\\\nRabbit Hole.  \\\\nA rabbit hole  is a distraction: like the disorienting, meandering journey experienced by \\\\nAlice in Alice’s Adventures in Wonderland .', metadata={'page': 98, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Observe \\\\n \\\\n \\\\n39 their schedule. Limit the breakouts to a couple of hours, or you will burn people out and walk into the laws \\\\nof diminishing returns. People will drift off and start working on emails or their next book in the \\\\nbackground. \\\\nMake lots of notes, especially names, titles, and roles. You are starting your cycle of improvement now. \\\\nYou will not get everything right the first time, and you will learn as you go. You will need follow-up calls \\\\nto speak to the stakeholders you missed. It is all part of the process. Try to diagram the flows of information \\\\nand relationships. Think of the notice board in detective shows—with the photos of key people with pins \\\\nand all the string between them. \\\\nThese meetings will be the start of your collaborative journey. Many people in the room will have often \\\\ncomplained about the same issues for years. It will probably be the first time many have discussed solving \\\\nthem together . \\\\nImportant  \\\\nNot all novemes will have the same lead time in a cell. How you average it out is up to you \\\\nand what makes sense in your value stream. Keep it consistent for each cell and across all \\\\nyour value stream maps. These measurements can become important indicators across your \\\\ndevops transformation to show that you are progressing. \\\\n \\\\nLead Time \\\\nIn the lead time  image, you can see outliers, deviations, and variations within the data. \\\\nConsider these at the start to ensure that you have a measurement practice that is flexible \\\\nenough to accommodate your whole organization. Getting this correct at the beginning will \\\\nhelp you consistently show progress over time and not waste time explaining differences in \\\\ndifferent data sets. \\\\n \\\\nWe usually break things down into manageable chunks in technical architecture and engineering. We \\\\nwill start with a high-level view and break it into pieces for a more detailed understanding. Start with the', metadata={'page': 56, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Do \\\\n \\\\n \\\\n75 above a specific size, this becomes the exception rather than the norm with numerous products and value \\\\nstreams. \\\\nOften there will be a shared function for operations, security, procurement, and finance. If this is the \\\\ncase, you need to automate the interfaces with the cells dependent on the people outside your direct \\\\nproduct team. What does that mean? You need to avoid the situation where the flow of your noveme stops \\\\nwith a ticket in someone else’s queue. We discuss that in more detail in Part III. \\\\nAn example is a shared ops team accepting tickets to create environments for competing workloads \\\\nand priorities. It could be a ticket with procurement and finance to get some more servers to increase \\\\ncapacity or security by running a vulnerability scan. We should automate these processes as a priority; \\\\narguably, they are the most important ones, as you have no control over them. \\\\nProcure enough capacity to give you headroom or buy resources in a public cloud with your budget. \\\\nHave APIs that developers can call to build standard environment definitions that ops have designed and \\\\nsigned off. Have APIs for the security tools so that developers can initiate the vulnerability scan themselves \\\\nthat security has developed and approved. We want all the activities within the pipeline to get a noveme \\\\nto release, delegated to the product team themselves to have no external lead times. It provides control \\\\nover the end-to-end pipeline of your novemes and creates the opportunity to increase overall flow. \\\\nYou should aim to have all the cells operated within your product team within your pipeline, even if \\\\npeople own and control them externally. If you empower developers to build their environments, you can \\\\nbreak the dependency on the shared ops team outside the pipeline. But communications between people \\\\nwithin and outside of the pipeline are still required. \\\\nIn the physical world, the car assembly line depends on the car seat assembly line. Suppose a developer \\\\nrequires changes to the environment template, such as a change in middleware technology; \\\\ncommunication channels still need to exist. Depending on the infrastructure, you will often find \\\\ndependencies between pipelines, such as the application layer. These dependencies are adjacent, and \\\\ncommunication will be frequent but usually less frequent than within the pipeline’s cells. \\\\nQuite often, we communicate this information via a ticketing system. It is very impersonal and treats \\\\nthe other service as a black box. We must foster collaboration between these pipelines as we work on a \\\\ncommon goal. The operations team is a group of external stakeholders in your pipeline. If you want this \\\\ninterface to work, you must communicate more effectively here. \\\\nRelationships between the people in both pipelines need to be encouraged and nurtured. We must align \\\\nthe management layers towards a common goal of increasing the value of our products. Professional', metadata={'page': 92, 'source': '/tf/docker-shared-data/rag-data/d4do_paperback.pdf'})]\\n\\n### QUESTION:\\nMy developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time? \\n\\n[/INST]\\n \\nTo reduce lead time, you can consider implementing agile practices such as documenting bugs globally, using short daily meetings to flag items up and collaborate further, and breaking down deliverables into smaller, prioritized chunks. Additionally, you can focus on automating processes and reducing external dependencies to increase overall flow and reduce lead time. Encouraging collaboration between teams and fostering effective communication can also help to reduce lead time and improve overall productivity.\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"My developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time?\"\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf7ff7-01eb-4ce4-a29c-92903c7a3aaa",
   "metadata": {},
   "source": [
    "### QUESTION:\\nMy developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time? \\n\\n[/INST]\\n \\nTo reduce lead time, you can consider implementing agile practices such as documenting bugs globally, using short daily meetings to flag items up and collaborate further, and breaking down deliverables into smaller, prioritized chunks. Additionally, you can focus on automating processes and reducing external dependencies to increase overall flow and reduce lead time. Encouraging collaboration between teams and fostering effective communication can also help to reduce lead time and improve overall productivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df285ad5-69f1-4242-8489-9a8cb406dcf5",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This was quite simple to set up on a local laptop. It demonstrates that generative AI is achievable with modest resources and in short time periods. Before you jump in, be sure to check out my blog on [Generative AI and RAG Security](https://).\n",
    "\n",
    "I'll be taking this project further and blogging along the way. I'll be talking about the environment I used to build this demo, how I productionise the system, package it and host it, and adding a front end so that you can interact with the book yourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d48bd0f-8f68-4647-9acf-f272d80409bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
