{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81544e7-f1c5-44cf-9faf-d7f2bc852117",
   "metadata": {},
   "source": [
    "# The hitchhiker's guide to Jupyter (part 5/n)\n",
    "\n",
    "## Let's create a Generative AI chatbot using RAG to talk to my book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea7779-0905-41f2-bb52-506fe08be871",
   "metadata": {},
   "source": [
    "I'm going to implement local chatbot on my laptop to talk to my book, [\"Designed4Devops\"](https://designed4devops.com). This will allow a user to be able to ask questions of the book and summarise its contents. My book is self-published and copywrite so it shouldn't appear in models' training data. To achieve this I'm going to RAG or _Retrieval Augmented Generation_. \n",
    "\n",
    "## RAG\n",
    "\n",
    "RAG is a technique that allows you to add data to a LLM after the model was trained, without retraining or finetuning it. Training models requires access to large and often numerous high-end GPUs. This can be expensive. It also has the downside that if you want to update the data, you need to retrain the model again.\n",
    "\n",
    "RAG overcomes this by taking the data (e.g., PDF, CSV, HTML) and vectorising it. Remember that models work by matrix multiplations of numbers not text. We use a model to embed the text as numbers in a vectore store. This allows the LLM to query the data with symantec searching. The model then returns results based on the context of the query given.\n",
    "\n",
    "Let's set up the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238abf1f-e8ff-4913-9d4a-cf53f5a32b15",
   "metadata": {},
   "source": [
    "### First, we'll install the dependencies and set up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a275d0f8-7cb0-45c8-9fa7-3af48132bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall -Uq 'torch==2.2.2' datasets accelerate peft bitsandbytes transformers trl 'numpy<2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8c7aeb-f605-43aa-9bdf-4fccc798d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import datasets\n",
    "import accelerate\n",
    "import peft\n",
    "import bitsandbytes\n",
    "import trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76fff367-5df0-4c0f-9ec0-59013aa3eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ebad1-ceb1-454b-936f-9bf54fadc68d",
   "metadata": {},
   "source": [
    "This sets up the tokeniser. This breaks the text up into tokens (chunks) which can be individual words or fragments of words.\n",
    "\n",
    "I'm going to use Mistral 7B as it offers a good performance at a low overhead of processing and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e7bb7e-1a11-4bfe-9b4d-29f60b0250b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='../models/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bff158-c603-4bd4-ba4b-5b2d61a8325b",
   "metadata": {},
   "source": [
    "#### Quantization of the Model\n",
    "\n",
    "I'm going to quantize the model to 4 bits. This lowers the precision of the data types (int4 vs fp16 or fp32), which reduces the overheads even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac06130-f66b-4341-9ee9-6197cd2effa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b72d5f88-8577-47f8-922a-740690132e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa1b72b-f025-4aec-b992-24b36bcdeab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc44133-d625-4336-88ab-ad02644a0705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa77168df2fa487fab99ee14e6026a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea67554-a91f-4008-bdcc-fcc24e2d6c8d",
   "metadata": {},
   "source": [
    "#### Let's test it..\n",
    "\n",
    "This query asks the model a question. We haven't loaded any of our data into it yet, this is all information held within the model from its training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3e1adf3-fdb0-4553-92a8-7208a5921c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> [INST] What is Designed4Devops? [/INST] Designed4DevOps is a collection of tools, processes, and methodologies that are designed specifically for software development teams to collaborate and work effectively with operations teams and other stakeholders to build, deploy, and manage software applications at scale.\\n\\nThe Designed4DevOps approach is focused on improving communication, collaboration, automation, and continuous improvement throughout the entire software development lifecycle (SDLC). It emphasizes the importance of DevOps best practices, such as continuous integration and delivery (CI/CD), continuous monitoring and testing, and infrastructure-as-code (IAC) to help organizations release software quickly and reliably.</s>']\n"
     ]
    }
   ],
   "source": [
    "inputs_not_chat = tokenizer.encode_plus(\"[INST] What is Designed4Devops? [/INST]\", return_tensors=\"pt\")['input_ids'].to('cuda')\n",
    "\n",
    "generated_ids = model.generate(inputs_not_chat, \n",
    "                               max_new_tokens=1000, \n",
    "                               do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3907e9-d871-4f3e-b605-142c42d859cf",
   "metadata": {},
   "source": [
    "___Not bad, we must have made it into the web scrapes!___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e5415-cd8b-49e7-b5a0-4ce93ba6e9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4a13d-3cae-436b-8f69-5f4599cb616d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93e0baba-0611-4acc-b0f6-8d436bb6fac5",
   "metadata": {},
   "source": [
    "#### Create the vector database\n",
    "\n",
    "I'm going to use ChromaDB, which is a lightweight local vector store, to hold the embeddings of the books text that will come from the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64eb884e-6087-4ddf-b7c1-be7b26fb27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uq langchain chromadb openai tiktoken sentence-transformers pypdf langchain-community langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a052fb6d-8a53-4894-b1d4-e3de5173d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "# from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "import nest_asyncio\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deb335d0-445e-4a47-8082-9ea021fd1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load the book\n",
    "loader = PyPDFLoader(\"/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Chunk text\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunked_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# Load chunked documents into the Chroma index\n",
    "db = Chroma.from_documents(chunked_documents, embedding_function)\n",
    "\n",
    "# Connect query to Chroma index using a retriever\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 4}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed6733c-07b0-4868-9a43-77193e0fb9c2",
   "metadata": {},
   "source": [
    "#### Test the vector store\n",
    "\n",
    "This tests that the data exists within the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee5ed610-a64b-470a-a391-259bc771dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "designed4devops\n"
     ]
    }
   ],
   "source": [
    "query = \"What can designed4devops do for my organisation?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b617a88c-1c08-4fc0-a180-3edc72d77924",
   "metadata": {},
   "source": [
    "#### Create the LLM chain\n",
    "\n",
    "To create a symantically aware search, we need to store the context of the question, and engineer a prompt that focuses the model on answering questions using the data from our vector store instead of making it up (hallucinating). Prompt engineering is a way to coach the model into giving the sort of answers that you want return and filter those that you don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd719b4a-e57c-4631-a523-eb91fc8536b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=300,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "### [INST] \n",
    "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
    "Don't use expletives or bad language.\n",
    "If you can't answer the appoligise and say you don't know.\n",
    "Don't make up answers. Please limit your answer to 200 words or less. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} \n",
    "\n",
    "[/INST]\n",
    " \"\"\"\n",
    "\n",
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8fb3a5-f435-4a19-956e-e4a6d2cb2dc0",
   "metadata": {},
   "source": [
    "#### Create RAG Chain\n",
    "\n",
    "This chains the prompt with the question to _hopefully_ get a strong answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7771491-5768-4f6e-b17a-1c8e8178a58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content=\"Part III - WHAT - A Model Value Stream- Phase 1 - Design \\n \\n \\n100 They will interview users, conduct workshops, and complete surveys using analytical methods and their \\nexperience to understand the requirements and their context better. They will turn the requirements into \\nuser stories. \\nA user story is a user-centric definition of what the target user tries to achieve with the requirement. It \\nwill be unambiguous and allow a developer to code the functionality without a back-and-forth exchange \\nof information that will slow down cadence. \\nA user story might look like, “I want to add details to a user ticket by editing the record when I have \\nselected it from the list of tickets available.” It should have enough information so the developer can \\nunderstand the user's intent, picture themselves in their position, and walk through their actions in their \\nmind. \\nBusiness analysis is critical to agile development in many ways. Its purpose is to remove ambiguity. \\nPeople can only do it with enough experience in the field of what they are doing. They usually have a \\nbackground in the industry vertical you are serving. It is a skilled role that involves using experience and \\nan analytical approach to design with an ability to communicate and empathize with the users. A good \\nbusiness analyst will have a toolbox of techniques to work with users to drive the requirements gathering \\nand create user stories from them. \\nBusiness analysis is the bridge between addressing the business, the organizational or social need to \\nsolve a problem or perform a task, and the system's design that addresses that need. \\nUser Researcher \\nUser research is the understanding of human behavior when interacting with products. A user \\nresearcher will observe users' behavior to drive the product's design. BAs will analyze the data gathered in \\nthis exercise to inform the UX (user experience) design and improve the product's usability. \\nUser researchers may sit and observe the users directly and use data from systems or eye-tracking \\nsoftware on a cohort of users who volunteer for testing. It provides feedback to the UX design to increase \\nthe product's usability, efficiency, accessibility, and reach.\", metadata={'page': 117, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Designed4: Selecting Novemes \\n \\n \\n93 Designed4: Selecting Novemes \\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\nfor further development. \\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\ndownstream one above all others. \\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\ncost required for the investment. The following are examples of information typically captured: \\n\\uf0b7 Feature request or bug fix \\n\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\n\\uf0b7 Required by whom? \\n\\uf0b7 Change to existing service or new service \\n\\uf0b7 Number of identical or similar requests \\nEstimation \\nMost organizations will want to track their costs in some form or another. In publicly listed \\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\n\\uf0b7 Upfront and ongoing costs for the noveme \\n\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\n\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\n\\uf0b7 The expected return on the investment in the noveme \\n\\uf0b7 The length of time required for the noveme to realize its benefits \\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid', metadata={'page': 110, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='89 Part III - WHAT - A Model Value Stream \\nIn this section, we will look at a reference value stream. We will look at practices, processes, \\nmethodologies, architectures, technologies, and tools we can employ to increase efficiencies in our \\npipelines. We will look at the handovers between cells to understand how to eliminate waste and improve \\nlead time.', metadata={'page': 106, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Part III - WHAT - A Model Value Stream- Phase 3 - Use \\n \\n \\n182 Designed4: Pipeline and Product Feedback \\nFeedback is getting the information from the tools back to those who need to act on it. Feedback drives \\nkaizen efforts at the delivery level. Technical information tends to go back to developers and operations to \\nchange the platform or application code. Product information tends to go back to the product managers \\nto influence the product’s business direction. The product manager can then use the information for \\ncontinuous improvement activities at the product level. \\nWe need to present different forms of information in different ways. Almost all data should be \\nvisualized in some way, such as charts or graphs, to see relationships or trends quickly. \\nA crucial part of devops pipelines is the ability to provide fast feedback. Feedback is vital as it shows \\nhow successfully we responded to the requirements we received. The quicker it gets to the people who \\nneed it, the less technical and social debt we incorporate into our products. Technological and social debt \\nare issues with technology and processes that we need to address and fix. The longer the problems remain \\nin the system, the more effort it will take to resolve them. It increases the amount of waste we have. \\nData must be collected, processed, stored, and published for people to be aware of it and understand \\nwhat they need to do. We need to get information to the right people for them to resolve issues quickly. \\nThis section will provide some ideas of what information we need to collect. \\nWe need to understand its impact when we release a noveme into our product. From a technical point \\nof view, we need to know the changes to its performance and capacity profile. We must continually \\nmeasure performance and capacity indicators such as available computing resources and load upon the \\nsystem to do this. These can be non-functional infrastructure counters, such as CPU, memory, storage, \\nand network utilization. There should also be measurements such as response times of application \\nbehavior, availability, and mean-time-between-failures (more on these later) and functionality \\nmeasurements. \\nWe also need to consider our service level objectives and contractual obligations. Suppose we have \\nservice level agreements (SLAs) with our external customers or operational level agreements (OLAs) with \\nour internal customers. In that case, we need to measure to demonstrate compliance or non-compliance \\nwith those obligations. The metrics we need to measure depend on what we try to prove. In this phase, we \\nwill look at the types of agreements and provide ideas and indicators as to what should be measured.', metadata={'page': 199, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})],\n",
       " 'question': 'Summarize the text in the vector database.',\n",
       " 'text': '\\n### [INST] \\nInstruction: Answer the question based on your knowledge from the files in the vector database only.\\nDon\\'t use expletives or bad language.\\nIf you can\\'t answer the appoligise and say you don\\'t know.\\nDon\\'t make up answers. Please limit your answer to 200 words or less. Here is context to help:\\n\\n[Document(page_content=\"Part III - WHAT - A Model Value Stream- Phase 1 - Design \\\\n \\\\n \\\\n100 They will interview users, conduct workshops, and complete surveys using analytical methods and their \\\\nexperience to understand the requirements and their context better. They will turn the requirements into \\\\nuser stories. \\\\nA user story is a user-centric definition of what the target user tries to achieve with the requirement. It \\\\nwill be unambiguous and allow a developer to code the functionality without a back-and-forth exchange \\\\nof information that will slow down cadence. \\\\nA user story might look like, “I want to add details to a user ticket by editing the record when I have \\\\nselected it from the list of tickets available.” It should have enough information so the developer can \\\\nunderstand the user\\'s intent, picture themselves in their position, and walk through their actions in their \\\\nmind. \\\\nBusiness analysis is critical to agile development in many ways. Its purpose is to remove ambiguity. \\\\nPeople can only do it with enough experience in the field of what they are doing. They usually have a \\\\nbackground in the industry vertical you are serving. It is a skilled role that involves using experience and \\\\nan analytical approach to design with an ability to communicate and empathize with the users. A good \\\\nbusiness analyst will have a toolbox of techniques to work with users to drive the requirements gathering \\\\nand create user stories from them. \\\\nBusiness analysis is the bridge between addressing the business, the organizational or social need to \\\\nsolve a problem or perform a task, and the system\\'s design that addresses that need. \\\\nUser Researcher \\\\nUser research is the understanding of human behavior when interacting with products. A user \\\\nresearcher will observe users\\' behavior to drive the product\\'s design. BAs will analyze the data gathered in \\\\nthis exercise to inform the UX (user experience) design and improve the product\\'s usability. \\\\nUser researchers may sit and observe the users directly and use data from systems or eye-tracking \\\\nsoftware on a cohort of users who volunteer for testing. It provides feedback to the UX design to increase \\\\nthe product\\'s usability, efficiency, accessibility, and reach.\", metadata={\\'page\\': 117, \\'source\\': \\'/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\\'}), Document(page_content=\\'Designed4: Selecting Novemes \\\\n \\\\n \\\\n93 Designed4: Selecting Novemes \\\\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\\\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\\\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\\\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\\\nfor further development. \\\\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\\\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\\\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\\\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\\\ndownstream one above all others. \\\\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\\\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\\\ncost required for the investment. The following are examples of information typically captured: \\\\n\\\\uf0b7 Feature request or bug fix \\\\n\\\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\\\n\\\\uf0b7 Required by whom? \\\\n\\\\uf0b7 Change to existing service or new service \\\\n\\\\uf0b7 Number of identical or similar requests \\\\nEstimation \\\\nMost organizations will want to track their costs in some form or another. In publicly listed \\\\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\\\n\\\\uf0b7 Upfront and ongoing costs for the noveme \\\\n\\\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\\\n\\\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\\\n\\\\uf0b7 The expected return on the investment in the noveme \\\\n\\\\uf0b7 The length of time required for the noveme to realize its benefits \\\\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\\\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\\\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid\\', metadata={\\'page\\': 110, \\'source\\': \\'/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\\'}), Document(page_content=\\'89 Part III - WHAT - A Model Value Stream \\\\nIn this section, we will look at a reference value stream. We will look at practices, processes, \\\\nmethodologies, architectures, technologies, and tools we can employ to increase efficiencies in our \\\\npipelines. We will look at the handovers between cells to understand how to eliminate waste and improve \\\\nlead time.\\', metadata={\\'page\\': 106, \\'source\\': \\'/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\\'}), Document(page_content=\\'Part III - WHAT - A Model Value Stream- Phase 3 - Use \\\\n \\\\n \\\\n182 Designed4: Pipeline and Product Feedback \\\\nFeedback is getting the information from the tools back to those who need to act on it. Feedback drives \\\\nkaizen efforts at the delivery level. Technical information tends to go back to developers and operations to \\\\nchange the platform or application code. Product information tends to go back to the product managers \\\\nto influence the product’s business direction. The product manager can then use the information for \\\\ncontinuous improvement activities at the product level. \\\\nWe need to present different forms of information in different ways. Almost all data should be \\\\nvisualized in some way, such as charts or graphs, to see relationships or trends quickly. \\\\nA crucial part of devops pipelines is the ability to provide fast feedback. Feedback is vital as it shows \\\\nhow successfully we responded to the requirements we received. The quicker it gets to the people who \\\\nneed it, the less technical and social debt we incorporate into our products. Technological and social debt \\\\nare issues with technology and processes that we need to address and fix. The longer the problems remain \\\\nin the system, the more effort it will take to resolve them. It increases the amount of waste we have. \\\\nData must be collected, processed, stored, and published for people to be aware of it and understand \\\\nwhat they need to do. We need to get information to the right people for them to resolve issues quickly. \\\\nThis section will provide some ideas of what information we need to collect. \\\\nWe need to understand its impact when we release a noveme into our product. From a technical point \\\\nof view, we need to know the changes to its performance and capacity profile. We must continually \\\\nmeasure performance and capacity indicators such as available computing resources and load upon the \\\\nsystem to do this. These can be non-functional infrastructure counters, such as CPU, memory, storage, \\\\nand network utilization. There should also be measurements such as response times of application \\\\nbehavior, availability, and mean-time-between-failures (more on these later) and functionality \\\\nmeasurements. \\\\nWe also need to consider our service level objectives and contractual obligations. Suppose we have \\\\nservice level agreements (SLAs) with our external customers or operational level agreements (OLAs) with \\\\nour internal customers. In that case, we need to measure to demonstrate compliance or non-compliance \\\\nwith those obligations. The metrics we need to measure depend on what we try to prove. In this phase, we \\\\nwill look at the types of agreements and provide ideas and indicators as to what should be measured.\\', metadata={\\'page\\': 199, \\'source\\': \\'/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\\'})]\\n\\n### QUESTION:\\nSummarize the text in the vector database. \\n\\n[/INST]\\n \\nThe text describes a model value stream for designing a product. The process begins with understanding the requirements and creating user stories. Business analysis is critical to removing ambiguity and empathizing with users. User research is used to understand human behavior and inform the UX design. The next step is selecting novemes, which are bugs, feature requests, or other tasks that need to be developed. The inputs and outputs of this step ensure a smooth transition from one cell to another. The team in the selecting novemes cell defines the input criteria for any noveme they will accept. Estimations are used to track costs and provide a cost-benefit analysis of the investment size in people and resources compared to their payback. The text also discusses the importance of feedback in driving kaizen efforts at the delivery level and presenting information in different ways. Data must be collected, processed, stored, and published for people to be aware of it and understand what they need to do.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Summarize the text in the vector database.\" \n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "rag_chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ffbf2-ffd4-463d-9cb4-6e9e60923afa",
   "metadata": {},
   "source": [
    "## The Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3bf2727-cc6b-4853-ac8f-de9c4316c273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Background \\n \\niii \\n With designed4devops  and its framework, I aim to give you a structure to use DevOps to design and \\ndeliver Digital Transformation within your organization.', metadata={'page': 12, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='designed4devops \\nDigital Transformation the Lean and Easy way \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAJ James', metadata={'page': 2, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='About this book \\n \\nvii \\n About this book \\nThis book is for anyone considering or working in the digital transformation of organizations that \\ncreate digital products. It uses DevOps and the optimization of delivering change as its core but shows you \\nhow to approach it structurally and repeatedly. It also shows you how to design your product delivery and \\nintegrate it into broader business frameworks such as security and service management. \\ndesigned4devops  will guide your digital transformation to becoming a ‘Digital Speed’ producer of \\ndigital products. It will shape your re-organization with a structured approach that is repeatable, \\nmeasurable, and testable. It could save you hundreds of thousands of dollars a year, improve your \\nproducts’ stability and security, make you more agile in your markets, create a culture of innovation, make \\nyour organization a better workplace, and reduce our contributions to climate change! \\nWhile I try to explain all the relevant terms used in devops within this book, it is a broad topic, with \\nsome subjects having entire (excellent) books of their own which I have included these in a reference \\nsection at the end of the book.', metadata={'page': 16, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='designed4devops', metadata={'page': 0, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})],\n",
       " 'question': 'How can I start a digital transformation programme on my portfolio of digital products using designed4devops?',\n",
       " 'text': \"\\n### [INST] \\nInstruction: Answer the question based on your knowledge from the files in the vector database only.\\nDon't use expletives or bad language.\\nIf you can't answer the appoligise and say you don't know.\\nDon't make up answers. Please limit your answer to 200 words or less. Here is context to help:\\n\\n[Document(page_content='Background \\\\n \\\\niii \\\\n With designed4devops  and its framework, I aim to give you a structure to use DevOps to design and \\\\ndeliver Digital Transformation within your organization.', metadata={'page': 12, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='designed4devops \\\\nDigital Transformation the Lean and Easy way \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\nAJ James', metadata={'page': 2, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='About this book \\\\n \\\\nvii \\\\n About this book \\\\nThis book is for anyone considering or working in the digital transformation of organizations that \\\\ncreate digital products. It uses DevOps and the optimization of delivering change as its core but shows you \\\\nhow to approach it structurally and repeatedly. It also shows you how to design your product delivery and \\\\nintegrate it into broader business frameworks such as security and service management. \\\\ndesigned4devops  will guide your digital transformation to becoming a ‘Digital Speed’ producer of \\\\ndigital products. It will shape your re-organization with a structured approach that is repeatable, \\\\nmeasurable, and testable. It could save you hundreds of thousands of dollars a year, improve your \\\\nproducts’ stability and security, make you more agile in your markets, create a culture of innovation, make \\\\nyour organization a better workplace, and reduce our contributions to climate change! \\\\nWhile I try to explain all the relevant terms used in devops within this book, it is a broad topic, with \\\\nsome subjects having entire (excellent) books of their own which I have included these in a reference \\\\nsection at the end of the book.', metadata={'page': 16, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='designed4devops', metadata={'page': 0, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})]\\n\\n### QUESTION:\\nHow can I start a digital transformation programme on my portfolio of digital products using designed4devops? \\n\\n[/INST]\\n \\nTo start a digital transformation program on your portfolio of digital products using designed4devOps, you should follow these steps:\\n\\n1. Understand the concept of digital transformation and its benefits. This book provides an overview of digital transformation and its importance in today's world.\\n2. Identify the areas where digital transformation can be applied to your portfolio of digital products. This may include improving product delivery, increasing agility, enhancing security, and reducing costs.\\n3. Develop a structured approach to digital transformation using designed4devOps. The book provides a step-by-step guide to designing and delivering digital transformation programs using DevOps principles.\\n4. Integrate digital transformation into broader business frameworks such as security and service management. This will ensure that digital transformation is aligned with your overall business goals and objectives.\\n5. Test and measure the success of your digital transformation program. The book provides guidance on how to measure the impact of digital transformation on your portfolio of digital products.\\n6. Continuously improve your digital transformation program. As new technologies and best practices emerge, it's important to stay up-to-date and incorporate them into your digital transformation program.\\n\\nBy following these steps, you can leverage the power of designed4devOps to transform your portfolio of digital products and achieve your business goals.\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How can I start a digital transformation programme on my portfolio of digital products using designed4devops?\"\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837018c0-6f46-4c46-a5b8-6fad503a9d4f",
   "metadata": {},
   "source": [
    "Not bad:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746b3f3-abce-4e92-8c65-2eca70d5de08",
   "metadata": {},
   "source": [
    "### QUESTION:\\nHow can I start a digital transformation programme on my portfolio of digital products using designed4devops? \\n\\n[/INST]\\n \\nTo start a digital transformation program on your portfolio of digital products using designed4devOps, you should follow these steps:\\n\\n1. Understand the concept of digital transformation and its benefits. This will help you understand why you need to transform your digital products and what the expected outcomes are.\\n2. Identify the areas where your digital products need improvement. This could include improving product stability, security, agility, innovation, and reducing your organization's contribution to climate change.\\n3. Develop a structured approach to digital transformation. Designed4devOps provides a framework for designing and delivering digital transformation within an organization. You can use this framework to develop a structured approach to digital transformation that is repeatable, measurable, and testable.\\n4. Integrate digital transformation into broader business frameworks. Designed4devOps emphasizes the importance of integrating digital transformation into broader business frameworks such as security and service management. This will ensure that your digital transformation efforts align with your overall business goals.\\n5. Implement the changes. Once you have developed a structured approach to digital transformation and integrated it into broader business frameworks, you can begin implementing the changes. This may involve reorganizing your teams, updating processes and procedures, and investing in new technologies.\\n6. Monitor and measure progress. To ensure that your digital transformation program is successful, you need to monitor and measure progress regularly. This will help you identify areas where you need to make adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9bd0c-e02c-4156-936f-335fab15ab74",
   "metadata": {},
   "source": [
    "Let's ask a very specific question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b9803f1-f8a6-40e2-b043-da28ea2b79f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='213 Epilogue \\nHopefully, we can draw enough parallels between the improvements made in the Lean physical product \\nproduction world and apply them to our digital pipelines. We can increase the efficiency of releasing \\nnovemes into our products by changing how we approach the introduction of changes. \\nWe aim to decrease the size of novemes to get close to single-piece flow to allow us to increase our \\nrelease frequency and decrease our release complexity. We achieve this by having developers check code \\nin more frequently and automate the testing of releases to ensure that they won’t cause problems and \\ncapture issues quickly. \\nTo make this easier for our developers, we look at the whole lifecycle of our product from the outset in \\nany change we make to it. We structure everyone involved in introducing novemes into sequential, \\nfunctional cells that self-organize. Each cell treats its downstream cell as its primary customer to ensure a \\nsmooth handover of work from one to the next and allow the introduction of automation. When we add \\nautomation, we set up guide rails that will enable us to delegate responsibility upstream or shift left to \\nreduce the wait time of work downstream. \\nTo govern this end-to-end process, we empower our product manager to have overall authority for the \\nproduct and its delivery pipeline. This person will make appropriate measurements at every step of the \\nprocess and within the product to create short feedback loops that allow us to keep improving our product \\nand its pipeline and embed a cultural appreciation of kaizen within the teams. \\nFaddy Toys Inc \\nSo how did we do in Faddy Toys? The marketing API was ready for the holiday period. \\nStakeholders de-scoped some features and added others, but it was there, and it was robust. \\nIt gave valuable insight to innovate in marketing new toy lines, which increased sales over \\nprevious years. The organization saw the change as a success. \\nThe kaizen effort continues and has a broader remit to improve existing services and \\nmanage new product delivery. The digital product management team now has an audible \\nvoice at the board level and is seen as equal to the rest of the company. IT now has support \\nto separate monolithic architectures to facilitate and optimize change. Devops is the default \\nmode of operation for any of these changes. The pipelines continue to evolve.', metadata={'page': 230, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Observe \\n \\n \\n39 their schedule. Limit the breakouts to a couple of hours, or you will burn people out and walk into the laws \\nof diminishing returns. People will drift off and start working on emails or their next book in the \\nbackground. \\nMake lots of notes, especially names, titles, and roles. You are starting your cycle of improvement now. \\nYou will not get everything right the first time, and you will learn as you go. You will need follow-up calls \\nto speak to the stakeholders you missed. It is all part of the process. Try to diagram the flows of information \\nand relationships. Think of the notice board in detective shows—with the photos of key people with pins \\nand all the string between them. \\nThese meetings will be the start of your collaborative journey. Many people in the room will have often \\ncomplained about the same issues for years. It will probably be the first time many have discussed solving \\nthem together . \\nImportant  \\nNot all novemes will have the same lead time in a cell. How you average it out is up to you \\nand what makes sense in your value stream. Keep it consistent for each cell and across all \\nyour value stream maps. These measurements can become important indicators across your \\ndevops transformation to show that you are progressing. \\n \\nLead Time \\nIn the lead time  image, you can see outliers, deviations, and variations within the data. \\nConsider these at the start to ensure that you have a measurement practice that is flexible \\nenough to accommodate your whole organization. Getting this correct at the beginning will \\nhelp you consistently show progress over time and not waste time explaining differences in \\ndifferent data sets. \\n \\nWe usually break things down into manageable chunks in technical architecture and engineering. We \\nwill start with a high-level view and break it into pieces for a more detailed understanding. Start with the', metadata={'page': 56, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Plan \\n \\n \\n61 introduce changes, the more chance of success in a shorter period. Ideally, start with product development \\nin a single language and framework and deploy with a small set of operating technologies. \\nPrioritizing Products and Value Streams \\nValue Stream Mapping is a valuable tool to help you understand your workflow from idea to release. \\nYou need to engage with your stakeholders to understand the handovers, the lead times, and the queue \\ntimes between individuals and groups. You can then use this map to target the bottlenecks and pinch-\\npoints of your value stream to improve the system by employing automation or increasing the performance \\nof steps such as unit tests or acceptance tests. You will need to capture the following: \\n\\uf0b7 The frequency of releases: how often are releases deployed? \\n\\uf0b7 The first-time success rates of deployments and releases. \\n\\uf0b7 The ‘wait time’ of each cell. \\n\\uf0b7 The transfer time of tasks. \\n\\uf0b7 The number of people required to facilitate the step within the cell. \\n\\uf0b7 The completion time of the tasks within the cell. \\nOnce you have mapped your value stream, you can start to look across the flows. At its heart, D4DO \\nimprovement is about facilitating the flow of novemes through your products to make them more efficient. \\nWe will realize the most gain from the products which see the most change. It is vital to approach all your \\nstakeholders when comparing the rate of change through various pipelines. A developer or ops engineer \\nwill know the rate of novemes today and provide a baseline. \\nIn contrast, a product manager or salesperson will look toward a more distant horizon with a long view \\nof change. It gives you a baseline for improvement. Examine the one-year horizon of the pipeline. It is \\nlikely to be the implementation timeframe of your devops transformation. If you are approaching a \\nsignificant milestone in your value stream, avoid activities that detract from it. Adversely impacting in-\\nflight activities may damage the reputation of your broader transformation program. If your next \\nsignificant milestone is one year away, you can aim to complete your transformation within that time. \\nAfter prioritizing the product for transformation, you must prioritize the value streams. Again, as a rule \\nof thumb, the value streams that see the most change will benefit the most from transformation. For \\nexample, an e-commerce site’s front end must frequently change to maintain consumer interest. The \\nsystems of record behind it, such as large databases, will usually change less regularly (unless we have \\nclosely coupled architectures - but more on that topic later).', metadata={'page': 78, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Do \\n \\n \\n75 above a specific size, this becomes the exception rather than the norm with numerous products and value \\nstreams. \\nOften there will be a shared function for operations, security, procurement, and finance. If this is the \\ncase, you need to automate the interfaces with the cells dependent on the people outside your direct \\nproduct team. What does that mean? You need to avoid the situation where the flow of your noveme stops \\nwith a ticket in someone else’s queue. We discuss that in more detail in Part III. \\nAn example is a shared ops team accepting tickets to create environments for competing workloads \\nand priorities. It could be a ticket with procurement and finance to get some more servers to increase \\ncapacity or security by running a vulnerability scan. We should automate these processes as a priority; \\narguably, they are the most important ones, as you have no control over them. \\nProcure enough capacity to give you headroom or buy resources in a public cloud with your budget. \\nHave APIs that developers can call to build standard environment definitions that ops have designed and \\nsigned off. Have APIs for the security tools so that developers can initiate the vulnerability scan themselves \\nthat security has developed and approved. We want all the activities within the pipeline to get a noveme \\nto release, delegated to the product team themselves to have no external lead times. It provides control \\nover the end-to-end pipeline of your novemes and creates the opportunity to increase overall flow. \\nYou should aim to have all the cells operated within your product team within your pipeline, even if \\npeople own and control them externally. If you empower developers to build their environments, you can \\nbreak the dependency on the shared ops team outside the pipeline. But communications between people \\nwithin and outside of the pipeline are still required. \\nIn the physical world, the car assembly line depends on the car seat assembly line. Suppose a developer \\nrequires changes to the environment template, such as a change in middleware technology; \\ncommunication channels still need to exist. Depending on the infrastructure, you will often find \\ndependencies between pipelines, such as the application layer. These dependencies are adjacent, and \\ncommunication will be frequent but usually less frequent than within the pipeline’s cells. \\nQuite often, we communicate this information via a ticketing system. It is very impersonal and treats \\nthe other service as a black box. We must foster collaboration between these pipelines as we work on a \\ncommon goal. The operations team is a group of external stakeholders in your pipeline. If you want this \\ninterface to work, you must communicate more effectively here. \\nRelationships between the people in both pipelines need to be encouraged and nurtured. We must align \\nthe management layers towards a common goal of increasing the value of our products. Professional', metadata={'page': 92, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})],\n",
       " 'question': 'My developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time?',\n",
       " 'text': \"\\n### [INST] \\nInstruction: Answer the question based on your knowledge from the files in the vector database only.\\nDon't use expletives or bad language.\\nIf you can't answer the appoligise and say you don't know.\\nDon't make up answers. Please limit your answer to 200 words or less. Here is context to help:\\n\\n[Document(page_content='213 Epilogue \\\\nHopefully, we can draw enough parallels between the improvements made in the Lean physical product \\\\nproduction world and apply them to our digital pipelines. We can increase the efficiency of releasing \\\\nnovemes into our products by changing how we approach the introduction of changes. \\\\nWe aim to decrease the size of novemes to get close to single-piece flow to allow us to increase our \\\\nrelease frequency and decrease our release complexity. We achieve this by having developers check code \\\\nin more frequently and automate the testing of releases to ensure that they won’t cause problems and \\\\ncapture issues quickly. \\\\nTo make this easier for our developers, we look at the whole lifecycle of our product from the outset in \\\\nany change we make to it. We structure everyone involved in introducing novemes into sequential, \\\\nfunctional cells that self-organize. Each cell treats its downstream cell as its primary customer to ensure a \\\\nsmooth handover of work from one to the next and allow the introduction of automation. When we add \\\\nautomation, we set up guide rails that will enable us to delegate responsibility upstream or shift left to \\\\nreduce the wait time of work downstream. \\\\nTo govern this end-to-end process, we empower our product manager to have overall authority for the \\\\nproduct and its delivery pipeline. This person will make appropriate measurements at every step of the \\\\nprocess and within the product to create short feedback loops that allow us to keep improving our product \\\\nand its pipeline and embed a cultural appreciation of kaizen within the teams. \\\\nFaddy Toys Inc \\\\nSo how did we do in Faddy Toys? The marketing API was ready for the holiday period. \\\\nStakeholders de-scoped some features and added others, but it was there, and it was robust. \\\\nIt gave valuable insight to innovate in marketing new toy lines, which increased sales over \\\\nprevious years. The organization saw the change as a success. \\\\nThe kaizen effort continues and has a broader remit to improve existing services and \\\\nmanage new product delivery. The digital product management team now has an audible \\\\nvoice at the board level and is seen as equal to the rest of the company. IT now has support \\\\nto separate monolithic architectures to facilitate and optimize change. Devops is the default \\\\nmode of operation for any of these changes. The pipelines continue to evolve.', metadata={'page': 230, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Observe \\\\n \\\\n \\\\n39 their schedule. Limit the breakouts to a couple of hours, or you will burn people out and walk into the laws \\\\nof diminishing returns. People will drift off and start working on emails or their next book in the \\\\nbackground. \\\\nMake lots of notes, especially names, titles, and roles. You are starting your cycle of improvement now. \\\\nYou will not get everything right the first time, and you will learn as you go. You will need follow-up calls \\\\nto speak to the stakeholders you missed. It is all part of the process. Try to diagram the flows of information \\\\nand relationships. Think of the notice board in detective shows—with the photos of key people with pins \\\\nand all the string between them. \\\\nThese meetings will be the start of your collaborative journey. Many people in the room will have often \\\\ncomplained about the same issues for years. It will probably be the first time many have discussed solving \\\\nthem together . \\\\nImportant  \\\\nNot all novemes will have the same lead time in a cell. How you average it out is up to you \\\\nand what makes sense in your value stream. Keep it consistent for each cell and across all \\\\nyour value stream maps. These measurements can become important indicators across your \\\\ndevops transformation to show that you are progressing. \\\\n \\\\nLead Time \\\\nIn the lead time  image, you can see outliers, deviations, and variations within the data. \\\\nConsider these at the start to ensure that you have a measurement practice that is flexible \\\\nenough to accommodate your whole organization. Getting this correct at the beginning will \\\\nhelp you consistently show progress over time and not waste time explaining differences in \\\\ndifferent data sets. \\\\n \\\\nWe usually break things down into manageable chunks in technical architecture and engineering. We \\\\nwill start with a high-level view and break it into pieces for a more detailed understanding. Start with the', metadata={'page': 56, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Plan \\\\n \\\\n \\\\n61 introduce changes, the more chance of success in a shorter period. Ideally, start with product development \\\\nin a single language and framework and deploy with a small set of operating technologies. \\\\nPrioritizing Products and Value Streams \\\\nValue Stream Mapping is a valuable tool to help you understand your workflow from idea to release. \\\\nYou need to engage with your stakeholders to understand the handovers, the lead times, and the queue \\\\ntimes between individuals and groups. You can then use this map to target the bottlenecks and pinch-\\\\npoints of your value stream to improve the system by employing automation or increasing the performance \\\\nof steps such as unit tests or acceptance tests. You will need to capture the following: \\\\n\\\\uf0b7 The frequency of releases: how often are releases deployed? \\\\n\\\\uf0b7 The first-time success rates of deployments and releases. \\\\n\\\\uf0b7 The ‘wait time’ of each cell. \\\\n\\\\uf0b7 The transfer time of tasks. \\\\n\\\\uf0b7 The number of people required to facilitate the step within the cell. \\\\n\\\\uf0b7 The completion time of the tasks within the cell. \\\\nOnce you have mapped your value stream, you can start to look across the flows. At its heart, D4DO \\\\nimprovement is about facilitating the flow of novemes through your products to make them more efficient. \\\\nWe will realize the most gain from the products which see the most change. It is vital to approach all your \\\\nstakeholders when comparing the rate of change through various pipelines. A developer or ops engineer \\\\nwill know the rate of novemes today and provide a baseline. \\\\nIn contrast, a product manager or salesperson will look toward a more distant horizon with a long view \\\\nof change. It gives you a baseline for improvement. Examine the one-year horizon of the pipeline. It is \\\\nlikely to be the implementation timeframe of your devops transformation. If you are approaching a \\\\nsignificant milestone in your value stream, avoid activities that detract from it. Adversely impacting in-\\\\nflight activities may damage the reputation of your broader transformation program. If your next \\\\nsignificant milestone is one year away, you can aim to complete your transformation within that time. \\\\nAfter prioritizing the product for transformation, you must prioritize the value streams. Again, as a rule \\\\nof thumb, the value streams that see the most change will benefit the most from transformation. For \\\\nexample, an e-commerce site’s front end must frequently change to maintain consumer interest. The \\\\nsystems of record behind it, such as large databases, will usually change less regularly (unless we have \\\\nclosely coupled architectures - but more on that topic later).', metadata={'page': 78, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Do \\\\n \\\\n \\\\n75 above a specific size, this becomes the exception rather than the norm with numerous products and value \\\\nstreams. \\\\nOften there will be a shared function for operations, security, procurement, and finance. If this is the \\\\ncase, you need to automate the interfaces with the cells dependent on the people outside your direct \\\\nproduct team. What does that mean? You need to avoid the situation where the flow of your noveme stops \\\\nwith a ticket in someone else’s queue. We discuss that in more detail in Part III. \\\\nAn example is a shared ops team accepting tickets to create environments for competing workloads \\\\nand priorities. It could be a ticket with procurement and finance to get some more servers to increase \\\\ncapacity or security by running a vulnerability scan. We should automate these processes as a priority; \\\\narguably, they are the most important ones, as you have no control over them. \\\\nProcure enough capacity to give you headroom or buy resources in a public cloud with your budget. \\\\nHave APIs that developers can call to build standard environment definitions that ops have designed and \\\\nsigned off. Have APIs for the security tools so that developers can initiate the vulnerability scan themselves \\\\nthat security has developed and approved. We want all the activities within the pipeline to get a noveme \\\\nto release, delegated to the product team themselves to have no external lead times. It provides control \\\\nover the end-to-end pipeline of your novemes and creates the opportunity to increase overall flow. \\\\nYou should aim to have all the cells operated within your product team within your pipeline, even if \\\\npeople own and control them externally. If you empower developers to build their environments, you can \\\\nbreak the dependency on the shared ops team outside the pipeline. But communications between people \\\\nwithin and outside of the pipeline are still required. \\\\nIn the physical world, the car assembly line depends on the car seat assembly line. Suppose a developer \\\\nrequires changes to the environment template, such as a change in middleware technology; \\\\ncommunication channels still need to exist. Depending on the infrastructure, you will often find \\\\ndependencies between pipelines, such as the application layer. These dependencies are adjacent, and \\\\ncommunication will be frequent but usually less frequent than within the pipeline’s cells. \\\\nQuite often, we communicate this information via a ticketing system. It is very impersonal and treats \\\\nthe other service as a black box. We must foster collaboration between these pipelines as we work on a \\\\ncommon goal. The operations team is a group of external stakeholders in your pipeline. If you want this \\\\ninterface to work, you must communicate more effectively here. \\\\nRelationships between the people in both pipelines need to be encouraged and nurtured. We must align \\\\nthe management layers towards a common goal of increasing the value of our products. Professional', metadata={'page': 92, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})]\\n\\n### QUESTION:\\nMy developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time? \\n\\n[/INST]\\n \\nTo reduce your lead time, you can consider implementing the following practices:\\n\\n1. Automate the installation process: Instead of having your developers manually install the software in production systems, you can automate the process using tools like Ansible, Terraform, or Puppet. This will save time and reduce errors.\\n2. Use containerization: Containerization allows you to package your software along with its dependencies into a single unit that can be easily deployed and run in different environments. This can significantly reduce your lead time by eliminating the need for manual configuration and setup.\\n3. Implement continuous integration and deployment (CI/CD): CI/CD automates the building, testing, and deployment of your software, reducing the time it takes to release new versions. By setting up automated builds and deployments, you can ensure that your software is always up-to-date and ready for production.\\n4. Prioritize your software releases: Focus on releasing the most critical software updates first, rather than trying to release everything at once. This will help you reduce your lead time by ensuring that your most important software updates are delivered quickly.\\n5. Monitor your lead time: Regularly monitor your lead time to identify areas where you can improve. Look for bottlenecks in your software development and deployment processes and work to eliminate them.\\n6. Collaborate with your operations team: Work closely with your operations team to ensure that your software is properly installed\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"My developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time?\"\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf7ff7-01eb-4ce4-a29c-92903c7a3aaa",
   "metadata": {},
   "source": [
    "### QUESTION:\\nMy developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time? \\n\\n[/INST]\\n \\nTo reduce lead time, you can consider implementing agile practices such as documenting bugs globally, using short daily meetings to flag items up and collaborate further, and breaking down deliverables into smaller, prioritized chunks. Additionally, you can focus on automating processes and reducing external dependencies to increase overall flow and reduce lead time. Encouraging collaboration between teams and fostering effective communication can also help to reduce lead time and improve overall productivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df285ad5-69f1-4242-8489-9a8cb406dcf5",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This was quite simple to set up on a local laptop. It demonstrates that generative AI is achievable with modest resources and in short time periods. Before you jump in, be sure to check out my blog on [Generative AI and RAG Security](https://).\n",
    "\n",
    "I'll be taking this project further and blogging along the way. I'll be talking about the environment I used to build this demo, how I productionise the system, package it and host it, and adding a front end so that you can interact with the book yourselves!\n",
    "\n",
    "You can download this blog as a Jupyter notebook file [here](https://github.com/tudor-james/ai-playground/blob/main/mistral-rag-langchain-chromadb.ipynb). As ever, if you need help with AI projects you can get in touch with Methods or contact us via LinkedIn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d48bd0f-8f68-4647-9acf-f272d80409bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Whatis your question? what name does designed4devops give to the concept of an idea or change as it flows through the value stream?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Observe \\n \\n \\n33 My background is as an engineer and technical architect. The critical skill in both roles is breaking \\nproblems into solvable chunks that I can work on separately. An organization, and the value streams \\nwithin it, are complex systems. By logically isolating processes and subprocesses, we can \\nredesign our organization’s value streams to optimize the flow of novemes. \\ndesigned4devops uses this approach to implement digital transformation . \\nI have also created a hierarchy of value streams within the products’ four phases. It allows us to develop \\na level of abstraction between functions of the value streams. An abstraction is a valuable tool for \\ndecoupling complicated dependencies. It reduces the level of complexity and simplifies the challenges \\nahead. \\nWe can divide our value stream into four phases through a product’s life. Considering all four phases \\nallows us to optimize the delivery flow of our product and integrate it into our broader business processes. \\n \\nThe four phases of a product’s lifecycle management \\ndesigned4devops  sets out to increase the flow of novemes through this lifecycle while improving \\nfeedback and acting on it quickly. The four phases are: \\n\\uf0b7 Phase 1 – Design \\nDesign is the up-front set of activities to introduce change.', metadata={'page': 50, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Part III - WHAT - A Model Value Stream - Phase 1 - Design \\n \\n \\n90 Phase 1 - Design \\nIn the design phase, feature requests or bug fixes are evaluated and selected for incorporation with the \\nproduct. It is where the preparation activities, such as design, approval, and procurement, occur. Many of \\nthese cells possess the worst lead times in the flow of novemes through our products’ value streams. The \\nsections that follow address these high-level cells to optimize flow. \\n \\nDesign Phase \\nThe diagram below, Design Phase , shows the cells we will address. The gatekeeper of the system is the \\nproduct manager. The architecture cells are typical of Enterprise Architecture (EA). Although EA can \\nresult in anti-patterns that encourage waterfall delivery and prevent agility, designed4devops  is not \\nintrinsically at odds with traditional EA and can even accommodate your EA lifecycle. We will look at this \\nin more detail later in the book. \\n \\nDesign Phase Value Stream', metadata={'page': 107, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='designed4devops', metadata={'page': 0, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}),\n",
       "  Document(page_content='Background \\n \\niii \\n With designed4devops  and its framework, I aim to give you a structure to use DevOps to design and \\ndeliver Digital Transformation within your organization.', metadata={'page': 12, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})],\n",
       " 'question': 'what name does designed4devops give to the concept of an idea or change as it flows through the value stream?',\n",
       " 'text': '\\n### [INST] \\nInstruction: Answer the question based on your knowledge from the files in the vector database only.\\nDon\\'t use expletives or bad language.\\nIf you can\\'t answer the appoligise and say you don\\'t know.\\nDon\\'t make up answers. Please limit your answer to 200 words or less. Here is context to help:\\n\\n[Document(page_content=\\'Observe \\\\n \\\\n \\\\n33 My background is as an engineer and technical architect. The critical skill in both roles is breaking \\\\nproblems into solvable chunks that I can work on separately. An organization, and the value streams \\\\nwithin it, are complex systems. By logically isolating processes and subprocesses, we can \\\\nredesign our organization’s value streams to optimize the flow of novemes. \\\\ndesigned4devops uses this approach to implement digital transformation . \\\\nI have also created a hierarchy of value streams within the products’ four phases. It allows us to develop \\\\na level of abstraction between functions of the value streams. An abstraction is a valuable tool for \\\\ndecoupling complicated dependencies. It reduces the level of complexity and simplifies the challenges \\\\nahead. \\\\nWe can divide our value stream into four phases through a product’s life. Considering all four phases \\\\nallows us to optimize the delivery flow of our product and integrate it into our broader business processes. \\\\n \\\\nThe four phases of a product’s lifecycle management \\\\ndesigned4devops  sets out to increase the flow of novemes through this lifecycle while improving \\\\nfeedback and acting on it quickly. The four phases are: \\\\n\\\\uf0b7 Phase 1 – Design \\\\nDesign is the up-front set of activities to introduce change.\\', metadata={\\'page\\': 50, \\'source\\': \\'/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\\'}), Document(page_content=\\'Part III - WHAT - A Model Value Stream - Phase 1 - Design \\\\n \\\\n \\\\n90 Phase 1 - Design \\\\nIn the design phase, feature requests or bug fixes are evaluated and selected for incorporation with the \\\\nproduct. It is where the preparation activities, such as design, approval, and procurement, occur. Many of \\\\nthese cells possess the worst lead times in the flow of novemes through our products’ value streams. The \\\\nsections that follow address these high-level cells to optimize flow. \\\\n \\\\nDesign Phase \\\\nThe diagram below, Design Phase , shows the cells we will address. The gatekeeper of the system is the \\\\nproduct manager. The architecture cells are typical of Enterprise Architecture (EA). Although EA can \\\\nresult in anti-patterns that encourage waterfall delivery and prevent agility, designed4devops  is not \\\\nintrinsically at odds with traditional EA and can even accommodate your EA lifecycle. We will look at this \\\\nin more detail later in the book. \\\\n \\\\nDesign Phase Value Stream\\', metadata={\\'page\\': 107, \\'source\\': \\'/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\\'}), Document(page_content=\\'designed4devops\\', metadata={\\'page\\': 0, \\'source\\': \\'/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\\'}), Document(page_content=\\'Background \\\\n \\\\niii \\\\n With designed4devops  and its framework, I aim to give you a structure to use DevOps to design and \\\\ndeliver Digital Transformation within your organization.\\', metadata={\\'page\\': 12, \\'source\\': \\'/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\\'})]\\n\\n### QUESTION:\\nwhat name does designed4devops give to the concept of an idea or change as it flows through the value stream? \\n\\n[/INST]\\n \\nDesigned4DevOps gives the concept of an idea or change as it flows through the value stream the name \"novemes.\"'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = input('Whatis your question?')\n",
    "rag_chain.invoke(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3bfd514-69e4-43c6-b14a-11a9f74a46bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "# GET /notebook\n",
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c9336-ea1f-4144-9aa4-1086862b19db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
