{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81544e7-f1c5-44cf-9faf-d7f2bc852117",
   "metadata": {},
   "source": [
    "# The hitchhiker's guide to Jupyter (part 5/n)\n",
    "\n",
    "## Let's create a Generative AI chatbot using RAG to talk to my book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea7779-0905-41f2-bb52-506fe08be871",
   "metadata": {},
   "source": [
    "I'm going to implement local chatbot on my laptop to talk to my book, [\"Designed4Devops\"](https://designed4devops.com). This will allow a user to be able to ask questions of the book and summarise its contents. My book is self-published and copywrite so it shouldn't appear in models' training data. To achieve this I'm going to RAG or _Retrieval Augmented Generation_. \n",
    "\n",
    "## RAG\n",
    "\n",
    "RAG is a technique that allows you to add data to a LLM after the model was trained, without retraining or finetuning it. Training models requires access to large and often numerous high-end GPUs. This can be expensive. It also has the downside that if you want to update the data, you need to retrain the model again.\n",
    "\n",
    "RAG overcomes this by taking the data (e.g., PDF, CSV, HTML) and vectorising it. Remember that models work by matrix multiplations of numbers not text. We use a model to embed the text as numbers in a vectore store. This allows the LLM to query the data with symantec searching. The model then returns results based on the context of the query given.\n",
    "\n",
    "Let's set up the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238abf1f-e8ff-4913-9d4a-cf53f5a32b15",
   "metadata": {},
   "source": [
    "### First, we'll install the dependencies and set up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a275d0f8-7cb0-45c8-9fa7-3af48132bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall -Uq 'torch==2.2.2' datasets accelerate peft bitsandbytes transformers trl 'numpy<2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8c7aeb-f605-43aa-9bdf-4fccc798d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import datasets\n",
    "import accelerate\n",
    "import peft\n",
    "import bitsandbytes\n",
    "import trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76fff367-5df0-4c0f-9ec0-59013aa3eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoModel, MistralForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ebad1-ceb1-454b-936f-9bf54fadc68d",
   "metadata": {},
   "source": [
    "This sets up the tokeniser. This breaks the text up into tokens (chunks) which can be individual words or fragments of words.\n",
    "\n",
    "I'm going to use Mistral 7B as it offers a good performance at a low overhead of processing and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e7bb7e-1a11-4bfe-9b4d-29f60b0250b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='../models/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bff158-c603-4bd4-ba4b-5b2d61a8325b",
   "metadata": {},
   "source": [
    "#### Quantization of the Model\n",
    "\n",
    "I'm going to quantize the model to 4 bits. This lowers the precision of the data types (int4 vs fp16 or fp32), which reduces the overheads even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac06130-f66b-4341-9ee9-6197cd2effa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72d5f88-8577-47f8-922a-740690132e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa1b72b-f025-4aec-b992-24b36bcdeab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc44133-d625-4336-88ab-ad02644a0705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae3d5282cd746acac11f8d3d3c8e212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "# model = AutoModel.from_pretrained(\n",
    "model = MistralForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea67554-a91f-4008-bdcc-fcc24e2d6c8d",
   "metadata": {},
   "source": [
    "#### Let's test it..\n",
    "\n",
    "This query asks the model a question. We haven't loaded any of our data into it yet, this is all information held within the model from its training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e1adf3-fdb0-4553-92a8-7208a5921c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> [INST] What is Designed4Devops? [/INST] Designed4DevOps is an open-source, automated testing framework for DevOps pipeline management for Windows, Mac, and Linux operating systems. It is designed to be easy to use and offers a wide range of features, including continuous integration and continuous delivery support, automated testing for both traditional Microsoft technologies and modern open source technologies, and built-in debugging and reporting capabilities. Designed4DevOps was originally developed by Microsoft, and it is released under the MIT license.</s>']\n"
     ]
    }
   ],
   "source": [
    "inputs_not_chat = tokenizer.encode_plus(\"[INST] What is Designed4Devops? [/INST]\", return_tensors=\"pt\")['input_ids'].to('cuda')\n",
    "\n",
    "generated_ids = model.generate(inputs_not_chat, \n",
    "                               max_new_tokens=1000, \n",
    "                               do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3907e9-d871-4f3e-b605-142c42d859cf",
   "metadata": {},
   "source": [
    "___COMPLETE HALUCINATION!___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0baba-0611-4acc-b0f6-8d436bb6fac5",
   "metadata": {},
   "source": [
    "#### Create the vector database\n",
    "\n",
    "I'm going to use ChromaDB, which is a lightweight local vector store, to hold the embeddings of the books text that will come from the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64eb884e-6087-4ddf-b7c1-be7b26fb27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uq langchain chromadb openai tiktoken sentence-transformers pypdf langchain-community langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a052fb6d-8a53-4894-b1d4-e3de5173d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "# from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "import nest_asyncio\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough, RunnableSequence\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.output_parsers.json import SimpleJsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb335d0-445e-4a47-8082-9ea021fd1ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load the book\n",
    "loader = PyPDFLoader(\"/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Chunk text\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunked_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# Load chunked documents into the Chroma index\n",
    "db = Chroma.from_documents(chunked_documents, embedding_function)\n",
    "\n",
    "# Connect query to Chroma index using a retriever\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 4}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed6733c-07b0-4868-9a43-77193e0fb9c2",
   "metadata": {},
   "source": [
    "#### Test the vector store\n",
    "\n",
    "This tests that the data exists within the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee5ed610-a64b-470a-a391-259bc771dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "designed4devops\n"
     ]
    }
   ],
   "source": [
    "query = \"What can designed4devops do for my organisation?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b617a88c-1c08-4fc0-a180-3edc72d77924",
   "metadata": {},
   "source": [
    "#### Create the LLM chain\n",
    "\n",
    "To create a symantically aware search, we need to store the context of the question, and engineer a prompt that focuses the model on answering questions using the data from our vector store instead of making it up (hallucinating). Prompt engineering is a way to coach the model into giving the sort of answers that you want return and filter those that you don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b621af5-c5b3-4e6e-8304-884d04dc4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "# from langchain.chains import LLMChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d1916-ac2b-49fb-a96d-60329064a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=300,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "### [INST] \n",
    "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
    "Don't use expletives or bad language.\n",
    "If you can't answer the appoligise and say you don't know.\n",
    "Don't make up answers. Please limit your answer to 500 words or less. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} \n",
    "\n",
    "[/INST]\n",
    " \"\"\"\n",
    "\n",
    "# mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "# llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "llm_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2eb0d6c3-1ae1-4041-a822-1e1ad9a66734",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "def test_rag(qa, query):\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    time_1 = time()\n",
    "    # result = qa.run(query)\n",
    "    result = rag_chain.invoke(query)\n",
    "    time_2 = time()\n",
    "    print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n",
    "    print(\"\\nResult: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8fb3a5-f435-4a19-956e-e4a6d2cb2dc0",
   "metadata": {},
   "source": [
    "#### Create RAG Chain\n",
    "\n",
    "This chains the prompt with the question to _hopefully_ get a strong answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7771491-5768-4f6e-b17a-1c8e8178a58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Summarize the text in the vector database.\n",
      "\n",
      "Inference time: 28.068 sec.\n",
      "\n",
      "Result:  \n",
      "### [INST] \n",
      "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
      "Don't use expletives or bad language.\n",
      "If you can't answer the appoligise and say you don't know.\n",
      "Don't make up answers. Please limit your answer to 200 words or less. Here is context to help:\n",
      "\n",
      "[Document(page_content=\"Part III - WHAT - A Model Value Stream- Phase 1 - Design \\n \\n \\n100 They will interview users, conduct workshops, and complete surveys using analytical methods and their \\nexperience to understand the requirements and their context better. They will turn the requirements into \\nuser stories. \\nA user story is a user-centric definition of what the target user tries to achieve with the requirement. It \\nwill be unambiguous and allow a developer to code the functionality without a back-and-forth exchange \\nof information that will slow down cadence. \\nA user story might look like, “I want to add details to a user ticket by editing the record when I have \\nselected it from the list of tickets available.” It should have enough information so the developer can \\nunderstand the user's intent, picture themselves in their position, and walk through their actions in their \\nmind. \\nBusiness analysis is critical to agile development in many ways. Its purpose is to remove ambiguity. \\nPeople can only do it with enough experience in the field of what they are doing. They usually have a \\nbackground in the industry vertical you are serving. It is a skilled role that involves using experience and \\nan analytical approach to design with an ability to communicate and empathize with the users. A good \\nbusiness analyst will have a toolbox of techniques to work with users to drive the requirements gathering \\nand create user stories from them. \\nBusiness analysis is the bridge between addressing the business, the organizational or social need to \\nsolve a problem or perform a task, and the system's design that addresses that need. \\nUser Researcher \\nUser research is the understanding of human behavior when interacting with products. A user \\nresearcher will observe users' behavior to drive the product's design. BAs will analyze the data gathered in \\nthis exercise to inform the UX (user experience) design and improve the product's usability. \\nUser researchers may sit and observe the users directly and use data from systems or eye-tracking \\nsoftware on a cohort of users who volunteer for testing. It provides feedback to the UX design to increase \\nthe product's usability, efficiency, accessibility, and reach.\", metadata={'page': 117, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='218 84, 87, 91, 92, 94, 95, 96, 97, 98, 101, 104, 114, 115, \\n119, 120, 121, 122, 126, 133, 135, 136, 142, 148, 149, \\n150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 162, \\n163, 164, 165, 167, 169, 171, 172, 173, 176, 180, 181, \\n184, 185, 191, 192, 195, 196, 197, 198, 199, 200, 201, \\n202, 203, 205, 210, 211, 212, 213 \\npizzas, 68, 79 \\nPolicy, 132, 134, 135, 137, 138 \\nProcedures, 139 \\nprocurement, v, 6, 11, 20, 28, 45, 52, 53, 58, 59, 62, 64, \\n69, 70, 71, 75, 76, 90, 108, 123, 124, 125, 126, 141, \\n142, 197, 200, 208 \\nProduct Lifecycle, 32 \\nProduct Manager, 69, 70, 78, 91, 93 \\nQuality, 96, 97 \\nRecovery Point Objective, 92, 105, 118 \\nRecovery Time Objective, 91, 105, 118 \\nReleasing, 97, 129, 177, 207 \\nRetirement, 205, 206, 207, 209 \\nReuse, 126, 210 \\nrisk, 5, 8, 9, 14, 24, 31, 34, 36, 46, 53, 57, 60, 67, 93, 96, \\n99, 108, 109, 111, 113, 119, 122, 128, 129, 130, 135, \\n137, 143, 168, 174, 177, 179, 183, 197, 200, 203, 206, \\n207, 212 \\nRobustness, 98 \\nScrum, 7, 49, 81, 82, 83 \\nServerless, 163 \\nService hours, 92, 105 \\nSite Reliability Engineering , 159 \\nSLA, 23, 94, 119, 121, 183 \\nSLI, 183 \\nSLO, 118, 183 \\nSRE, 159 \\nStandards, 137, 138 stateful, 107, 119, 155 \\nStateful architectures, 107 \\nStatelessness, 155 \\nStrategy, 22, 131 \\nTaguchi, 98, 215 \\ntechnical debt , 19, 23, 24, 46, 47, 49, 50, 52, 55, 70, 72, 79, \\n82, 97, 108, 121, 128, 129, 136, 150, 163, 164, 172, \\n173, 190, 202 \\nTesting, 103, 147, 165, 166, 167, 168, 169, 170, 171, 174, \\n175, 207, 215 \\nTIMWOODS, 43 \\nTwelve Principles , 81 \\ntwo-pizza team , 78 \\nunit testing , 148 \\nUser experience, 101 \\nvalue stream, 8, 12, 13, 14, 15, 16, 17, 18, 20, 28, 29, 31, \\n32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 57, 58, 59, 60, \\n61, 62, 63, 64, 65, 67, 68, 70, 71, 77, 80, 87, 89, 91, \\n92, 93, 95, 104, 105, 106, 107, 113, 123, 124, 128, 129, \\n130, 131, 133, 137, 138, 139, 140, 141, 142, 144, 159, \\n161, 164, 170, 181, 194, 212 \\nValue Stream, 41, 42, 43, 60, 61, 89, 90, 101, 145, 181, \\n204 \\nvalue streams, v, 12, 16, 29, 30, 33, 38, 40, 42, 43, 59, \\n60, 61, 62, 63, 65, 70, 71, 73, 75, 78, 90, 104, 112, 131, \\n138, 139, 141, 142, 155, 173, 212 \\nVelocity, 185 \\nWaste, 6, 43, 81, 207, 215 \\nWIP, 14, 17, 18, 48, 49, 50, 52, 57, 82, 92, 95, 146, 164, \\n185 \\nWork in progress, 81 \\nWork in Progress , 14, 18, 95 \\nWork-In-Progress, 17, 80, 136', metadata={'page': 235, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='217 Index \\naccessibility, 100, 101, 102, 103, 137, 168, 190 \\nAgile, 13, 62, 77, 81, 82, 83, 84, 104 \\nAnalysis, 97, 99, 107, 146, 173 \\nArchitecture, 6, 9, 42, 90, 101, 104, 105, 108, 109, 116, \\n117, 118, 125, 126, 172, 196, 201 \\nartifacts, 44, 153, 156, 158, 160, 163, 174 \\nAutomation, 18, 48, 49, 65, 139, 152, 157, 175, 179, 215 \\nAvailability Target, 91, 105, 118 \\nAXSChat , 102 \\nBi-modal, 8 \\nblue/green, 129, 160, 162, 178, 206 \\nBurndown, 185 \\nCanary Releases, 167, 178 \\ncell, 10, 16, 17, 18, 19, 20, 32, 35, 37, 39, 41, 42, 49, 52, \\n56, 57, 59, 60, 61, 70, 77, 78, 79, 80, 82, 86, 91, 93, \\n95, 101, 104, 105, 106, 107, 108, 117, 118, 126, 141, \\n144, 149, 163, 164, 166, 175, 180, 184, 185, 200, 201, \\n210, 212, 213 \\nChaos Engineering , 154 \\ncode repository, 67, 114, 151, 152, 153, 156, 159, 165, \\n173 \\ncontainer, 20, 82, 114, 115, 121, 138, 156, 163, 176, 186, \\n189, 192 \\nContinuous deployment, 160 \\nContinuous Integration, 151, 155, 163 \\nculture, ii, vii, 8, 9, 11, 12, 13, 14, 22, 23, 24, 31, 54, 55, \\n56, 58, 60, 62, 67, 68, 69, 71, 101, 112, 126, 165, 194, \\n210 \\ndefects, 17, 25, 43, 52, 69, 84, 98, 148, 149, 167, 185 \\nDefinition of Done, 82 \\nDeming, 31 \\ndesign phase, 42, 90 \\ndevelopment , ii, 5, 8, 11, 15, 18, 32, 34, 35, 36, 40, 41, \\n49, 52, 57, 58, 60, 61, 63, 70, 71, 72, 82, 93, 99, 100, \\n106, 116, 126, 127, 128, 130, 131, 132, 133, 135, 136, \\n137, 138, 145, 146, 147, 148, 149, 150, 152, 154, 155, \\n157, 159, 160, 161, 163, 164, 165, 173, 180, 184, 198, \\n199, 200 \\nDevops, 9, 13, 14, 15, 17, 19, 22, 35, 37, 53, 94, 129, \\n150, 196, 199, 213 \\nDigital Transformation, iii, ii, iii \\ndiversity, 24, 55, 68 \\nDomain-Driven Design, 112 \\nFeature flags, 177 \\nfeedback, v, 6, 14, 31, 33, 34, 37, 52, 57, 58, 67, 68, 73, \\n82, 96, 97, 100, 129, 132, 133, 137, 138, 144, 148, 150, \\n152, 153, 154, 155, 160, 161, 162, 164, 165, 166, 168, \\n169, 170, 172, 175, 181, 182, 184, 191, 193, 194, 195, \\n196, 197, 200, 201, 202, 211, 213, 214 \\nflow, ii, v, viii, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, \\n19, 21, 22, 23, 24, 32, 33, 36, 37, 38, 40, 42, 43, 45, 48, 55, 59, 60, 61, 64, 65, 69, 70, 72, 73, 74, 75, 77, \\n79, 80, 81, 82, 83, 87, 90, 91, 92, 93, 94, 95, 96, 97, \\n98, 101, 103, 105, 106, 108,110, 111, 113, 116, 119, \\n120, 126, 129, 131, 135, 136, 139, 140, 144, 146, 147, \\n149, 153, 160, 161, 162, 163, 164, 166, 167, 168, 171, \\n177, 185, 196, 198, 205, 212, 213 \\nfunctional requirements, 34, 97, 105, 107, 116, 117, 118, \\n119, 126, 173 \\nGlue, 150 \\nGovernance , 29 \\nGuidance, 138, 154 \\nImmutable, 113, 178, 206 \\ninfrastructure-as-code, 157, 174, 178, 201 \\ninnovation, ii, vii, 6, 7, 8, 9, 23, 24, 25, 31, 53, 69, 93, \\n108, 139, 141, 162 \\nITSM, 183, 194, 197, 198, 199, 200 \\nkaizen, 11, 14, 28, 29, 30, 31, 32, 38, 62, 63, 67, 68, 70, \\n84, 85, 86, 114, 133, 181, 182, 200, 213 \\nKaizen, 11, 29 \\nKanban, 7, 49, 82, 83 \\nKPI, 183, 186 \\nKPIs, 106, 183, 186, 188, 192 \\nLead time, 16, 185 \\nlean, ii, viii, 4, 9, 10, 11, 13, 30, 57, 62, 68, 70, 83, 87, \\n108, 197, 214 \\nloosely coupled, 109 \\nmetrics, 30, 32, 41, 68, 85, 149, 153, 175, 182, 183, 184, \\n185, 186, 188, 189, 190, 202 \\nMetrics, 188, 189, 190 \\nmicroservice, 109, 111, 133, 187, 189, 192 \\nMicroservices, 110, 111 \\nMinimum Viable Product , 36 \\nmonitoring, 14, 32, 34, 50, 84, 97, 114, 117, 122, 123, \\n124, 127, 130, 153, 161, 162, 186, 187, 189, 191, 192, \\n194, 198 \\nMVP, 36, 37, 83, 94, 150, 176 \\nNIST, 115, 122 \\nNorth Star, 131 \\nnovemes, 8, 11, 13, 14, 17, 18, 19, 22, 24, 32, 33, 34, 35, \\n36, 37, 39, 40, 42, 55, 57, 61, 69, 74, 75, 77, 78, 79, \\n80, 82, 87, 90, 91, 92, 93, 94, 95, 96, 97, 99, 106, 110, \\n111, 114, 120, 126, 128, 129, 131, 136, 139, 141, 142, \\n144, 145, 146, 163, 165, 167, 175,177, 178, 179, 184, \\n185, 190, 191, 197, 200, 201, 202, 205, 209, 210, 211, \\n212, 213, 214 \\nOLA, 183 \\nOrchestration, 151, 158 \\nPackaging, 163 \\npipeline, ii, v, 6, 7, 10, 13, 14, 15, 16, 17, 18, 24, 25, 31, \\n32, 34, 35, 36, 37, 38, 43, 44, 45, 47, 48, 50, 51, 52, \\n54, 55, 58, 61, 69, 72, 74, 75, 76, 77, 78, 79, 82, 83,', metadata={'page': 234, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Selecting Novemes \\n \\n \\n93 Designed4: Selecting Novemes \\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\nfor further development. \\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\ndownstream one above all others. \\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\ncost required for the investment. The following are examples of information typically captured: \\n\\uf0b7 Feature request or bug fix \\n\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\n\\uf0b7 Required by whom? \\n\\uf0b7 Change to existing service or new service \\n\\uf0b7 Number of identical or similar requests \\nEstimation \\nMost organizations will want to track their costs in some form or another. In publicly listed \\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\n\\uf0b7 Upfront and ongoing costs for the noveme \\n\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\n\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\n\\uf0b7 The expected return on the investment in the noveme \\n\\uf0b7 The length of time required for the noveme to realize its benefits \\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid', metadata={'page': 110, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})]\n",
      "\n",
      "### QUESTION:\n",
      "Summarize the text in the vector database. \n",
      "\n",
      "[/INST]\n",
      " \n",
      "The text describes a process called \"Designing\" in a value stream. This process involves selecting novemes, which are user requirements or feature requests, and defining the input criteria for each noveme. The inputs capture information such as the type of noveme, customer priority, and number of similar requests. Estimates are also taken into account, including upfront and ongoing costs, effort to build and run the noveme, and expected return on investment. The goal is to provide a cost-benefit analysis of the investment size in people and resources compared to their payback.\n"
     ]
    }
   ],
   "source": [
    "query = \"Summarize the text in the vector database.\" \n",
    "\n",
    "test_rag(qa, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ffbf2-ffd4-463d-9cb4-6e9e60923afa",
   "metadata": {},
   "source": [
    "## The Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3bf2727-cc6b-4853-ac8f-de9c4316c273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do I make the transition of novemes more efficient?\n",
      "\n",
      "Inference time: 28.967 sec.\n",
      "\n",
      "Result:  \n",
      "### [INST] \n",
      "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
      "Don't use expletives or bad language.\n",
      "If you can't answer the appoligise and say you don't know.\n",
      "Don't make up answers. Please limit your answer to 200 words or less. Here is context to help:\n",
      "\n",
      "[Document(page_content='Designed4: Selecting Novemes \\n \\n \\n95 \\uf0b7 Security vulnerabilities - any critical security vulnerabilities should be able to jump the queue! \\nAnother selection criterion that might be important is the cost/benefit relationship identified at the \\nestimation stage. Many organizations expect a return on investments within a specified period. Not all \\ninvestments will be financial. For example, you may have a security bug that requires fixing. You may be \\nmorally or contractually obliged to remedy the known bug within a defined period of its discovery or \\ndisclosure. \\nWork in Progress (WIP) \\nWhen selecting novemes, you need to consider the pipeline’s capacity. Any work put into the pipeline \\nwill be processed at each cell, requiring people and resources. If we keep adding novemes into the pipe \\nwithout considering the flow rate downstream, we will inevitably cause blockages further down the value \\nstream as we hit bottlenecks. Restricting the Work in Progress (WIP) is probably the most critical method \\nto optimize flow through the value stream. \\nWe should meet, discuss, and collaborate with our downstream cell to understand the resources and \\nstaffing levels available to process new novemes. Do not hold novemes back upstream to relieve our \\ndownstream cell’s pressure; it will mask the problems downstream. We should expose the takt time of the \\ndownstream cell to get more investment. We can report back to our bug-track systems in the tickets to set \\nexpectations regarding expectations for timescales. Once we send the noveme downstream, we might no \\nlonger directly see its status. It is related to the number of people you have in the cells’ teams and the takt \\ntime to process novemes.', metadata={'page': 112, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Selecting Novemes \\n \\n \\n93 Designed4: Selecting Novemes \\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\nfor further development. \\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\ndownstream one above all others. \\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\ncost required for the investment. The following are examples of information typically captured: \\n\\uf0b7 Feature request or bug fix \\n\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\n\\uf0b7 Required by whom? \\n\\uf0b7 Change to existing service or new service \\n\\uf0b7 Number of identical or similar requests \\nEstimation \\nMost organizations will want to track their costs in some form or another. In publicly listed \\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\n\\uf0b7 Upfront and ongoing costs for the noveme \\n\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\n\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\n\\uf0b7 The expected return on the investment in the noveme \\n\\uf0b7 The length of time required for the noveme to realize its benefits \\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid', metadata={'page': 110, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Part III - WHAT - A Model Value Stream- Phase 4 - Disposal \\n \\n \\n212 Part III – Summary \\nWe have come to the end of our novemes’ journey, flowing down the pipeline. Hopefully, we will \\nachieve what we set out to do, recognize the flow of novemes through our business, and optimize their \\ndelivery. We can improve the flow by aligning the upstream cell’s outputs with the downstream’s inputs. \\nAutomating as much cell processing as possible in the pipeline will help bring down the sizes of the \\nnovemes to get as close as possible to the single-piece flow we can. It will smooth the flow, reduce the size \\nof releases, and remove the risk and anxiety from the release process itself. Reducing risk allows you to \\nembrace a constant change stream, driving improvements in your product and the pipeline that delivers \\nit. \\nRemember, this section is not a foolproof template for building a pipeline that will work in your \\nproduct. Hopefully, you can recognize the cells involved in the flow and understand their need to be more \\nefficient. We should expect every pipeline to be different. The pipeline here can be used as a reference \\npoint or model to conceptualize your pipeline. Once you understand your pipeline, you can improve it \\nusing tools such as value stream mapping. \\nThe framework in Part III is a typical value stream within digital product delivery. It is intended as a \\nreference point to discuss how flow moves between one cell and another. It is not the value stream or even \\nnecessarily the target  value stream. Value streams will necessarily vary between products, organizations, \\nand organizational units. You need to map the value streams you intend to improve.', metadata={'page': 229, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Product Management \\n \\n \\n91 Designed4: Product Management \\nThe pipeline and product must have the same owner. Moving both governance frameworks under the \\nsame umbrella will probably be your biggest and first challenge. In many organizations, product \\nmanagement and delivery are distinct and separate. \\nHaving products and pipelines under the same control means we can design and develop them to \\ncomplement each other. We aim to reduce the overall lead time, minimize the number of external \\ndependencies, and reduce noveme size to allow single-piece flow. The Product Manager responsible for \\nboth can ensure that everyone moves forward together. Remember, we want to enable global progress, not \\nlocal progress. \\nThe first task is to find someone to take this role, your Product Manager. \\nProduct Manager Role \\nThe best way to increase the flow for the noveme selection is to have it done by someone trained and \\nexperienced in product management and with devops experience. The Product Manager role is the \\ngatekeeper for the whole value stream, and as such, it is their job to balance the flow of work going into \\nthe pipeline with the pipeline’s output rate. We must not add novemes from the backlog to process faster \\nthan we can handle them, as this will only expose the pinch-points and bottlenecks and add pressure to \\nthe people at those points. It stresses them as individuals and has long-term implications for mental health \\nand productivity. If the workflow’s rate needs to increase, you should use the value stream maps to identify \\nthe lowest flow areas and improve those. The rest of the sections within these four phases guide those \\nimprovements. \\nThe outputs of the selected cell should match the next cell’s inputs; in this example, it is the solution \\narchitecture cell. We should consider the information the solution architects require without them having \\nto come back repeatedly for clarification. These are listed below in the inputs of the next section, but we \\nwill state them here: \\n\\uf0b7 Description of the functionality you will implement \\n\\uf0b7 Non-functional objectives \\no Availability Target (AT): the amount of time a system must be up as a percentage of the \\nmeasurement period \\no Recovery Time Objective (RTO): how long does it take to restore a system to a working \\nstate', metadata={'page': 108, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})]\n",
      "\n",
      "### QUESTION:\n",
      "How do I make the transition of novemes more efficient? \n",
      "\n",
      "[/INST]\n",
      " \n",
      "To make the transition of novumes more efficient, there are several steps you can take:\n",
      "\n",
      "1. Collaboration: Collaboration between the upstream and downstream cells is crucial. The upstream cell should communicate effectively with the downstream cell to ensure that the novumes are being processed efficiently and effectively. This includes sharing information about the novumes, such as their priority and estimated time to complete.\n",
      "2. Automation: Automating as much of the novume processing as possible can help to reduce the size of the novumes and improve the efficiency of the pipeline. This can include automating tasks such as testing, deployment, and monitoring.\n",
      "3. Prioritization: Prioritizing novumes based on their importance and urgency can help to ensure that the most critical novumes are processed first. This can involve using metrics such as customer priority and impact on revenue to determine the priority of each novume.\n",
      "4. Communication: Effective communication between the cells in the pipeline is essential for ensuring that the novumes are being processed efficiently. This includes regular meetings to discuss progress, identifying bottlenecks and addressing them promptly, and providing regular updates to stakeholders.\n",
      "5. Continuous improvement: Continuously reviewing and improving the pipeline can help to identify areas for improvement and ensure that the novumes are being processed efficiently. This can involve using value stream mapping to identify bottlenecks and inefficiencies in the pipeline, and\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I start a digital transformation programme on my portfolio of digital products using designed4devops?\"\n",
    "\n",
    "test_rag(qa, user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9bd0c-e02c-4156-936f-335fab15ab74",
   "metadata": {},
   "source": [
    "Let's ask a very specific question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b9803f1-f8a6-40e2-b043-da28ea2b79f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do I make the transition of novemes more efficient?\n",
      "\n",
      "Inference time: 30.03 sec.\n",
      "\n",
      "Result:  \n",
      "### [INST] \n",
      "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
      "Don't use expletives or bad language.\n",
      "If you can't answer the appoligise and say you don't know.\n",
      "Don't make up answers. Please limit your answer to 200 words or less. Here is context to help:\n",
      "\n",
      "[Document(page_content='Designed4: Selecting Novemes \\n \\n \\n95 \\uf0b7 Security vulnerabilities - any critical security vulnerabilities should be able to jump the queue! \\nAnother selection criterion that might be important is the cost/benefit relationship identified at the \\nestimation stage. Many organizations expect a return on investments within a specified period. Not all \\ninvestments will be financial. For example, you may have a security bug that requires fixing. You may be \\nmorally or contractually obliged to remedy the known bug within a defined period of its discovery or \\ndisclosure. \\nWork in Progress (WIP) \\nWhen selecting novemes, you need to consider the pipeline’s capacity. Any work put into the pipeline \\nwill be processed at each cell, requiring people and resources. If we keep adding novemes into the pipe \\nwithout considering the flow rate downstream, we will inevitably cause blockages further down the value \\nstream as we hit bottlenecks. Restricting the Work in Progress (WIP) is probably the most critical method \\nto optimize flow through the value stream. \\nWe should meet, discuss, and collaborate with our downstream cell to understand the resources and \\nstaffing levels available to process new novemes. Do not hold novemes back upstream to relieve our \\ndownstream cell’s pressure; it will mask the problems downstream. We should expose the takt time of the \\ndownstream cell to get more investment. We can report back to our bug-track systems in the tickets to set \\nexpectations regarding expectations for timescales. Once we send the noveme downstream, we might no \\nlonger directly see its status. It is related to the number of people you have in the cells’ teams and the takt \\ntime to process novemes.', metadata={'page': 112, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Selecting Novemes \\n \\n \\n93 Designed4: Selecting Novemes \\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\nfor further development. \\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\ndownstream one above all others. \\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\ncost required for the investment. The following are examples of information typically captured: \\n\\uf0b7 Feature request or bug fix \\n\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\n\\uf0b7 Required by whom? \\n\\uf0b7 Change to existing service or new service \\n\\uf0b7 Number of identical or similar requests \\nEstimation \\nMost organizations will want to track their costs in some form or another. In publicly listed \\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\n\\uf0b7 Upfront and ongoing costs for the noveme \\n\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\n\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\n\\uf0b7 The expected return on the investment in the noveme \\n\\uf0b7 The length of time required for the noveme to realize its benefits \\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid', metadata={'page': 110, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Part III - WHAT - A Model Value Stream- Phase 4 - Disposal \\n \\n \\n212 Part III – Summary \\nWe have come to the end of our novemes’ journey, flowing down the pipeline. Hopefully, we will \\nachieve what we set out to do, recognize the flow of novemes through our business, and optimize their \\ndelivery. We can improve the flow by aligning the upstream cell’s outputs with the downstream’s inputs. \\nAutomating as much cell processing as possible in the pipeline will help bring down the sizes of the \\nnovemes to get as close as possible to the single-piece flow we can. It will smooth the flow, reduce the size \\nof releases, and remove the risk and anxiety from the release process itself. Reducing risk allows you to \\nembrace a constant change stream, driving improvements in your product and the pipeline that delivers \\nit. \\nRemember, this section is not a foolproof template for building a pipeline that will work in your \\nproduct. Hopefully, you can recognize the cells involved in the flow and understand their need to be more \\nefficient. We should expect every pipeline to be different. The pipeline here can be used as a reference \\npoint or model to conceptualize your pipeline. Once you understand your pipeline, you can improve it \\nusing tools such as value stream mapping. \\nThe framework in Part III is a typical value stream within digital product delivery. It is intended as a \\nreference point to discuss how flow moves between one cell and another. It is not the value stream or even \\nnecessarily the target  value stream. Value streams will necessarily vary between products, organizations, \\nand organizational units. You need to map the value streams you intend to improve.', metadata={'page': 229, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Product Management \\n \\n \\n91 Designed4: Product Management \\nThe pipeline and product must have the same owner. Moving both governance frameworks under the \\nsame umbrella will probably be your biggest and first challenge. In many organizations, product \\nmanagement and delivery are distinct and separate. \\nHaving products and pipelines under the same control means we can design and develop them to \\ncomplement each other. We aim to reduce the overall lead time, minimize the number of external \\ndependencies, and reduce noveme size to allow single-piece flow. The Product Manager responsible for \\nboth can ensure that everyone moves forward together. Remember, we want to enable global progress, not \\nlocal progress. \\nThe first task is to find someone to take this role, your Product Manager. \\nProduct Manager Role \\nThe best way to increase the flow for the noveme selection is to have it done by someone trained and \\nexperienced in product management and with devops experience. The Product Manager role is the \\ngatekeeper for the whole value stream, and as such, it is their job to balance the flow of work going into \\nthe pipeline with the pipeline’s output rate. We must not add novemes from the backlog to process faster \\nthan we can handle them, as this will only expose the pinch-points and bottlenecks and add pressure to \\nthe people at those points. It stresses them as individuals and has long-term implications for mental health \\nand productivity. If the workflow’s rate needs to increase, you should use the value stream maps to identify \\nthe lowest flow areas and improve those. The rest of the sections within these four phases guide those \\nimprovements. \\nThe outputs of the selected cell should match the next cell’s inputs; in this example, it is the solution \\narchitecture cell. We should consider the information the solution architects require without them having \\nto come back repeatedly for clarification. These are listed below in the inputs of the next section, but we \\nwill state them here: \\n\\uf0b7 Description of the functionality you will implement \\n\\uf0b7 Non-functional objectives \\no Availability Target (AT): the amount of time a system must be up as a percentage of the \\nmeasurement period \\no Recovery Time Objective (RTO): how long does it take to restore a system to a working \\nstate', metadata={'page': 108, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})]\n",
      "\n",
      "### QUESTION:\n",
      "How do I make the transition of novemes more efficient? \n",
      "\n",
      "[/INST]\n",
      " \n",
      "To make the transition of novumes more efficient, there are several steps you can take:\n",
      "\n",
      "1. Define clear input criteria: The team in the Selecting Novemes cell should define the input criteria for any novume they will accept. This will help the Product Manager provide an early rough-order estimate of the effort and cost required for the investment.\n",
      "2. Automate as much cell processing as possible: Automating as much cell processing as possible in the pipeline will help bring down the sizes of the novumes to get as close as possible to the single-piece flow we can. It will smooth the flow, reduce the size of releases, and remove the risk and anxiety from the release process itself.\n",
      "3. Collaborate with downstream cells: When selecting novumes, it's important to collaborate with the downstream cells to understand their resources and staffing levels available to process new novumes. Don't hold novumes back upstream to relieve downstream pressure; it will mask the problems downstream. Instead, expose the takt time of the downstream cell to get more investment.\n",
      "4. Estimate costs and benefits: Most organizations will want to track their costs in some form or another. The estimate must provide the following information: upfront and ongoing costs for the novume, the cost of software licenses, infrastructure services, and external services that we require, the effort to build and run the novume (which may have\n"
     ]
    }
   ],
   "source": [
    "query = \"My developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time?\"\n",
    "\n",
    "test_rag(qa, user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df285ad5-69f1-4242-8489-9a8cb406dcf5",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This was quite simple to set up on a local laptop. It demonstrates that generative AI is achievable with modest resources and in short time periods. Before you jump in, be sure to check out my blog on [Generative AI and RAG Security](https://).\n",
    "\n",
    "I'll be taking this project further and blogging along the way. I'll be talking about the environment I used to build this demo, how I productionise the system, package it and host it, and adding a front end so that you can interact with the book yourselves!\n",
    "\n",
    "You can download this blog as a Jupyter notebook file [here](https://github.com/tudor-james/ai-playground/blob/main/mistral-rag-langchain-chromadb.ipynb). As ever, if you need help with AI projects you can get in touch with Methods or contact us via LinkedIn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79254d96-0145-4fc2-bad0-09d2f9972cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is your question? How do I make the transition of novemes more efficient?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do I make the transition of novemes more efficient?\n",
      "\n",
      "Inference time: 26.657 sec.\n",
      "\n",
      "Result:  \n",
      "### [INST] \n",
      "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
      "Don't use expletives or bad language.\n",
      "If you can't answer the appoligise and say you don't know.\n",
      "Don't make up answers. Please limit your answer to 200 words or less. Here is context to help:\n",
      "\n",
      "[Document(page_content='Designed4: Selecting Novemes \\n \\n \\n95 \\uf0b7 Security vulnerabilities - any critical security vulnerabilities should be able to jump the queue! \\nAnother selection criterion that might be important is the cost/benefit relationship identified at the \\nestimation stage. Many organizations expect a return on investments within a specified period. Not all \\ninvestments will be financial. For example, you may have a security bug that requires fixing. You may be \\nmorally or contractually obliged to remedy the known bug within a defined period of its discovery or \\ndisclosure. \\nWork in Progress (WIP) \\nWhen selecting novemes, you need to consider the pipeline’s capacity. Any work put into the pipeline \\nwill be processed at each cell, requiring people and resources. If we keep adding novemes into the pipe \\nwithout considering the flow rate downstream, we will inevitably cause blockages further down the value \\nstream as we hit bottlenecks. Restricting the Work in Progress (WIP) is probably the most critical method \\nto optimize flow through the value stream. \\nWe should meet, discuss, and collaborate with our downstream cell to understand the resources and \\nstaffing levels available to process new novemes. Do not hold novemes back upstream to relieve our \\ndownstream cell’s pressure; it will mask the problems downstream. We should expose the takt time of the \\ndownstream cell to get more investment. We can report back to our bug-track systems in the tickets to set \\nexpectations regarding expectations for timescales. Once we send the noveme downstream, we might no \\nlonger directly see its status. It is related to the number of people you have in the cells’ teams and the takt \\ntime to process novemes.', metadata={'page': 112, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Selecting Novemes \\n \\n \\n93 Designed4: Selecting Novemes \\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\nfor further development. \\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\ndownstream one above all others. \\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\ncost required for the investment. The following are examples of information typically captured: \\n\\uf0b7 Feature request or bug fix \\n\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\n\\uf0b7 Required by whom? \\n\\uf0b7 Change to existing service or new service \\n\\uf0b7 Number of identical or similar requests \\nEstimation \\nMost organizations will want to track their costs in some form or another. In publicly listed \\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\n\\uf0b7 Upfront and ongoing costs for the noveme \\n\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\n\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\n\\uf0b7 The expected return on the investment in the noveme \\n\\uf0b7 The length of time required for the noveme to realize its benefits \\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid', metadata={'page': 110, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Part III - WHAT - A Model Value Stream- Phase 4 - Disposal \\n \\n \\n212 Part III – Summary \\nWe have come to the end of our novemes’ journey, flowing down the pipeline. Hopefully, we will \\nachieve what we set out to do, recognize the flow of novemes through our business, and optimize their \\ndelivery. We can improve the flow by aligning the upstream cell’s outputs with the downstream’s inputs. \\nAutomating as much cell processing as possible in the pipeline will help bring down the sizes of the \\nnovemes to get as close as possible to the single-piece flow we can. It will smooth the flow, reduce the size \\nof releases, and remove the risk and anxiety from the release process itself. Reducing risk allows you to \\nembrace a constant change stream, driving improvements in your product and the pipeline that delivers \\nit. \\nRemember, this section is not a foolproof template for building a pipeline that will work in your \\nproduct. Hopefully, you can recognize the cells involved in the flow and understand their need to be more \\nefficient. We should expect every pipeline to be different. The pipeline here can be used as a reference \\npoint or model to conceptualize your pipeline. Once you understand your pipeline, you can improve it \\nusing tools such as value stream mapping. \\nThe framework in Part III is a typical value stream within digital product delivery. It is intended as a \\nreference point to discuss how flow moves between one cell and another. It is not the value stream or even \\nnecessarily the target  value stream. Value streams will necessarily vary between products, organizations, \\nand organizational units. You need to map the value streams you intend to improve.', metadata={'page': 229, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Product Management \\n \\n \\n91 Designed4: Product Management \\nThe pipeline and product must have the same owner. Moving both governance frameworks under the \\nsame umbrella will probably be your biggest and first challenge. In many organizations, product \\nmanagement and delivery are distinct and separate. \\nHaving products and pipelines under the same control means we can design and develop them to \\ncomplement each other. We aim to reduce the overall lead time, minimize the number of external \\ndependencies, and reduce noveme size to allow single-piece flow. The Product Manager responsible for \\nboth can ensure that everyone moves forward together. Remember, we want to enable global progress, not \\nlocal progress. \\nThe first task is to find someone to take this role, your Product Manager. \\nProduct Manager Role \\nThe best way to increase the flow for the noveme selection is to have it done by someone trained and \\nexperienced in product management and with devops experience. The Product Manager role is the \\ngatekeeper for the whole value stream, and as such, it is their job to balance the flow of work going into \\nthe pipeline with the pipeline’s output rate. We must not add novemes from the backlog to process faster \\nthan we can handle them, as this will only expose the pinch-points and bottlenecks and add pressure to \\nthe people at those points. It stresses them as individuals and has long-term implications for mental health \\nand productivity. If the workflow’s rate needs to increase, you should use the value stream maps to identify \\nthe lowest flow areas and improve those. The rest of the sections within these four phases guide those \\nimprovements. \\nThe outputs of the selected cell should match the next cell’s inputs; in this example, it is the solution \\narchitecture cell. We should consider the information the solution architects require without them having \\nto come back repeatedly for clarification. These are listed below in the inputs of the next section, but we \\nwill state them here: \\n\\uf0b7 Description of the functionality you will implement \\n\\uf0b7 Non-functional objectives \\no Availability Target (AT): the amount of time a system must be up as a percentage of the \\nmeasurement period \\no Recovery Time Objective (RTO): how long does it take to restore a system to a working \\nstate', metadata={'page': 108, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})]\n",
      "\n",
      "### QUESTION:\n",
      "How do I make the transition of novemes more efficient? \n",
      "\n",
      "[/INST]\n",
      " \n",
      "To make the transition of novumes more efficient, there are several steps that can be taken. Firstly, it is important to have a clear understanding of the requirements and priorities for the novumes being developed. This can be achieved by involving the relevant stakeholders, such as the Product Manager, in the decision-making process.\n",
      "\n",
      "Once the priorities have been established, it is important to ensure that the novumes are properly aligned with the capabilities and resources available in the organization. This can involve working closely with downstream cells to understand their capacity and staffing levels, and adjusting the workload accordingly.\n",
      "\n",
      "It is also important to establish clear communication channels between the novume selection and development cells, to ensure that any issues or concerns are addressed promptly. This can involve regular meetings and collaboration sessions, as well as the use of tools such as value stream mapping to visualize the flow of novumes through the pipeline.\n",
      "\n",
      "Finally, it is important to continuously monitor and evaluate the performance of the novume selection and development processes, and make adjustments as necessary to improve efficiency and effectiveness. This can involve tracking metrics such as cycle time and throughput, and using this data to identify areas for improvement.\n"
     ]
    }
   ],
   "source": [
    "user_input = input('What is your question?')\n",
    "# rag_chain.invoke(user_input)\n",
    "test_rag(qa, user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71b7e4-5959-413d-b1f1-9e7a6faa6340",
   "metadata": {},
   "source": [
    "### Find source documents by semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41d7c260-abaf-4aee-9e2d-8fd30861e216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What would you like to look for? Where can i find out about the market growth for digital transformation?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Where can i find out about the market growth for digital transformation?\n",
      "Retrieved documents: 4\n",
      "Source:  /home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\n",
      "Text:  About this book \n",
      " \n",
      "vii \n",
      " About this book \n",
      "This book is for anyone considering or working in the digital transformation of organizations that \n",
      "create digital products. It uses DevOps and the optimization of delivering change as its core but shows you \n",
      "how to approach it structurally and repeatedly. It also shows you how to design your product delivery and \n",
      "integrate it into broader business frameworks such as security and service management. \n",
      "designed4devops  will guide your digital transformation to becoming a ‘Digital Speed’ producer of \n",
      "digital products. It will shape your re-organization with a structured approach that is repeatable, \n",
      "measurable, and testable. It could save you hundreds of thousands of dollars a year, improve your \n",
      "products’ stability and security, make you more agile in your markets, create a culture of innovation, make \n",
      "your organization a better workplace, and reduce our contributions to climate change! \n",
      "While I try to explain all the relevant terms used in devops within this book, it is a broad topic, with \n",
      "some subjects having entire (excellent) books of their own which I have included these in a reference \n",
      "section at the end of the book. \n",
      "\n",
      "Source:  /home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\n",
      "Text:  Preface \n",
      " \n",
      " \n",
      "ii Background \n",
      "If you are involved in delivering technology products in any capacity, such as consulting, management, \n",
      "or technical, then this book is for you. I intend to give you a structured approach to increasing efficiency \n",
      "in technology delivery within your organization. It will help you understand DevOps and why you should \n",
      "embrace it within your organization and integrate it with your broader business frameworks. \n",
      "Digital Transformation is the restructuring of organizations that deliver digital products to operate \n",
      "more efficiently while decreasing costs and increasing the speed of product development, delivery, and \n",
      "innovation. DevOps is a crucial ingredient of Digital Transformation as it brings a cultural and \n",
      "technological approach to embedding these ideologies in our processes. \n",
      "The lean transformation techniques started in the manufacturing industry. Toyota looked for ways of \n",
      "optimizing its manufacturing processes in its factories. Beginning with “The Toyota Way,” they evolved \n",
      "into the “Toyota Production System.” Womack, Roos, and Jones distilled it into the Lean principles in The \n",
      "Machine That Changed the World and Lean Thinking in the 1990s. Lean is about putting customer value \n",
      "over processes. We can use the Lean principles to cut waste, increase flow, and create a culture of continual \n",
      "improvement. \n",
      "designed4devops  is a Lean, product-centric, integrated approach to the digital transformation of \n",
      "organizations engaged in digital product delivery. It explains how we can learn from decades of learning \n",
      "in optimizing production lines for physical product delivery and apply it to the pipelines of digital product \n",
      "delivery. \n",
      "designed4devops  focuses on the four phases of the lifecycle of a typical digital product: Design, \n",
      "Development, Use, and Disposal. We can optimize the pipeline for the product's whole life from the outset \n",
      "to optimize the overall lead times for delivering changes. \n",
      "Gartner claims that the Digital Transformation market was at USD 284.38 billion in 2019 and expects \n",
      "to expand at a compound annual growth rate (CAGR) of 22.5% from 2020 to 2027. Gartner also predicts \n",
      "DevOps to reach USD 12.85 billion by 2025, an 18.60% CAGR during the forecast period. \n",
      "It is a fair generalization to say that most organizations are IT organizations today. Very few \n",
      "organizations could survive without technology. Organizations choose to customize or buy bespoke \n",
      "software to service their core business. Others are in the business of selling digital products, from apps \n",
      "and games to enterprise systems. \n",
      "The speed at which we can deliver change to our core products can mean the difference between leading \n",
      "a market segment or being left behind by competitors. \n",
      "\n",
      "Source:  /home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\n",
      "Text:  Lean in a Digital World \n",
      " \n",
      " \n",
      "5 IT: Sorry, we’d also need to buy some new servers for development. That usually takes three \n",
      "months by the time we get the money approved.  \n",
      "You: Oh. How do we start?  \n",
      "IT: We are at the year-end change freeze. Plus, there’s the spending freeze. And we have the \n",
      "auditing. Could we get everyone together after the holidays?  \n",
      "You: [to yourself] This year or next? \n",
      "If this sounds familiar, you are not alone. If you recognize the problem, congratulations, you are taking \n",
      "your first steps toward digital transformation. We must ask, “What prevents us from making changes \n",
      "quickly?” \n",
      "Technology and the industry-standard processes that govern them are locked in a Darwinian dance \n",
      "perpetuated for decades. As technology has become more complicated, so too have the controls. Mistakes \n",
      "can be inordinately expensive; we strive to avoid lost revenue, incorrect software purchases, and outages. \n",
      "We propagate a second vicious circle. As changes become riskier, we become more risk averse. We \n",
      "instinctively try to make fewer changes less frequently. Conversely, our changes get more complicated and \n",
      "even more difficult. The longer we stay locked in this battle of wits, the less agile we become. \n",
      "Beyond our organizations, technology has now become ubiquitous. Your business is now wholly reliant \n",
      "on it to work efficiently for its success. The world changes fast, so we must innovate our technology \n",
      "products even quicker. In the example above, the business’ constraint to marketing its product more \n",
      "effectively is how quickly we can change the eCommerce website. ‘The company’ views IT like power and \n",
      "water, something necessary but not core. \n",
      "Technology-selling organizations usually supply customer-facing products through separate but \n",
      "loosely integrated divisions. Most companies with over a hundred or so staff in their technology \n",
      "departments form smaller groups, sometimes organically, defined by roles rather than products. The IT \n",
      "division often has internal departments, such as the service desk, operations, development, and \n",
      "application teams. People in other non-IT divisions are often responsible for products and owning feature \n",
      "lists and roadmaps. They are then defined for the technologists to deliver. \n",
      "Quote \n",
      "Any organization that designs a system (defined broadly) will produce a design whose structure is a \n",
      "copy of the organization’s communication structure.  \n",
      "— Melvin E. Conway \n",
      "\n",
      "Source:  /home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\n",
      "Text:  Background \n",
      " \n",
      "iii \n",
      " With designed4devops  and its framework, I aim to give you a structure to use DevOps to design and \n",
      "deliver Digital Transformation within your organization. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_search = input('What would you like to look for?')\n",
    "docs = db.similarity_search(doc_search)\n",
    "print(f\"Query: {doc_search}\")\n",
    "print(f\"Retrieved documents: {len(docs)}\")\n",
    "for doc in docs:\n",
    "    doc_details = doc.to_json()['kwargs']\n",
    "    print(\"Source: \", doc_details['metadata']['source'])\n",
    "    print(\"Text: \", doc_details['page_content'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6f59a-0690-43e0-a9aa-90731b825eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
