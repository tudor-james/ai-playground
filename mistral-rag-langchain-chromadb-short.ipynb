{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81544e7-f1c5-44cf-9faf-d7f2bc852117",
   "metadata": {},
   "source": [
    "# RAG with ChromaDB, Langchain, Mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238abf1f-e8ff-4913-9d4a-cf53f5a32b15",
   "metadata": {},
   "source": [
    "First, we'll install the dependencies and set up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a275d0f8-7cb0-45c8-9fa7-3af48132bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall -Uq 'torch==2.2.2' datasets accelerate peft bitsandbytes transformers trl 'numpy<2.0' langchain chromadb openai tiktoken sentence-transformers pypdf langchain-community langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a61245b-de66-41a1-ae9f-6c358ce3ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq pipreqsnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865dccba-094c-4cc4-bcc1-9fad33efc7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate==0.31.0\n",
      "aiohttp==3.9.5\n",
      "aiosignal==1.3.1\n",
      "alembic @ file:///home/conda/feedstock_root/build_artifacts/alembic_1705179948871/work\n",
      "altair @ file:///home/conda/feedstock_root/build_artifacts/altair-split_1711824856061/work\n",
      "annotated-types==0.7.0\n",
      "anyio==4.4.0\n",
      "archspec @ file:///home/conda/feedstock_root/build_artifacts/archspec_1708969572489/work\n",
      "argon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1692818318753/work\n",
      "argon2-cffi-bindings @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi-bindings_1695386553988/work\n",
      "arrow @ file:///home/conda/feedstock_root/build_artifacts/arrow_1696128962909/work\n",
      "asgiref==3.8.1\n",
      "asttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1698341106958/work\n",
      "async-generator==1.10\n",
      "async-lru @ file:///home/conda/feedstock_root/build_artifacts/async-lru_1690563019058/work\n",
      "attrs==23.2.0\n",
      "Babel @ file:///home/conda/feedstock_root/build_artifacts/babel_1702422572539/work\n",
      "backcall==0.2.0\n",
      "backoff==2.2.1\n",
      "bcrypt==4.1.3\n",
      "beautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1705564648255/work\n",
      "bitsandbytes==0.43.1\n",
      "bleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1696630167146/work\n",
      "blinker @ file:///home/conda/feedstock_root/build_artifacts/blinker_1698890160476/work\n",
      "bokeh @ file:///home/conda/feedstock_root/build_artifacts/bokeh_1712901085037/work\n",
      "boltons @ file:///home/conda/feedstock_root/build_artifacts/boltons_1711936407380/work\n",
      "Bottleneck @ file:///home/conda/feedstock_root/build_artifacts/bottleneck_1708965975391/work\n",
      "Brotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1695989787169/work\n",
      "build==1.2.1\n",
      "cached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\n",
      "cachetools==5.3.3\n",
      "certifi==2024.6.2\n",
      "certipy==0.1.3\n",
      "cffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1696001724357/work\n",
      "charset-normalizer==3.3.2\n",
      "chroma-hnswlib==0.7.3\n",
      "chromadb==0.5.3\n",
      "click==8.1.7\n",
      "cloudpickle @ file:///home/conda/feedstock_root/build_artifacts/cloudpickle_1697464713350/work\n",
      "colorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work\n",
      "coloredlogs==15.0.1\n",
      "comm @ file:///home/conda/feedstock_root/build_artifacts/comm_1710320294760/work\n",
      "conda @ file:///home/conda/feedstock_root/build_artifacts/conda_1711445840151/work\n",
      "conda-libmamba-solver @ file:///home/conda/feedstock_root/build_artifacts/conda-libmamba-solver_1706566000184/work/src\n",
      "conda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1691048088238/work\n",
      "conda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1691009212940/work\n",
      "contourpy @ file:///home/conda/feedstock_root/build_artifacts/contourpy_1712429897138/work\n",
      "cryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography-split_1708780250343/work\n",
      "cycler @ file:///home/conda/feedstock_root/build_artifacts/cycler_1696677705766/work\n",
      "Cython @ file:///home/conda/feedstock_root/build_artifacts/cython_1711833971575/work\n",
      "cytoolz @ file:///home/conda/feedstock_root/build_artifacts/cytoolz_1706897031595/work\n",
      "dask @ file:///home/conda/feedstock_root/build_artifacts/dask-core_1712248465271/work\n",
      "dask-expr @ file:///home/conda/feedstock_root/build_artifacts/dask-expr_1712693819397/work\n",
      "dataclasses-json==0.6.7\n",
      "datasets==2.20.0\n",
      "debugpy @ file:///home/conda/feedstock_root/build_artifacts/debugpy_1707444446407/work\n",
      "decorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\n",
      "defusedxml @ file:///home/conda/feedstock_root/build_artifacts/defusedxml_1615232257335/work\n",
      "Deprecated==1.2.14\n",
      "dill==0.3.8\n",
      "distributed @ file:///home/conda/feedstock_root/build_artifacts/distributed_1712327504625/work\n",
      "distro==1.9.0\n",
      "dnspython==2.6.1\n",
      "docopt==0.6.2\n",
      "docstring_parser==0.16\n",
      "email_validator==2.2.0\n",
      "entrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\n",
      "et-xmlfile @ file:///home/conda/feedstock_root/build_artifacts/et_xmlfile_1674664118162/work\n",
      "exceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1704921103267/work\n",
      "executing @ file:///home/conda/feedstock_root/build_artifacts/executing_1698579936712/work\n",
      "fastapi==0.111.0\n",
      "fastapi-cli==0.0.4\n",
      "fastjsonschema @ file:///home/conda/feedstock_root/build_artifacts/python-fastjsonschema_1703780968325/work/dist\n",
      "filelock==3.15.4\n",
      "flatbuffers==24.3.25\n",
      "fonttools @ file:///home/conda/feedstock_root/build_artifacts/fonttools_1712344564583/work\n",
      "fqdn @ file:///home/conda/feedstock_root/build_artifacts/fqdn_1638810296540/work/dist\n",
      "frozenlist==1.4.1\n",
      "fsspec==2024.5.0\n",
      "gitdb @ file:///home/conda/feedstock_root/build_artifacts/gitdb_1697791558612/work\n",
      "GitPython @ file:///home/conda/feedstock_root/build_artifacts/gitpython_1711991025291/work\n",
      "gmpy2 @ file:///home/conda/feedstock_root/build_artifacts/gmpy2_1666808665953/work\n",
      "google-auth==2.30.0\n",
      "googleapis-common-protos==1.63.2\n",
      "greenlet==3.0.3\n",
      "grpcio==1.64.1\n",
      "h11==0.14.0\n",
      "h2 @ file:///home/conda/feedstock_root/build_artifacts/h2_1634280454336/work\n",
      "h5py @ file:///home/conda/feedstock_root/build_artifacts/h5py_1712763571402/work\n",
      "hpack==4.0.0\n",
      "httpcore==1.0.5\n",
      "httptools==0.6.1\n",
      "httpx==0.27.0\n",
      "huggingface-hub==0.23.4\n",
      "humanfriendly==10.0\n",
      "hyperframe @ file:///home/conda/feedstock_root/build_artifacts/hyperframe_1619110129307/work\n",
      "idna==3.7\n",
      "imagecodecs @ file:///home/conda/feedstock_root/build_artifacts/imagecodecs_1712887516691/work\n",
      "imageio @ file:///home/conda/feedstock_root/build_artifacts/imageio_1707730027807/work\n",
      "importlib_metadata==7.1.0\n",
      "importlib_resources==6.4.0\n",
      "ipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1708996548741/work\n",
      "ipympl @ file:///home/conda/feedstock_root/build_artifacts/ipympl_1713251546026/work\n",
      "ipython==8.12.3\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets @ file:///home/conda/feedstock_root/build_artifacts/ipywidgets_1707427226251/work\n",
      "isoduration @ file:///home/conda/feedstock_root/build_artifacts/isoduration_1638811571363/work/dist\n",
      "jedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work\n",
      "Jinja2==3.1.4\n",
      "joblib==1.4.2\n",
      "json5 @ file:///home/conda/feedstock_root/build_artifacts/json5_1712986206667/work\n",
      "jsonpatch==1.33\n",
      "jsonpointer==3.0.0\n",
      "jsonschema @ file:///home/conda/feedstock_root/build_artifacts/jsonschema-meta_1705707496704/work\n",
      "jsonschema-specifications @ file:///tmp/tmpkv1z7p57/src\n",
      "jupyter-events @ file:///home/conda/feedstock_root/build_artifacts/jupyter_events_1710805637316/work\n",
      "jupyter-kernel-gateway==3.0.1\n",
      "jupyter-lsp @ file:///home/conda/feedstock_root/build_artifacts/jupyter-lsp-meta_1712707420468/work/jupyter-lsp\n",
      "jupyter-server-mathjax @ file:///home/conda/feedstock_root/build_artifacts/jupyter-server-mathjax_1672324512570/work\n",
      "jupyter-telemetry @ file:///home/conda/feedstock_root/build_artifacts/jupyter_telemetry_1605173804246/work\n",
      "jupyter_client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1710255804825/work\n",
      "jupyter_core @ file:///home/conda/feedstock_root/build_artifacts/jupyter_core_1710257359434/work\n",
      "jupyter_server @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_1712884210432/work\n",
      "jupyter_server_terminals @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_terminals_1710262634903/work\n",
      "jupyterhub @ file:///home/conda/feedstock_root/build_artifacts/jupyterhub-feedstock_1712274897296/work\n",
      "jupyterlab @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_1712586972478/work\n",
      "jupyterlab_git @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab-git_1707314297225/work\n",
      "jupyterlab_pygments @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_pygments_1707149102966/work\n",
      "jupyterlab_server @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_server-split_1712583928460/work\n",
      "jupyterlab_widgets @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_widgets_1707421892171/work\n",
      "kiwisolver @ file:///home/conda/feedstock_root/build_artifacts/kiwisolver_1695379920604/work\n",
      "kubernetes==30.1.0\n",
      "langchain==0.2.6\n",
      "langchain-community==0.2.6\n",
      "langchain-core==0.2.10\n",
      "langchain-huggingface==0.0.3\n",
      "langchain-text-splitters==0.2.2\n",
      "langsmith==0.1.82\n",
      "lazy_loader @ file:///home/conda/feedstock_root/build_artifacts/lazy_loader_1712342969017/work\n",
      "libmambapy @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1711394305528/work/libmambapy\n",
      "llvmlite==0.42.0\n",
      "locket @ file:///home/conda/feedstock_root/build_artifacts/locket_1650660393415/work\n",
      "lz4 @ file:///home/conda/feedstock_root/build_artifacts/lz4_1704831090180/work\n",
      "Mako @ file:///home/conda/feedstock_root/build_artifacts/mako_1712771160938/work\n",
      "mamba @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1711394305528/work/mamba\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==2.1.5\n",
      "marshmallow==3.21.3\n",
      "matplotlib @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-suite_1712605884949/work\n",
      "matplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1713250518406/work\n",
      "mdurl==0.1.2\n",
      "menuinst @ file:///home/conda/feedstock_root/build_artifacts/menuinst_1705068285750/work\n",
      "mistune @ file:///home/conda/feedstock_root/build_artifacts/mistune_1698947099619/work\n",
      "mmh3==4.1.0\n",
      "monotonic==1.6\n",
      "mpmath==1.3.0\n",
      "msgpack @ file:///home/conda/feedstock_root/build_artifacts/msgpack-python_1700926512836/work\n",
      "multidict==6.0.5\n",
      "multiprocess==0.70.16\n",
      "munkres==1.1.4\n",
      "mypy-extensions==1.0.0\n",
      "nbclassic @ file:///home/conda/feedstock_root/build_artifacts/nbclassic_1683202081046/work\n",
      "nbclient @ file:///home/conda/feedstock_root/build_artifacts/nbclient_1710317608672/work\n",
      "nbconvert @ file:///home/conda/feedstock_root/build_artifacts/nbconvert-meta_1712766805841/work\n",
      "nbdime @ file:///home/conda/feedstock_root/build_artifacts/nbdime_1700575643650/work\n",
      "nbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1712238998817/work\n",
      "nest_asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1705850609492/work\n",
      "networkx==3.3\n",
      "notebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1713397707292/work\n",
      "notebook_shim @ file:///home/conda/feedstock_root/build_artifacts/notebook-shim_1707957777232/work\n",
      "numba @ file:///home/conda/feedstock_root/build_artifacts/numba_1711475169058/work\n",
      "numexpr @ file:///home/conda/feedstock_root/build_artifacts/numexpr_1707139886895/work\n",
      "numpy==1.26.4\n",
      "nvidia-cublas-cu12==12.1.3.1\n",
      "nvidia-cuda-cupti-cu12==12.1.105\n",
      "nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "nvidia-cuda-runtime-cu12==12.1.105\n",
      "nvidia-cudnn-cu12==8.9.2.26\n",
      "nvidia-cufft-cu12==11.0.2.54\n",
      "nvidia-curand-cu12==10.3.2.106\n",
      "nvidia-cusolver-cu12==11.4.5.107\n",
      "nvidia-cusparse-cu12==12.1.0.106\n",
      "nvidia-nccl-cu12==2.19.3\n",
      "nvidia-nvjitlink-cu12==12.5.40\n",
      "nvidia-nvtx-cu12==12.1.105\n",
      "oauthlib==3.2.2\n",
      "onnxruntime==1.18.0\n",
      "openai==1.35.6\n",
      "openpyxl @ file:///home/conda/feedstock_root/build_artifacts/openpyxl_1695464696880/work\n",
      "opentelemetry-api==1.25.0\n",
      "opentelemetry-exporter-otlp-proto-common==1.25.0\n",
      "opentelemetry-exporter-otlp-proto-grpc==1.25.0\n",
      "opentelemetry-instrumentation==0.46b0\n",
      "opentelemetry-instrumentation-asgi==0.46b0\n",
      "opentelemetry-instrumentation-fastapi==0.46b0\n",
      "opentelemetry-proto==1.25.0\n",
      "opentelemetry-sdk==1.25.0\n",
      "opentelemetry-semantic-conventions==0.46b0\n",
      "opentelemetry-util-http==0.46b0\n",
      "orjson==3.10.5\n",
      "overrides==7.7.0\n",
      "packaging==24.1\n",
      "pamela @ file:///home/conda/feedstock_root/build_artifacts/pamela_1691565434937/work\n",
      "pandas==2.2.2\n",
      "pandocfilters @ file:///home/conda/feedstock_root/build_artifacts/pandocfilters_1631603243851/work\n",
      "parso @ file:///home/conda/feedstock_root/build_artifacts/parso_1712320355065/work\n",
      "partd @ file:///home/conda/feedstock_root/build_artifacts/partd_1695667515973/work\n",
      "patsy @ file:///home/conda/feedstock_root/build_artifacts/patsy_1704469236901/work\n",
      "peft==0.11.1\n",
      "pexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1706113125309/work\n",
      "pickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\n",
      "pillow==10.3.0\n",
      "pipreqs==0.5.0\n",
      "pipreqsnb==0.2.4\n",
      "pkgutil_resolve_name @ file:///home/conda/feedstock_root/build_artifacts/pkgutil-resolve-name_1694617248815/work\n",
      "platformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1706713388748/work\n",
      "pluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1706116770704/work\n",
      "posthog==3.5.0\n",
      "prometheus_client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1707932675456/work\n",
      "prompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1702399386289/work\n",
      "protobuf==4.25.3\n",
      "psutil==6.0.0\n",
      "ptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n",
      "pure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\n",
      "py-cpuinfo @ file:///home/conda/feedstock_root/build_artifacts/py-cpuinfo_1666774466606/work\n",
      "pyarrow==16.1.0\n",
      "pyarrow-hotfix==0.6\n",
      "pyasn1==0.6.0\n",
      "pyasn1_modules==0.4.0\n",
      "pycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1696355758146/work\n",
      "pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1711811537435/work\n",
      "pycurl @ file:///home/conda/feedstock_root/build_artifacts/pycurl_1710066807136/work\n",
      "pydantic==2.7.4\n",
      "pydantic_core==2.18.4\n",
      "Pygments==2.18.0\n",
      "PyJWT @ file:///home/conda/feedstock_root/build_artifacts/pyjwt_1706895065046/work\n",
      "pyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1706660063483/work\n",
      "pyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1709721012883/work\n",
      "pypdf==4.2.0\n",
      "PyPika==0.48.9\n",
      "pyproject_hooks==1.1.0\n",
      "PySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1661604839144/work\n",
      "python-dateutil==2.9.0.post0\n",
      "python-dotenv==1.0.1\n",
      "python-json-logger @ file:///home/conda/feedstock_root/build_artifacts/python-json-logger_1677079630776/work\n",
      "python-multipart==0.0.9\n",
      "pytz==2024.1\n",
      "PyWavelets @ file:///home/conda/feedstock_root/build_artifacts/pywavelets_1695567566807/work\n",
      "PyYAML==6.0.1\n",
      "pyzmq @ file:///home/conda/feedstock_root/build_artifacts/pyzmq_1713207461646/work\n",
      "referencing @ file:///home/conda/feedstock_root/build_artifacts/referencing_1710763696991/work\n",
      "regex==2024.5.15\n",
      "requests==2.32.3\n",
      "requests-oauthlib==2.0.0\n",
      "rfc3339-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3339-validator_1638811747357/work\n",
      "rfc3986-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3986-validator_1598024191506/work\n",
      "rich==13.7.1\n",
      "rpds-py @ file:///home/conda/feedstock_root/build_artifacts/rpds-py_1707922729351/work\n",
      "rsa==4.9\n",
      "ruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1707298093865/work\n",
      "ruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1707314491256/work\n",
      "safetensors==0.4.3\n",
      "scikit-image @ file:///home/conda/feedstock_root/build_artifacts/scikit-image_1697028611470/work/dist/scikit_image-0.22.0-cp311-cp311-linux_x86_64.whl#sha256=53d8b95f752df47007e9e71dd1c9805b9334e1e4791cf48e3762abb922636f04\n",
      "scikit-learn==1.5.0\n",
      "scipy==1.14.0\n",
      "seaborn @ file:///home/conda/feedstock_root/build_artifacts/seaborn-split_1706340836595/work\n",
      "Send2Trash @ file:///home/conda/feedstock_root/build_artifacts/send2trash_1712584999685/work\n",
      "sentence-transformers==3.0.1\n",
      "shellingham==1.5.4\n",
      "shtab==1.7.1\n",
      "six==1.16.0\n",
      "smmap @ file:///home/conda/feedstock_root/build_artifacts/smmap_1634310307496/work\n",
      "sniffio==1.3.1\n",
      "sortedcontainers @ file:///home/conda/feedstock_root/build_artifacts/sortedcontainers_1621217038088/work\n",
      "soupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1693929250441/work\n",
      "SQLAlchemy==2.0.31\n",
      "stack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work\n",
      "starlette==0.37.2\n",
      "statsmodels @ file:///home/conda/feedstock_root/build_artifacts/statsmodels_1702575375433/work\n",
      "sympy==1.12.1\n",
      "tables @ file:///home/conda/feedstock_root/build_artifacts/pytables_1712794355007/work\n",
      "tblib @ file:///home/conda/feedstock_root/build_artifacts/tblib_1702066284995/work\n",
      "tenacity==8.4.2\n",
      "terminado @ file:///home/conda/feedstock_root/build_artifacts/terminado_1710262609923/work\n",
      "threadpoolctl==3.5.0\n",
      "tifffile @ file:///home/conda/feedstock_root/build_artifacts/tifffile_1713426129511/work\n",
      "tiktoken==0.7.0\n",
      "tinycss2 @ file:///home/conda/feedstock_root/build_artifacts/tinycss2_1666100256010/work\n",
      "tokenizers==0.19.1\n",
      "tomli @ file:///home/conda/feedstock_root/build_artifacts/tomli_1644342247877/work\n",
      "toolz @ file:///home/conda/feedstock_root/build_artifacts/toolz_1706112571092/work\n",
      "torch==2.2.2\n",
      "torchaudio==2.2.2+cu121\n",
      "torchvision==0.17.2+cu121\n",
      "tornado @ file:///home/conda/feedstock_root/build_artifacts/tornado_1708363099148/work\n",
      "tqdm==4.66.4\n",
      "traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1710254411456/work\n",
      "transformers==4.42.1\n",
      "triton==2.2.0\n",
      "trl==0.9.4\n",
      "truststore @ file:///home/conda/feedstock_root/build_artifacts/truststore_1694154605758/work\n",
      "typer==0.12.3\n",
      "types-python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/types-python-dateutil_1710589910274/work\n",
      "typing-inspect==0.9.0\n",
      "typing-utils @ file:///home/conda/feedstock_root/build_artifacts/typing_utils_1622899189314/work\n",
      "typing_extensions==4.12.2\n",
      "tyro==0.8.5\n",
      "tzdata==2024.1\n",
      "ujson==5.10.0\n",
      "uri-template @ file:///home/conda/feedstock_root/build_artifacts/uri-template_1688655812972/work/dist\n",
      "urllib3==2.2.2\n",
      "uvicorn==0.30.1\n",
      "uvloop==0.19.0\n",
      "watchfiles==0.22.0\n",
      "wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1704731205417/work\n",
      "webcolors @ file:///home/conda/feedstock_root/build_artifacts/webcolors_1679900785843/work\n",
      "webencodings @ file:///home/conda/feedstock_root/build_artifacts/webencodings_1694681268211/work\n",
      "websocket-client==1.8.0\n",
      "websockets==12.0\n",
      "widgetsnbextension @ file:///home/conda/feedstock_root/build_artifacts/widgetsnbextension_1707420319466/work\n",
      "wrapt==1.16.0\n",
      "xlrd @ file:///home/conda/feedstock_root/build_artifacts/xlrd_1610224409810/work\n",
      "xxhash==3.4.1\n",
      "xyzservices @ file:///home/conda/feedstock_root/build_artifacts/xyzservices_1712209912887/work\n",
      "yarg==0.1.9\n",
      "yarl==1.9.4\n",
      "zict @ file:///home/conda/feedstock_root/build_artifacts/zict_1681770155528/work\n",
      "zipp==3.19.2\n",
      "zstandard==0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14dc4a7a-1e58-4b59-a510-a8e5cfeaf664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import datasets\n",
    "import accelerate\n",
    "import peft\n",
    "import bitsandbytes\n",
    "import trl\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "# from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "import nest_asyncio\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough, RunnableSequence\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.output_parsers.json import SimpleJsonOutputParser\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoModel, MistralForCausalLM\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "# from langchain.chains import LLMChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ebad1-ceb1-454b-936f-9bf54fadc68d",
   "metadata": {},
   "source": [
    "This sets up the tokeniser. This breaks the text up into tokens (chunks) which can be individual words or fragments of words.\n",
    "\n",
    "I'm going to use Mistral 7B as it offers a good performance at a low overhead of processing and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e7bb7e-1a11-4bfe-9b4d-29f60b0250b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='../models/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bff158-c603-4bd4-ba4b-5b2d61a8325b",
   "metadata": {},
   "source": [
    "#### Quantization of the Model\n",
    "\n",
    "I'm going to quantize the model to 4 bits. This lowers the precision of the data types (int4 vs fp16 or fp32), which reduces the overheads even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac06130-f66b-4341-9ee9-6197cd2effa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72d5f88-8577-47f8-922a-740690132e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa1b72b-f025-4aec-b992-24b36bcdeab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc44133-d625-4336-88ab-ad02644a0705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae3d5282cd746acac11f8d3d3c8e212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "# model = AutoModel.from_pretrained(\n",
    "model = MistralForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea67554-a91f-4008-bdcc-fcc24e2d6c8d",
   "metadata": {},
   "source": [
    "#### Let's test it..\n",
    "\n",
    "This query asks the model a question. We haven't loaded any of our data into it yet, this is all information held within the model from its training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e1adf3-fdb0-4553-92a8-7208a5921c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> [INST] What is Designed4Devops? [/INST] Designed4DevOps is an open-source, automated testing framework for DevOps pipeline management for Windows, Mac, and Linux operating systems. It is designed to be easy to use and offers a wide range of features, including continuous integration and continuous delivery support, automated testing for both traditional Microsoft technologies and modern open source technologies, and built-in debugging and reporting capabilities. Designed4DevOps was originally developed by Microsoft, and it is released under the MIT license.</s>']\n"
     ]
    }
   ],
   "source": [
    "inputs_not_chat = tokenizer.encode_plus(\"[INST] What is Designed4Devops? [/INST]\", return_tensors=\"pt\")['input_ids'].to('cuda')\n",
    "\n",
    "generated_ids = model.generate(inputs_not_chat, \n",
    "                               max_new_tokens=1000, \n",
    "                               do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0baba-0611-4acc-b0f6-8d436bb6fac5",
   "metadata": {},
   "source": [
    "#### Create the ChromaDB vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb335d0-445e-4a47-8082-9ea021fd1ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load the book\n",
    "loader = PyPDFLoader(\"/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Chunk text\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunked_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# Load chunked documents into the Chroma index\n",
    "db = Chroma.from_documents(chunked_documents, embedding_function)\n",
    "\n",
    "# Connect query to Chroma index using a retriever\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 4}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed6733c-07b0-4868-9a43-77193e0fb9c2",
   "metadata": {},
   "source": [
    "#### Test the vector store\n",
    "\n",
    "This tests that the data exists within the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee5ed610-a64b-470a-a391-259bc771dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "designed4devops\n"
     ]
    }
   ],
   "source": [
    "query = \"What can designed4devops do for my organisation?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b617a88c-1c08-4fc0-a180-3edc72d77924",
   "metadata": {},
   "source": [
    "#### Create the LLM chain\n",
    "\n",
    "To create a symantically aware search, we need to store the context of the question, and engineer a prompt that focuses the model on answering questions using the data from our vector store instead of making it up (hallucinating). Prompt engineering is a way to coach the model into giving the sort of answers that you want return and filter those that you don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d1916-ac2b-49fb-a96d-60329064a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=300,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "### [INST] \n",
    "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
    "Don't use expletives or bad language.\n",
    "If you can't answer the appoligise and say you don't know.\n",
    "Don't make up answers. Please limit your answer to 500 words or less. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} \n",
    "\n",
    "[/INST]\n",
    " \"\"\"\n",
    "\n",
    "# mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "# llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "llm_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2eb0d6c3-1ae1-4041-a822-1e1ad9a66734",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "def test_rag(qa, query):\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    time_1 = time()\n",
    "    # result = qa.run(query)\n",
    "    result = rag_chain.invoke(query)\n",
    "    time_2 = time()\n",
    "    print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n",
    "    print(\"\\nResult: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8fb3a5-f435-4a19-956e-e4a6d2cb2dc0",
   "metadata": {},
   "source": [
    "#### Create RAG Chain\n",
    "\n",
    "This chains the prompt with the question to _hopefully_ get a strong answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7771491-5768-4f6e-b17a-1c8e8178a58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Summarize the text in the vector database.\n",
      "\n",
      "Inference time: 28.068 sec.\n",
      "\n",
      "Result:  \n",
      "### [INST] \n",
      "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
      "Don't use expletives or bad language.\n",
      "If you can't answer the appoligise and say you don't know.\n",
      "Don't make up answers. Please limit your answer to 200 words or less. Here is context to help:\n",
      "\n",
      "[Document(page_content=\"Part III - WHAT - A Model Value Stream- Phase 1 - Design \\n \\n \\n100 They will interview users, conduct workshops, and complete surveys using analytical methods and their \\nexperience to understand the requirements and their context better. They will turn the requirements into \\nuser stories. \\nA user story is a user-centric definition of what the target user tries to achieve with the requirement. It \\nwill be unambiguous and allow a developer to code the functionality without a back-and-forth exchange \\nof information that will slow down cadence. \\nA user story might look like, “I want to add details to a user ticket by editing the record when I have \\nselected it from the list of tickets available.” It should have enough information so the developer can \\nunderstand the user's intent, picture themselves in their position, and walk through their actions in their \\nmind. \\nBusiness analysis is critical to agile development in many ways. Its purpose is to remove ambiguity. \\nPeople can only do it with enough experience in the field of what they are doing. They usually have a \\nbackground in the industry vertical you are serving. It is a skilled role that involves using experience and \\nan analytical approach to design with an ability to communicate and empathize with the users. A good \\nbusiness analyst will have a toolbox of techniques to work with users to drive the requirements gathering \\nand create user stories from them. \\nBusiness analysis is the bridge between addressing the business, the organizational or social need to \\nsolve a problem or perform a task, and the system's design that addresses that need. \\nUser Researcher \\nUser research is the understanding of human behavior when interacting with products. A user \\nresearcher will observe users' behavior to drive the product's design. BAs will analyze the data gathered in \\nthis exercise to inform the UX (user experience) design and improve the product's usability. \\nUser researchers may sit and observe the users directly and use data from systems or eye-tracking \\nsoftware on a cohort of users who volunteer for testing. It provides feedback to the UX design to increase \\nthe product's usability, efficiency, accessibility, and reach.\", metadata={'page': 117, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='218 84, 87, 91, 92, 94, 95, 96, 97, 98, 101, 104, 114, 115, \\n119, 120, 121, 122, 126, 133, 135, 136, 142, 148, 149, \\n150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 162, \\n163, 164, 165, 167, 169, 171, 172, 173, 176, 180, 181, \\n184, 185, 191, 192, 195, 196, 197, 198, 199, 200, 201, \\n202, 203, 205, 210, 211, 212, 213 \\npizzas, 68, 79 \\nPolicy, 132, 134, 135, 137, 138 \\nProcedures, 139 \\nprocurement, v, 6, 11, 20, 28, 45, 52, 53, 58, 59, 62, 64, \\n69, 70, 71, 75, 76, 90, 108, 123, 124, 125, 126, 141, \\n142, 197, 200, 208 \\nProduct Lifecycle, 32 \\nProduct Manager, 69, 70, 78, 91, 93 \\nQuality, 96, 97 \\nRecovery Point Objective, 92, 105, 118 \\nRecovery Time Objective, 91, 105, 118 \\nReleasing, 97, 129, 177, 207 \\nRetirement, 205, 206, 207, 209 \\nReuse, 126, 210 \\nrisk, 5, 8, 9, 14, 24, 31, 34, 36, 46, 53, 57, 60, 67, 93, 96, \\n99, 108, 109, 111, 113, 119, 122, 128, 129, 130, 135, \\n137, 143, 168, 174, 177, 179, 183, 197, 200, 203, 206, \\n207, 212 \\nRobustness, 98 \\nScrum, 7, 49, 81, 82, 83 \\nServerless, 163 \\nService hours, 92, 105 \\nSite Reliability Engineering , 159 \\nSLA, 23, 94, 119, 121, 183 \\nSLI, 183 \\nSLO, 118, 183 \\nSRE, 159 \\nStandards, 137, 138 stateful, 107, 119, 155 \\nStateful architectures, 107 \\nStatelessness, 155 \\nStrategy, 22, 131 \\nTaguchi, 98, 215 \\ntechnical debt , 19, 23, 24, 46, 47, 49, 50, 52, 55, 70, 72, 79, \\n82, 97, 108, 121, 128, 129, 136, 150, 163, 164, 172, \\n173, 190, 202 \\nTesting, 103, 147, 165, 166, 167, 168, 169, 170, 171, 174, \\n175, 207, 215 \\nTIMWOODS, 43 \\nTwelve Principles , 81 \\ntwo-pizza team , 78 \\nunit testing , 148 \\nUser experience, 101 \\nvalue stream, 8, 12, 13, 14, 15, 16, 17, 18, 20, 28, 29, 31, \\n32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 57, 58, 59, 60, \\n61, 62, 63, 64, 65, 67, 68, 70, 71, 77, 80, 87, 89, 91, \\n92, 93, 95, 104, 105, 106, 107, 113, 123, 124, 128, 129, \\n130, 131, 133, 137, 138, 139, 140, 141, 142, 144, 159, \\n161, 164, 170, 181, 194, 212 \\nValue Stream, 41, 42, 43, 60, 61, 89, 90, 101, 145, 181, \\n204 \\nvalue streams, v, 12, 16, 29, 30, 33, 38, 40, 42, 43, 59, \\n60, 61, 62, 63, 65, 70, 71, 73, 75, 78, 90, 104, 112, 131, \\n138, 139, 141, 142, 155, 173, 212 \\nVelocity, 185 \\nWaste, 6, 43, 81, 207, 215 \\nWIP, 14, 17, 18, 48, 49, 50, 52, 57, 82, 92, 95, 146, 164, \\n185 \\nWork in progress, 81 \\nWork in Progress , 14, 18, 95 \\nWork-In-Progress, 17, 80, 136', metadata={'page': 235, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='217 Index \\naccessibility, 100, 101, 102, 103, 137, 168, 190 \\nAgile, 13, 62, 77, 81, 82, 83, 84, 104 \\nAnalysis, 97, 99, 107, 146, 173 \\nArchitecture, 6, 9, 42, 90, 101, 104, 105, 108, 109, 116, \\n117, 118, 125, 126, 172, 196, 201 \\nartifacts, 44, 153, 156, 158, 160, 163, 174 \\nAutomation, 18, 48, 49, 65, 139, 152, 157, 175, 179, 215 \\nAvailability Target, 91, 105, 118 \\nAXSChat , 102 \\nBi-modal, 8 \\nblue/green, 129, 160, 162, 178, 206 \\nBurndown, 185 \\nCanary Releases, 167, 178 \\ncell, 10, 16, 17, 18, 19, 20, 32, 35, 37, 39, 41, 42, 49, 52, \\n56, 57, 59, 60, 61, 70, 77, 78, 79, 80, 82, 86, 91, 93, \\n95, 101, 104, 105, 106, 107, 108, 117, 118, 126, 141, \\n144, 149, 163, 164, 166, 175, 180, 184, 185, 200, 201, \\n210, 212, 213 \\nChaos Engineering , 154 \\ncode repository, 67, 114, 151, 152, 153, 156, 159, 165, \\n173 \\ncontainer, 20, 82, 114, 115, 121, 138, 156, 163, 176, 186, \\n189, 192 \\nContinuous deployment, 160 \\nContinuous Integration, 151, 155, 163 \\nculture, ii, vii, 8, 9, 11, 12, 13, 14, 22, 23, 24, 31, 54, 55, \\n56, 58, 60, 62, 67, 68, 69, 71, 101, 112, 126, 165, 194, \\n210 \\ndefects, 17, 25, 43, 52, 69, 84, 98, 148, 149, 167, 185 \\nDefinition of Done, 82 \\nDeming, 31 \\ndesign phase, 42, 90 \\ndevelopment , ii, 5, 8, 11, 15, 18, 32, 34, 35, 36, 40, 41, \\n49, 52, 57, 58, 60, 61, 63, 70, 71, 72, 82, 93, 99, 100, \\n106, 116, 126, 127, 128, 130, 131, 132, 133, 135, 136, \\n137, 138, 145, 146, 147, 148, 149, 150, 152, 154, 155, \\n157, 159, 160, 161, 163, 164, 165, 173, 180, 184, 198, \\n199, 200 \\nDevops, 9, 13, 14, 15, 17, 19, 22, 35, 37, 53, 94, 129, \\n150, 196, 199, 213 \\nDigital Transformation, iii, ii, iii \\ndiversity, 24, 55, 68 \\nDomain-Driven Design, 112 \\nFeature flags, 177 \\nfeedback, v, 6, 14, 31, 33, 34, 37, 52, 57, 58, 67, 68, 73, \\n82, 96, 97, 100, 129, 132, 133, 137, 138, 144, 148, 150, \\n152, 153, 154, 155, 160, 161, 162, 164, 165, 166, 168, \\n169, 170, 172, 175, 181, 182, 184, 191, 193, 194, 195, \\n196, 197, 200, 201, 202, 211, 213, 214 \\nflow, ii, v, viii, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, \\n19, 21, 22, 23, 24, 32, 33, 36, 37, 38, 40, 42, 43, 45, 48, 55, 59, 60, 61, 64, 65, 69, 70, 72, 73, 74, 75, 77, \\n79, 80, 81, 82, 83, 87, 90, 91, 92, 93, 94, 95, 96, 97, \\n98, 101, 103, 105, 106, 108,110, 111, 113, 116, 119, \\n120, 126, 129, 131, 135, 136, 139, 140, 144, 146, 147, \\n149, 153, 160, 161, 162, 163, 164, 166, 167, 168, 171, \\n177, 185, 196, 198, 205, 212, 213 \\nfunctional requirements, 34, 97, 105, 107, 116, 117, 118, \\n119, 126, 173 \\nGlue, 150 \\nGovernance , 29 \\nGuidance, 138, 154 \\nImmutable, 113, 178, 206 \\ninfrastructure-as-code, 157, 174, 178, 201 \\ninnovation, ii, vii, 6, 7, 8, 9, 23, 24, 25, 31, 53, 69, 93, \\n108, 139, 141, 162 \\nITSM, 183, 194, 197, 198, 199, 200 \\nkaizen, 11, 14, 28, 29, 30, 31, 32, 38, 62, 63, 67, 68, 70, \\n84, 85, 86, 114, 133, 181, 182, 200, 213 \\nKaizen, 11, 29 \\nKanban, 7, 49, 82, 83 \\nKPI, 183, 186 \\nKPIs, 106, 183, 186, 188, 192 \\nLead time, 16, 185 \\nlean, ii, viii, 4, 9, 10, 11, 13, 30, 57, 62, 68, 70, 83, 87, \\n108, 197, 214 \\nloosely coupled, 109 \\nmetrics, 30, 32, 41, 68, 85, 149, 153, 175, 182, 183, 184, \\n185, 186, 188, 189, 190, 202 \\nMetrics, 188, 189, 190 \\nmicroservice, 109, 111, 133, 187, 189, 192 \\nMicroservices, 110, 111 \\nMinimum Viable Product , 36 \\nmonitoring, 14, 32, 34, 50, 84, 97, 114, 117, 122, 123, \\n124, 127, 130, 153, 161, 162, 186, 187, 189, 191, 192, \\n194, 198 \\nMVP, 36, 37, 83, 94, 150, 176 \\nNIST, 115, 122 \\nNorth Star, 131 \\nnovemes, 8, 11, 13, 14, 17, 18, 19, 22, 24, 32, 33, 34, 35, \\n36, 37, 39, 40, 42, 55, 57, 61, 69, 74, 75, 77, 78, 79, \\n80, 82, 87, 90, 91, 92, 93, 94, 95, 96, 97, 99, 106, 110, \\n111, 114, 120, 126, 128, 129, 131, 136, 139, 141, 142, \\n144, 145, 146, 163, 165, 167, 175,177, 178, 179, 184, \\n185, 190, 191, 197, 200, 201, 202, 205, 209, 210, 211, \\n212, 213, 214 \\nOLA, 183 \\nOrchestration, 151, 158 \\nPackaging, 163 \\npipeline, ii, v, 6, 7, 10, 13, 14, 15, 16, 17, 18, 24, 25, 31, \\n32, 34, 35, 36, 37, 38, 43, 44, 45, 47, 48, 50, 51, 52, \\n54, 55, 58, 61, 69, 72, 74, 75, 76, 77, 78, 79, 82, 83,', metadata={'page': 234, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Selecting Novemes \\n \\n \\n93 Designed4: Selecting Novemes \\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\nfor further development. \\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\ndownstream one above all others. \\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\ncost required for the investment. The following are examples of information typically captured: \\n\\uf0b7 Feature request or bug fix \\n\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\n\\uf0b7 Required by whom? \\n\\uf0b7 Change to existing service or new service \\n\\uf0b7 Number of identical or similar requests \\nEstimation \\nMost organizations will want to track their costs in some form or another. In publicly listed \\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\n\\uf0b7 Upfront and ongoing costs for the noveme \\n\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\n\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\n\\uf0b7 The expected return on the investment in the noveme \\n\\uf0b7 The length of time required for the noveme to realize its benefits \\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid', metadata={'page': 110, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})]\n",
      "\n",
      "### QUESTION:\n",
      "Summarize the text in the vector database. \n",
      "\n",
      "[/INST]\n",
      " \n",
      "The text describes a process called \"Designing\" in a value stream. This process involves selecting novemes, which are user requirements or feature requests, and defining the input criteria for each noveme. The inputs capture information such as the type of noveme, customer priority, and number of similar requests. Estimates are also taken into account, including upfront and ongoing costs, effort to build and run the noveme, and expected return on investment. The goal is to provide a cost-benefit analysis of the investment size in people and resources compared to their payback.\n"
     ]
    }
   ],
   "source": [
    "query = \"Summarize the text in the vector database.\" \n",
    "\n",
    "test_rag(qa, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ffbf2-ffd4-463d-9cb4-6e9e60923afa",
   "metadata": {},
   "source": [
    "## The Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3bf2727-cc6b-4853-ac8f-de9c4316c273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do I make the transition of novemes more efficient?\n",
      "\n",
      "Inference time: 28.967 sec.\n",
      "\n",
      "Result:  \n",
      "### [INST] \n",
      "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
      "Don't use expletives or bad language.\n",
      "If you can't answer the appoligise and say you don't know.\n",
      "Don't make up answers. Please limit your answer to 200 words or less. Here is context to help:\n",
      "\n",
      "[Document(page_content='Designed4: Selecting Novemes \\n \\n \\n95 \\uf0b7 Security vulnerabilities - any critical security vulnerabilities should be able to jump the queue! \\nAnother selection criterion that might be important is the cost/benefit relationship identified at the \\nestimation stage. Many organizations expect a return on investments within a specified period. Not all \\ninvestments will be financial. For example, you may have a security bug that requires fixing. You may be \\nmorally or contractually obliged to remedy the known bug within a defined period of its discovery or \\ndisclosure. \\nWork in Progress (WIP) \\nWhen selecting novemes, you need to consider the pipeline’s capacity. Any work put into the pipeline \\nwill be processed at each cell, requiring people and resources. If we keep adding novemes into the pipe \\nwithout considering the flow rate downstream, we will inevitably cause blockages further down the value \\nstream as we hit bottlenecks. Restricting the Work in Progress (WIP) is probably the most critical method \\nto optimize flow through the value stream. \\nWe should meet, discuss, and collaborate with our downstream cell to understand the resources and \\nstaffing levels available to process new novemes. Do not hold novemes back upstream to relieve our \\ndownstream cell’s pressure; it will mask the problems downstream. We should expose the takt time of the \\ndownstream cell to get more investment. We can report back to our bug-track systems in the tickets to set \\nexpectations regarding expectations for timescales. Once we send the noveme downstream, we might no \\nlonger directly see its status. It is related to the number of people you have in the cells’ teams and the takt \\ntime to process novemes.', metadata={'page': 112, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Selecting Novemes \\n \\n \\n93 Designed4: Selecting Novemes \\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\nfor further development. \\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\ndownstream one above all others. \\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\ncost required for the investment. The following are examples of information typically captured: \\n\\uf0b7 Feature request or bug fix \\n\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\n\\uf0b7 Required by whom? \\n\\uf0b7 Change to existing service or new service \\n\\uf0b7 Number of identical or similar requests \\nEstimation \\nMost organizations will want to track their costs in some form or another. In publicly listed \\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\n\\uf0b7 Upfront and ongoing costs for the noveme \\n\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\n\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\n\\uf0b7 The expected return on the investment in the noveme \\n\\uf0b7 The length of time required for the noveme to realize its benefits \\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid', metadata={'page': 110, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Part III - WHAT - A Model Value Stream- Phase 4 - Disposal \\n \\n \\n212 Part III – Summary \\nWe have come to the end of our novemes’ journey, flowing down the pipeline. Hopefully, we will \\nachieve what we set out to do, recognize the flow of novemes through our business, and optimize their \\ndelivery. We can improve the flow by aligning the upstream cell’s outputs with the downstream’s inputs. \\nAutomating as much cell processing as possible in the pipeline will help bring down the sizes of the \\nnovemes to get as close as possible to the single-piece flow we can. It will smooth the flow, reduce the size \\nof releases, and remove the risk and anxiety from the release process itself. Reducing risk allows you to \\nembrace a constant change stream, driving improvements in your product and the pipeline that delivers \\nit. \\nRemember, this section is not a foolproof template for building a pipeline that will work in your \\nproduct. Hopefully, you can recognize the cells involved in the flow and understand their need to be more \\nefficient. We should expect every pipeline to be different. The pipeline here can be used as a reference \\npoint or model to conceptualize your pipeline. Once you understand your pipeline, you can improve it \\nusing tools such as value stream mapping. \\nThe framework in Part III is a typical value stream within digital product delivery. It is intended as a \\nreference point to discuss how flow moves between one cell and another. It is not the value stream or even \\nnecessarily the target  value stream. Value streams will necessarily vary between products, organizations, \\nand organizational units. You need to map the value streams you intend to improve.', metadata={'page': 229, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Product Management \\n \\n \\n91 Designed4: Product Management \\nThe pipeline and product must have the same owner. Moving both governance frameworks under the \\nsame umbrella will probably be your biggest and first challenge. In many organizations, product \\nmanagement and delivery are distinct and separate. \\nHaving products and pipelines under the same control means we can design and develop them to \\ncomplement each other. We aim to reduce the overall lead time, minimize the number of external \\ndependencies, and reduce noveme size to allow single-piece flow. The Product Manager responsible for \\nboth can ensure that everyone moves forward together. Remember, we want to enable global progress, not \\nlocal progress. \\nThe first task is to find someone to take this role, your Product Manager. \\nProduct Manager Role \\nThe best way to increase the flow for the noveme selection is to have it done by someone trained and \\nexperienced in product management and with devops experience. The Product Manager role is the \\ngatekeeper for the whole value stream, and as such, it is their job to balance the flow of work going into \\nthe pipeline with the pipeline’s output rate. We must not add novemes from the backlog to process faster \\nthan we can handle them, as this will only expose the pinch-points and bottlenecks and add pressure to \\nthe people at those points. It stresses them as individuals and has long-term implications for mental health \\nand productivity. If the workflow’s rate needs to increase, you should use the value stream maps to identify \\nthe lowest flow areas and improve those. The rest of the sections within these four phases guide those \\nimprovements. \\nThe outputs of the selected cell should match the next cell’s inputs; in this example, it is the solution \\narchitecture cell. We should consider the information the solution architects require without them having \\nto come back repeatedly for clarification. These are listed below in the inputs of the next section, but we \\nwill state them here: \\n\\uf0b7 Description of the functionality you will implement \\n\\uf0b7 Non-functional objectives \\no Availability Target (AT): the amount of time a system must be up as a percentage of the \\nmeasurement period \\no Recovery Time Objective (RTO): how long does it take to restore a system to a working \\nstate', metadata={'page': 108, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})]\n",
      "\n",
      "### QUESTION:\n",
      "How do I make the transition of novemes more efficient? \n",
      "\n",
      "[/INST]\n",
      " \n",
      "To make the transition of novumes more efficient, there are several steps you can take:\n",
      "\n",
      "1. Collaboration: Collaboration between the upstream and downstream cells is crucial. The upstream cell should communicate effectively with the downstream cell to ensure that the novumes are being processed efficiently and effectively. This includes sharing information about the novumes, such as their priority and estimated time to complete.\n",
      "2. Automation: Automating as much of the novume processing as possible can help to reduce the size of the novumes and improve the efficiency of the pipeline. This can include automating tasks such as testing, deployment, and monitoring.\n",
      "3. Prioritization: Prioritizing novumes based on their importance and urgency can help to ensure that the most critical novumes are processed first. This can involve using metrics such as customer priority and impact on revenue to determine the priority of each novume.\n",
      "4. Communication: Effective communication between the cells in the pipeline is essential for ensuring that the novumes are being processed efficiently. This includes regular meetings to discuss progress, identifying bottlenecks and addressing them promptly, and providing regular updates to stakeholders.\n",
      "5. Continuous improvement: Continuously reviewing and improving the pipeline can help to identify areas for improvement and ensure that the novumes are being processed efficiently. This can involve using value stream mapping to identify bottlenecks and inefficiencies in the pipeline, and\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I start a digital transformation programme on my portfolio of digital products using designed4devops?\"\n",
    "\n",
    "test_rag(qa, user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9bd0c-e02c-4156-936f-335fab15ab74",
   "metadata": {},
   "source": [
    "Let's ask a very specific question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b9803f1-f8a6-40e2-b043-da28ea2b79f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do I make the transition of novemes more efficient?\n",
      "\n",
      "Inference time: 30.03 sec.\n",
      "\n",
      "Result:  \n",
      "### [INST] \n",
      "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
      "Don't use expletives or bad language.\n",
      "If you can't answer the appoligise and say you don't know.\n",
      "Don't make up answers. Please limit your answer to 200 words or less. Here is context to help:\n",
      "\n",
      "[Document(page_content='Designed4: Selecting Novemes \\n \\n \\n95 \\uf0b7 Security vulnerabilities - any critical security vulnerabilities should be able to jump the queue! \\nAnother selection criterion that might be important is the cost/benefit relationship identified at the \\nestimation stage. Many organizations expect a return on investments within a specified period. Not all \\ninvestments will be financial. For example, you may have a security bug that requires fixing. You may be \\nmorally or contractually obliged to remedy the known bug within a defined period of its discovery or \\ndisclosure. \\nWork in Progress (WIP) \\nWhen selecting novemes, you need to consider the pipeline’s capacity. Any work put into the pipeline \\nwill be processed at each cell, requiring people and resources. If we keep adding novemes into the pipe \\nwithout considering the flow rate downstream, we will inevitably cause blockages further down the value \\nstream as we hit bottlenecks. Restricting the Work in Progress (WIP) is probably the most critical method \\nto optimize flow through the value stream. \\nWe should meet, discuss, and collaborate with our downstream cell to understand the resources and \\nstaffing levels available to process new novemes. Do not hold novemes back upstream to relieve our \\ndownstream cell’s pressure; it will mask the problems downstream. We should expose the takt time of the \\ndownstream cell to get more investment. We can report back to our bug-track systems in the tickets to set \\nexpectations regarding expectations for timescales. Once we send the noveme downstream, we might no \\nlonger directly see its status. It is related to the number of people you have in the cells’ teams and the takt \\ntime to process novemes.', metadata={'page': 112, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Selecting Novemes \\n \\n \\n93 Designed4: Selecting Novemes \\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\nfor further development. \\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\ndownstream one above all others. \\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\ncost required for the investment. The following are examples of information typically captured: \\n\\uf0b7 Feature request or bug fix \\n\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\n\\uf0b7 Required by whom? \\n\\uf0b7 Change to existing service or new service \\n\\uf0b7 Number of identical or similar requests \\nEstimation \\nMost organizations will want to track their costs in some form or another. In publicly listed \\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\n\\uf0b7 Upfront and ongoing costs for the noveme \\n\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\n\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\n\\uf0b7 The expected return on the investment in the noveme \\n\\uf0b7 The length of time required for the noveme to realize its benefits \\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid', metadata={'page': 110, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Part III - WHAT - A Model Value Stream- Phase 4 - Disposal \\n \\n \\n212 Part III – Summary \\nWe have come to the end of our novemes’ journey, flowing down the pipeline. Hopefully, we will \\nachieve what we set out to do, recognize the flow of novemes through our business, and optimize their \\ndelivery. We can improve the flow by aligning the upstream cell’s outputs with the downstream’s inputs. \\nAutomating as much cell processing as possible in the pipeline will help bring down the sizes of the \\nnovemes to get as close as possible to the single-piece flow we can. It will smooth the flow, reduce the size \\nof releases, and remove the risk and anxiety from the release process itself. Reducing risk allows you to \\nembrace a constant change stream, driving improvements in your product and the pipeline that delivers \\nit. \\nRemember, this section is not a foolproof template for building a pipeline that will work in your \\nproduct. Hopefully, you can recognize the cells involved in the flow and understand their need to be more \\nefficient. We should expect every pipeline to be different. The pipeline here can be used as a reference \\npoint or model to conceptualize your pipeline. Once you understand your pipeline, you can improve it \\nusing tools such as value stream mapping. \\nThe framework in Part III is a typical value stream within digital product delivery. It is intended as a \\nreference point to discuss how flow moves between one cell and another. It is not the value stream or even \\nnecessarily the target  value stream. Value streams will necessarily vary between products, organizations, \\nand organizational units. You need to map the value streams you intend to improve.', metadata={'page': 229, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Product Management \\n \\n \\n91 Designed4: Product Management \\nThe pipeline and product must have the same owner. Moving both governance frameworks under the \\nsame umbrella will probably be your biggest and first challenge. In many organizations, product \\nmanagement and delivery are distinct and separate. \\nHaving products and pipelines under the same control means we can design and develop them to \\ncomplement each other. We aim to reduce the overall lead time, minimize the number of external \\ndependencies, and reduce noveme size to allow single-piece flow. The Product Manager responsible for \\nboth can ensure that everyone moves forward together. Remember, we want to enable global progress, not \\nlocal progress. \\nThe first task is to find someone to take this role, your Product Manager. \\nProduct Manager Role \\nThe best way to increase the flow for the noveme selection is to have it done by someone trained and \\nexperienced in product management and with devops experience. The Product Manager role is the \\ngatekeeper for the whole value stream, and as such, it is their job to balance the flow of work going into \\nthe pipeline with the pipeline’s output rate. We must not add novemes from the backlog to process faster \\nthan we can handle them, as this will only expose the pinch-points and bottlenecks and add pressure to \\nthe people at those points. It stresses them as individuals and has long-term implications for mental health \\nand productivity. If the workflow’s rate needs to increase, you should use the value stream maps to identify \\nthe lowest flow areas and improve those. The rest of the sections within these four phases guide those \\nimprovements. \\nThe outputs of the selected cell should match the next cell’s inputs; in this example, it is the solution \\narchitecture cell. We should consider the information the solution architects require without them having \\nto come back repeatedly for clarification. These are listed below in the inputs of the next section, but we \\nwill state them here: \\n\\uf0b7 Description of the functionality you will implement \\n\\uf0b7 Non-functional objectives \\no Availability Target (AT): the amount of time a system must be up as a percentage of the \\nmeasurement period \\no Recovery Time Objective (RTO): how long does it take to restore a system to a working \\nstate', metadata={'page': 108, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})]\n",
      "\n",
      "### QUESTION:\n",
      "How do I make the transition of novemes more efficient? \n",
      "\n",
      "[/INST]\n",
      " \n",
      "To make the transition of novumes more efficient, there are several steps you can take:\n",
      "\n",
      "1. Define clear input criteria: The team in the Selecting Novemes cell should define the input criteria for any novume they will accept. This will help the Product Manager provide an early rough-order estimate of the effort and cost required for the investment.\n",
      "2. Automate as much cell processing as possible: Automating as much cell processing as possible in the pipeline will help bring down the sizes of the novumes to get as close as possible to the single-piece flow we can. It will smooth the flow, reduce the size of releases, and remove the risk and anxiety from the release process itself.\n",
      "3. Collaborate with downstream cells: When selecting novumes, it's important to collaborate with the downstream cells to understand their resources and staffing levels available to process new novumes. Don't hold novumes back upstream to relieve downstream pressure; it will mask the problems downstream. Instead, expose the takt time of the downstream cell to get more investment.\n",
      "4. Estimate costs and benefits: Most organizations will want to track their costs in some form or another. The estimate must provide the following information: upfront and ongoing costs for the novume, the cost of software licenses, infrastructure services, and external services that we require, the effort to build and run the novume (which may have\n"
     ]
    }
   ],
   "source": [
    "query = \"My developers produce working digital software products and them hand them to the operations team to manually install them in production systems. How do I reduce my lead time?\"\n",
    "\n",
    "test_rag(qa, user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df285ad5-69f1-4242-8489-9a8cb406dcf5",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This was quite simple to set up on a local laptop. It demonstrates that generative AI is achievable with modest resources and in short time periods. Before you jump in, be sure to check out my blog on [Generative AI and RAG Security](https://).\n",
    "\n",
    "I'll be taking this project further and blogging along the way. I'll be talking about the environment I used to build this demo, how I productionise the system, package it and host it, and adding a front end so that you can interact with the book yourselves!\n",
    "\n",
    "You can download this blog as a Jupyter notebook file [here](https://github.com/tudor-james/ai-playground/blob/main/mistral-rag-langchain-chromadb.ipynb). As ever, if you need help with AI projects you can get in touch with Methods or contact us via LinkedIn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79254d96-0145-4fc2-bad0-09d2f9972cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is your question? How do I make the transition of novemes more efficient?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do I make the transition of novemes more efficient?\n",
      "\n",
      "Inference time: 26.657 sec.\n",
      "\n",
      "Result:  \n",
      "### [INST] \n",
      "Instruction: Answer the question based on your knowledge from the files in the vector database only.\n",
      "Don't use expletives or bad language.\n",
      "If you can't answer the appoligise and say you don't know.\n",
      "Don't make up answers. Please limit your answer to 200 words or less. Here is context to help:\n",
      "\n",
      "[Document(page_content='Designed4: Selecting Novemes \\n \\n \\n95 \\uf0b7 Security vulnerabilities - any critical security vulnerabilities should be able to jump the queue! \\nAnother selection criterion that might be important is the cost/benefit relationship identified at the \\nestimation stage. Many organizations expect a return on investments within a specified period. Not all \\ninvestments will be financial. For example, you may have a security bug that requires fixing. You may be \\nmorally or contractually obliged to remedy the known bug within a defined period of its discovery or \\ndisclosure. \\nWork in Progress (WIP) \\nWhen selecting novemes, you need to consider the pipeline’s capacity. Any work put into the pipeline \\nwill be processed at each cell, requiring people and resources. If we keep adding novemes into the pipe \\nwithout considering the flow rate downstream, we will inevitably cause blockages further down the value \\nstream as we hit bottlenecks. Restricting the Work in Progress (WIP) is probably the most critical method \\nto optimize flow through the value stream. \\nWe should meet, discuss, and collaborate with our downstream cell to understand the resources and \\nstaffing levels available to process new novemes. Do not hold novemes back upstream to relieve our \\ndownstream cell’s pressure; it will mask the problems downstream. We should expose the takt time of the \\ndownstream cell to get more investment. We can report back to our bug-track systems in the tickets to set \\nexpectations regarding expectations for timescales. Once we send the noveme downstream, we might no \\nlonger directly see its status. It is related to the number of people you have in the cells’ teams and the takt \\ntime to process novemes.', metadata={'page': 112, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Selecting Novemes \\n \\n \\n93 Designed4: Selecting Novemes \\nThe backlog of novemes can come from many different sources. For example, you might have a bug \\ntracker with issues documented by your user base. You may also have an innovation funnel for new \\nfeatures due to market testing or business analysis. Whatever the source, you must select which ones you \\nwill work on and which take priority. It is typically the role of the Product Manager to choose the novemes \\nfor further development. \\nThe inputs and outputs enable the connected flow of the value stream. Inputs should capture the \\ninformation or data required for the cell to process the novemes passing through it. Outputs should match \\nthe following cell’s inputs to provide a smooth transition from one cell to another. Aligning the interface \\nensures that the downstream cell is considered the primary customer. The upstream cell must service the \\ndownstream one above all others. \\nThe team in the Selecting Novemes cell should define the input criteria for any noveme they will accept. \\nThese are important for the product managers to provide an early rough-order estimate of the effort and \\ncost required for the investment. The following are examples of information typically captured: \\n\\uf0b7 Feature request or bug fix \\n\\uf0b7 Customer priority: Blocking or non-blocking (causing incidents or holding up other work) \\n\\uf0b7 Required by whom? \\n\\uf0b7 Change to existing service or new service \\n\\uf0b7 Number of identical or similar requests \\nEstimation \\nMost organizations will want to track their costs in some form or another. In publicly listed \\norganizations, this can even be a legal requirement. The estimate must provide the following information: \\n\\uf0b7 Upfront and ongoing costs for the noveme \\n\\uf0b7 The cost of software licenses, infrastructure services, and external services that we require \\n\\uf0b7 The effort to build and run the noveme (which may have standard day rates attached) \\n\\uf0b7 The expected return on the investment in the noveme \\n\\uf0b7 The length of time required for the noveme to realize its benefits \\nThe estimation should provide a simple cost-benefit analysis of the investment size in people and \\nresources compared to those investments’ payback. Not all returns on investments will be a direct financial \\npayment. If the noveme focuses on fixing a security vulnerability, the payback may reduce risk or avoid', metadata={'page': 110, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Part III - WHAT - A Model Value Stream- Phase 4 - Disposal \\n \\n \\n212 Part III – Summary \\nWe have come to the end of our novemes’ journey, flowing down the pipeline. Hopefully, we will \\nachieve what we set out to do, recognize the flow of novemes through our business, and optimize their \\ndelivery. We can improve the flow by aligning the upstream cell’s outputs with the downstream’s inputs. \\nAutomating as much cell processing as possible in the pipeline will help bring down the sizes of the \\nnovemes to get as close as possible to the single-piece flow we can. It will smooth the flow, reduce the size \\nof releases, and remove the risk and anxiety from the release process itself. Reducing risk allows you to \\nembrace a constant change stream, driving improvements in your product and the pipeline that delivers \\nit. \\nRemember, this section is not a foolproof template for building a pipeline that will work in your \\nproduct. Hopefully, you can recognize the cells involved in the flow and understand their need to be more \\nefficient. We should expect every pipeline to be different. The pipeline here can be used as a reference \\npoint or model to conceptualize your pipeline. Once you understand your pipeline, you can improve it \\nusing tools such as value stream mapping. \\nThe framework in Part III is a typical value stream within digital product delivery. It is intended as a \\nreference point to discuss how flow moves between one cell and another. It is not the value stream or even \\nnecessarily the target  value stream. Value streams will necessarily vary between products, organizations, \\nand organizational units. You need to map the value streams you intend to improve.', metadata={'page': 229, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'}), Document(page_content='Designed4: Product Management \\n \\n \\n91 Designed4: Product Management \\nThe pipeline and product must have the same owner. Moving both governance frameworks under the \\nsame umbrella will probably be your biggest and first challenge. In many organizations, product \\nmanagement and delivery are distinct and separate. \\nHaving products and pipelines under the same control means we can design and develop them to \\ncomplement each other. We aim to reduce the overall lead time, minimize the number of external \\ndependencies, and reduce noveme size to allow single-piece flow. The Product Manager responsible for \\nboth can ensure that everyone moves forward together. Remember, we want to enable global progress, not \\nlocal progress. \\nThe first task is to find someone to take this role, your Product Manager. \\nProduct Manager Role \\nThe best way to increase the flow for the noveme selection is to have it done by someone trained and \\nexperienced in product management and with devops experience. The Product Manager role is the \\ngatekeeper for the whole value stream, and as such, it is their job to balance the flow of work going into \\nthe pipeline with the pipeline’s output rate. We must not add novemes from the backlog to process faster \\nthan we can handle them, as this will only expose the pinch-points and bottlenecks and add pressure to \\nthe people at those points. It stresses them as individuals and has long-term implications for mental health \\nand productivity. If the workflow’s rate needs to increase, you should use the value stream maps to identify \\nthe lowest flow areas and improve those. The rest of the sections within these four phases guide those \\nimprovements. \\nThe outputs of the selected cell should match the next cell’s inputs; in this example, it is the solution \\narchitecture cell. We should consider the information the solution architects require without them having \\nto come back repeatedly for clarification. These are listed below in the inputs of the next section, but we \\nwill state them here: \\n\\uf0b7 Description of the functionality you will implement \\n\\uf0b7 Non-functional objectives \\no Availability Target (AT): the amount of time a system must be up as a percentage of the \\nmeasurement period \\no Recovery Time Objective (RTO): how long does it take to restore a system to a working \\nstate', metadata={'page': 108, 'source': '/home/jovyan/docker-shared-data/rag-data/d4do_paperback.pdf'})]\n",
      "\n",
      "### QUESTION:\n",
      "How do I make the transition of novemes more efficient? \n",
      "\n",
      "[/INST]\n",
      " \n",
      "To make the transition of novumes more efficient, there are several steps that can be taken. Firstly, it is important to have a clear understanding of the requirements and priorities for the novumes being developed. This can be achieved by involving the relevant stakeholders, such as the Product Manager, in the decision-making process.\n",
      "\n",
      "Once the priorities have been established, it is important to ensure that the novumes are properly aligned with the capabilities and resources available in the organization. This can involve working closely with downstream cells to understand their capacity and staffing levels, and adjusting the workload accordingly.\n",
      "\n",
      "It is also important to establish clear communication channels between the novume selection and development cells, to ensure that any issues or concerns are addressed promptly. This can involve regular meetings and collaboration sessions, as well as the use of tools such as value stream mapping to visualize the flow of novumes through the pipeline.\n",
      "\n",
      "Finally, it is important to continuously monitor and evaluate the performance of the novume selection and development processes, and make adjustments as necessary to improve efficiency and effectiveness. This can involve tracking metrics such as cycle time and throughput, and using this data to identify areas for improvement.\n"
     ]
    }
   ],
   "source": [
    "user_input = input('What is your question?')\n",
    "# rag_chain.invoke(user_input)\n",
    "test_rag(qa, user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51934abd-bc39-4855-9d9c-308e83f01509",
   "metadata": {},
   "source": [
    "### Show information sources for a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e7f13ca-5cda-4ef6-ac10-f8da55b25073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What would you like to look for? What page is security on?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m doc_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat would you like to look for?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(doc_search)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_search\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieved documents: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "doc_search = input('What would you like to look for?')\n",
    "docs = db.similarity_search(doc_search)\n",
    "print(f\"Query: {doc_search}\")\n",
    "print(f\"Retrieved documents: {len(docs)}\")\n",
    "for doc in docs:\n",
    "    doc_details = doc.to_json()['kwargs']\n",
    "    print(\"Source: \", doc_details['metadata']['source'])\n",
    "    print(\"Text: \", doc_details['page_content'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29b6bc-3ef3-45c5-bd6d-93c1ed4c32f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
